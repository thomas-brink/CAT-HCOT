{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar BA & QM\n",
    "### Code - Data Cleaning and Preparation\n",
    "\n",
    "Group 8\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import dynamic_input_data\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "#### Load data and set data-types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data: fill in path to where csv files with data from the retailer (data_2019 and data_2020) are located\n",
    "#df_2019 = pd.read_csv('path_data_2019...', low_memory = True)\n",
    "#df_2020 = pd.read_csv('path_data_2020...', low_memory = True)\n",
    "df_2019 = pd.read_csv('/Users/thoma/Documents/seminar_data/data_2019.csv', low_memory = True)\n",
    "df_2020 = pd.read_csv('/Users/thoma/Documents/seminar_data/data_2020.csv', low_memory = True)\n",
    "\n",
    "# Concatenate files and create new index\n",
    "df_full = pd.concat([df_2019, df_2020])\n",
    "df_full = df_full.reset_index(drop = True)\n",
    "\n",
    "print('Total # records: ',df_full.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns:\n",
    "rename_columns = {'datetTimeFirstDeliveryMoment': 'dateTimeFirstDeliveryMoment',\n",
    "                  'generalMatchClassification'  : 'detailedMatchClassification',\n",
    "                  'detailedMatchClassification' : 'generalMatchClassification',\n",
    "                  'quanityReturned'             : 'quantityReturned'}\n",
    "\n",
    "df_full = df_full.rename(columns = rename_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['generalMatchClassification'] = df_full['generalMatchClassification'].replace('KNOWN HAPPY', 'HAPPY')\n",
    "\n",
    "df_full['detailedMatchClassification'] = df_full['detailedMatchClassification'].replace({'KNOWN HAPPY':'HAPPY',\n",
    "                                                                                         'KNOWN MILDLY UNHAPPY':'MILDLY UNHAPPY',\n",
    "                                                                                         'KNOWN MEDIUM UNHAPPY':'MEDIUM UNHAPPY',\n",
    "                                                                                         'KNOWN HEAVILY UNHAPPY':'HEAVILY UNHAPPY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date variables to date-type\n",
    "df_full['orderDate']                   = pd.to_datetime(df_full['orderDate'])\n",
    "df_full['cancellationDate']            = pd.to_datetime(df_full['cancellationDate'])\n",
    "df_full['promisedDeliveryDate']        = pd.to_datetime(df_full['promisedDeliveryDate'])\n",
    "df_full['shipmentDate']                = pd.to_datetime(df_full['shipmentDate'])\n",
    "df_full['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df_full['dateTimeFirstDeliveryMoment'])\n",
    "df_full['startDateCase']               = pd.to_datetime(df_full['startDateCase'])\n",
    "df_full['returnDateTime']              = pd.to_datetime(df_full['returnDateTime'])\n",
    "df_full['registrationDateSeller']      = pd.to_datetime(df_full['registrationDateSeller'])\n",
    "\n",
    "# Change type of columns\n",
    "dtype = {'calculationDefinitive': bool,\n",
    "         'noCancellation'       : bool,\n",
    "         'noCase'               : bool,\n",
    "         'hasOneCase'           : bool,\n",
    "         'hasMoreCases'         : bool,\n",
    "         'noReturn'             : bool}\n",
    "\n",
    "df_full = df_full.astype(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Remove Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nonsensical rows\n",
    "noise = df_full.loc[(df_full['startDateCase']        < df_full['orderDate']) | \n",
    "                   (df_full['cancellationDate']      < df_full['orderDate']) |\n",
    "                   (df_full['promisedDeliveryDate']  < df_full['orderDate']) |\n",
    "                   (df_full['shipmentDate']          < df_full['orderDate']) |\n",
    "                   (df_full['returnDateTime']        < df_full['orderDate']) |\n",
    "                   (df_full['cancellationDate']      > df_full['returnDateTime']) |\n",
    "                   (df_full['orderDate']             < df_full['registrationDateSeller']) |\n",
    "                   (df_full['orderDate']             > df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) |\n",
    "                   (df_full['cancellationDate']      > df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) |\n",
    "                   ((df_full['returnDateTime']       < df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) & \n",
    "                                                       (df_full['dateTimeFirstDeliveryMoment'].notnull()) &\n",
    "                                                       (df_full['returnDateTime'].notnull())) |\n",
    "                   (df_full['registrationDateSeller'].isnull()) |\n",
    "                   (df_full['promisedDeliveryDate'].isnull())].index\n",
    "\n",
    "# Drop noisy data\n",
    "df = df_full.drop(index = noise)\n",
    "print(len(noise), 'complete records removed from the data')\n",
    "print('Cleaned # records: ',df.shape[0],'\\n')\n",
    "\n",
    "# Sort rows by orderDate and create new index\n",
    "df = df.sort_values(by = 'orderDate')\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "# Remove inconsistent values\n",
    "cancellationNoise = df.loc[(df['noCancellation'] == True) & (df['cancellationDate'].notnull())].index\n",
    "returnNoise       = df.loc[(df['noReturn'] == True) & (df['returnDateTime'].notnull())].index\n",
    "caseNoise         = df.loc[(df['noCase'] == True) & (df['startDateCase'].notnull())].index\n",
    "quantityNoise     = df.loc[df['quantityReturned'] > df['quantityOrdered']].index\n",
    "deliveryNoise     = df.loc[(df['dateTimeFirstDeliveryMoment'].notnull()) & (df['onTimeDelivery'].isnull())].index\n",
    "\n",
    "df.loc[cancellationNoise, ['cancellationDate','cancellationReasonCode']] = None\n",
    "df.loc[returnNoise,       ['returnDateTime','quantityReturned','returnCode']] = None\n",
    "df.loc[caseNoise,         ['startDateCase','cntDistinctCaseIds','hasOneCase','hasMoreCases']] = None\n",
    "df.loc[quantityNoise,     ['quantityReturned']] = df.loc[quantityNoise, ['quantityOrdered']]\n",
    "df.loc[deliveryNoise,     ['dateTimeFirstDeliveryMoment']] = None\n",
    "\n",
    "print('# Records where cancellation values are emptied:',len(cancellationNoise))\n",
    "print('# Records where return values are emptied: \\t',len(returnNoise))\n",
    "print('# Records where case values are emptied: \\t',len(caseNoise))\n",
    "print('# Records where quantity values are equalized: \\t',len(quantityNoise))\n",
    "print('# Records where delivery values are emptied: \\t',len(deliveryNoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform totalPrice variable\n",
    "df['totalPrice'] = np.log(df['totalPrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Create New Variables\n",
    "\n",
    "##### Time Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables related to periods (days difference)\n",
    "df['caseDays']             = (df['startDateCase'] - df['orderDate']).dt.days\n",
    "df['returnDays']           = (df['returnDateTime'] - df['orderDate']).dt.days\n",
    "df['cancellationDays']     = (df['cancellationDate'] - df['orderDate']).dt.days\n",
    "df['actualDeliveryDays']   = (df['dateTimeFirstDeliveryMoment'].dt.normalize() - df['orderDate']).dt.days\n",
    "df['shipmentDays']         = (df['shipmentDate'] - df['orderDate']).dt.days\n",
    "df['partnerSellingDays']   = (df['orderDate'] - df['registrationDateSeller']).dt.days\n",
    "df['promisedDeliveryDays'] = (df['promisedDeliveryDate'] - df['orderDate']).dt.days\n",
    "\n",
    "# Time-related variables\n",
    "df['orderYear']    = df['orderDate'].dt.year\n",
    "df['orderMonth']   = df['orderDate'].dt.month\n",
    "df['orderWeekday'] = df['orderDate'].dt.weekday\n",
    "df['orderCorona']  = df['orderDate'].apply(lambda x: True if x > datetime.strptime('2020-03-20','%Y-%m-%d') else False)\n",
    "\n",
    "# Create dummy variables for weekdays, months and years\n",
    "df['orderMonday']    = df['orderWeekday'].apply(lambda x: True if x == 0 else False)\n",
    "df['orderTuesday']   = df['orderWeekday'].apply(lambda x: True if x == 1 else False)\n",
    "df['orderWednesday'] = df['orderWeekday'].apply(lambda x: True if x == 2 else False)\n",
    "df['orderThursday']  = df['orderWeekday'].apply(lambda x: True if x == 3 else False)\n",
    "df['orderFriday']    = df['orderWeekday'].apply(lambda x: True if x == 4 else False)\n",
    "df['orderSaturday']  = df['orderWeekday'].apply(lambda x: True if x == 5 else False)\n",
    "df['orderSunday']    = df['orderWeekday'].apply(lambda x: True if x == 6 else False)\n",
    "\n",
    "df['orderJanuary']   = df['orderMonth'].apply(lambda x: True if x == 1 else False)\n",
    "df['orderFebruary']  = df['orderMonth'].apply(lambda x: True if x == 2 else False)\n",
    "df['orderMarch']     = df['orderMonth'].apply(lambda x: True if x == 3 else False)\n",
    "df['orderApril']     = df['orderMonth'].apply(lambda x: True if x == 4 else False)\n",
    "df['orderMay']       = df['orderMonth'].apply(lambda x: True if x == 5 else False)\n",
    "df['orderJune']      = df['orderMonth'].apply(lambda x: True if x == 6 else False)\n",
    "df['orderJuly']      = df['orderMonth'].apply(lambda x: True if x == 7 else False)\n",
    "df['orderAugust']    = df['orderMonth'].apply(lambda x: True if x == 8 else False)\n",
    "df['orderSeptember'] = df['orderMonth'].apply(lambda x: True if x == 9 else False)\n",
    "df['orderOctober']   = df['orderMonth'].apply(lambda x: True if x == 10 else False)\n",
    "df['orderNovember']  = df['orderMonth'].apply(lambda x: True if x == 11 else False)\n",
    "df['orderDecember']  = df['orderMonth'].apply(lambda x: True if x == 12 else False)\n",
    "\n",
    "df['orderYear2020'] = df['orderYear'].apply(lambda x: True if x == 2020 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "##### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['productTitleLength'] = df['productTitle'].str.len()\n",
    "df['fulfilmentByPlatform'] = df['fulfilmentType'].apply(lambda x: True if x == 'FBB' else False)\n",
    "\n",
    "df['countryCodeNL']   = df['countryCode'].apply(lambda x: True if x == 'NL' else False)\n",
    "df['countryOriginNL'] = df['countryOriginSeller'].apply(lambda x: True if x == 'NL' else False)\n",
    "df['countryOriginBE'] = df['countryOriginSeller'].apply(lambda x: True if x == 'BE' else False)\n",
    "df['countryOriginDE'] = df['countryOriginSeller'].apply(lambda x: True if x == 'DE' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "##### Determinant Classification (for own insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df[['noCancellation','noReturn','noCase','onTimeDelivery']].values\n",
    "\n",
    "determinantClassification = np.empty(df_values.shape[0], dtype='object')\n",
    "\n",
    "for ix,df_ in enumerate(df_values):\n",
    "    if ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 1) & (df_[3] == True)): \n",
    "        determinantClassification[ix] = 'All good'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 1) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 1) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Late delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 0) & (df_[3] == True)):\n",
    "        determinantClassification[ix] = 'Case'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 0) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Case + Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 0) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Case + Late delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 1) & (df_[3] == True)):\n",
    "        determinantClassification[ix] = 'Return'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 1) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Return + Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 1) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Return + Late delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 0) & (df_[3] == True)):\n",
    "        determinantClassification[ix] = 'Return + Case'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 0) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Return + Case + Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 0) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Return + Case + Late delivery'\n",
    "    elif (df_[0] == 0):\n",
    "        determinantClassification[ix] = 'Cancellation'\n",
    "        \n",
    "df['determinantClassification'] = determinantClassification\n",
    "df['determinantClassification'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "##### Binary Match Classification (for own insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['binaryMatchClassification'] = df['generalMatchClassification'].apply(lambda x: 'UNKNOWN' if x == 'UNKNOWN' else 'KNOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "##### Transporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transporterCluster(transporterCode):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered transporter variable: 28 -> 5 categories\n",
    "    \"\"\"\n",
    "    if transporterCode in ['AH-NL','TNT','TNT-EXPRESS','TNT-EXTRA']:\n",
    "        return 'POSTNL'\n",
    "    elif transporterCode in ['DHL','DHL_DE','DHLFORYOU']:\n",
    "        return 'DHL'\n",
    "    elif transporterCode in ['DPD-NL','DPD-BE']:\n",
    "        return 'DPD'\n",
    "    elif transporterCode in ['BRIEFPOST','BPOST_BRIEF','DHL-GLOBAL-MAIL','TNT_BRIEF']:\n",
    "        return 'BRIEF'\n",
    "    else:\n",
    "        return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transporterCodeGeneral'] = df['transporterCode'].apply(transporterCluster)\n",
    "df['transporterCodeGeneral'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "##### Product Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productGroupCluster(productGroup):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered product group variable based on categories of retailer\n",
    "    60 -> 14 groups.\n",
    "    \"\"\"\n",
    "    if productGroup in ['Dutch Books PG','Ebooks and Audiobooks','International Books PG']:\n",
    "        return 'Books'\n",
    "    elif productGroup in ['Games Accessories','Games Consoles','Games Software Physical',\n",
    "                          'Movies','Music']:\n",
    "        return 'Music, Film & Games'\n",
    "    elif productGroup in ['Camera','Desktop Monitor and Beamer','Ereaders and Accessories',\n",
    "                          'Laptop Computers','PC Accessories','Personal Audio',\n",
    "                          'Sound and Vision Accessories','Storage and Network',\n",
    "                          'Telephone and Tablet Accessories','Telephones and Tablets','Television']:\n",
    "        return 'Computer & Electronics'\n",
    "    elif productGroup in ['General Toys','Recreational and Outdoor Toys']:\n",
    "        return 'Toys & Hobby'\n",
    "    elif productGroup in ['Baby and Kids Fashion','Baby PG']:\n",
    "        return 'Baby & Kids'\n",
    "    elif productGroup in ['Daily Care PG','Health PG','Perfumery PG','Personal Care']:\n",
    "        return 'Health & Care'\n",
    "    elif productGroup in ['Footwear','Jewelry and Watches','Mens and Womens Fashion','Wearables']:\n",
    "        return 'Fashion, Shoes & Accessories'\n",
    "    elif productGroup in ['Bodyfashion and Beachwear','Camping and Outdoor','Cycling',\n",
    "                          'Sporting Equipment','Sportswear','Travel Bags and Accessories']:\n",
    "        return 'Sports, Outdoor & Travel'\n",
    "    elif productGroup in ['Educational Dutch','Educational International','Printing and Ink']:\n",
    "        return 'Office & School'\n",
    "    elif productGroup in ['Supermarket PG'] :\n",
    "        return 'Food & Beverage'\n",
    "    elif productGroup in ['Furniture','Heating and Air','Home Decoration','Home Entertainment',\n",
    "                          'Household','Household Appliances','Kitchen','Kitchen Machines',\n",
    "                          'Lighting','Major Domestic Appliances PG','Plumbing and Safety']:\n",
    "        return 'Home, Cooking & Household'\n",
    "    elif productGroup in ['Garden','Pet PG','Textiles','Tools and Paint']:\n",
    "        return 'Pets, Garden & Jobs'\n",
    "    elif productGroup in ['Car and Motorcycle'] :\n",
    "        return 'Car & Motor'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['productGroupGeneral'] = df['productGroup'].apply(productGroupCluster)\n",
    "df['productGroupGeneral'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies of new product grouping\n",
    "for group in df['productGroupGeneral'].unique():\n",
    "    columnName = 'group' + group.split(' ')[0].replace(',','')\n",
    "    df[columnName] = df['productGroupGeneral'].apply(lambda x: True if x == group else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "##### Total Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print('Total: ',len(df.columns),' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cleaned and prepared data to csv file and choose the location to place the file at\n",
    "#df.to_csv('path...')\n",
    "df.to_csv('/Users/thoma/Documents/seminar_data/cleaned_prepared_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Determinant availability (for own insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate totals per Match Determinant\n",
    "totalCase = df['caseDays'].count()\n",
    "totalReturn = df['returnDays'].count()\n",
    "totalCancel = df['cancellationDays'].count()\n",
    "totalPromisedDelivery = df['promisedDeliveryDays'].count()\n",
    "totalDelivery = df['actualDeliveryDays'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for plot\n",
    "periodTable = pd.concat([df['caseDays'].value_counts().sort_index(),\n",
    "                         df['returnDays'].value_counts().sort_index(),\n",
    "                         df['cancellationDays'].value_counts().sort_index(),\n",
    "                         df['promisedDeliveryDays'].value_counts().sort_index(),\n",
    "                         df['actualDeliveryDays'].value_counts().sort_index()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create percantages per day and calculate running sum\n",
    "periodTable['caseDays%'] = (periodTable['caseDays'] / totalCase).cumsum()\n",
    "periodTable['returnDays%'] = (periodTable['returnDays'] / totalReturn).cumsum()\n",
    "periodTable['cancellationDays%'] = (periodTable['cancellationDays'] / totalCancel).cumsum()\n",
    "periodTable['promisedDeliveryDays%'] = (periodTable['promisedDeliveryDays'] / totalPromisedDelivery).cumsum()\n",
    "periodTable['actualDeliveryDays%'] = (periodTable['actualDeliveryDays'] / df.shape[0]).cumsum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
