{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T22:55:08.204309Z",
     "iopub.status.busy": "2021-02-23T22:55:08.204065Z",
     "iopub.status.idle": "2021-02-23T22:55:27.094470Z",
     "shell.execute_reply": "2021-02-23T22:55:27.093692Z",
     "shell.execute_reply.started": "2021-02-23T22:55:08.204286Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectPercentile, mutual_info_classif, RFE, RFECV, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import product\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T12:02:21.321878Z",
     "iopub.status.busy": "2021-02-18T12:02:21.321606Z",
     "iopub.status.idle": "2021-02-18T12:02:21.341805Z",
     "shell.execute_reply": "2021-02-18T12:02:21.340473Z",
     "shell.execute_reply.started": "2021-02-18T12:02:21.321852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/Users/LV/Documents/GitHub/Seminar-QM-BA/functions.py'>"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:33:11.105029Z",
     "iopub.status.busy": "2021-02-26T14:33:11.104424Z",
     "iopub.status.idle": "2021-02-26T14:35:04.504522Z",
     "shell.execute_reply": "2021-02-26T14:35:04.499415Z",
     "shell.execute_reply.started": "2021-02-26T14:33:11.104993Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/LV/Desktop/data_bol_complete.csv', low_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:35:04.508867Z",
     "iopub.status.busy": "2021-02-26T14:35:04.508566Z",
     "iopub.status.idle": "2021-02-26T14:35:26.067620Z",
     "shell.execute_reply": "2021-02-26T14:35:26.066992Z",
     "shell.execute_reply.started": "2021-02-26T14:35:04.508836Z"
    }
   },
   "outputs": [],
   "source": [
    "df['orderDate']                   = pd.to_datetime(df['orderDate'])\n",
    "df['cancellationDate']            = pd.to_datetime(df['cancellationDate'])\n",
    "df['promisedDeliveryDate']        = pd.to_datetime(df['promisedDeliveryDate'])\n",
    "df['shipmentDate']                = pd.to_datetime(df['shipmentDate'])\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'])\n",
    "df['startDateCase']               = pd.to_datetime(df['startDateCase'])\n",
    "df['returnDateTime']              = pd.to_datetime(df['returnDateTime'])\n",
    "df['registrationDateSeller']      = pd.to_datetime(df['registrationDateSeller'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:35:26.070130Z",
     "iopub.status.busy": "2021-02-26T14:35:26.069887Z",
     "iopub.status.idle": "2021-02-26T14:35:26.280842Z",
     "shell.execute_reply": "2021-02-26T14:35:26.279914Z",
     "shell.execute_reply.started": "2021-02-26T14:35:26.070105Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate totals per Match Determinant\n",
    "totalCase = df['caseDays'].count()\n",
    "totalReturn = df['returnDays'].count()\n",
    "totalCancel = df['cancellationDays'].count()\n",
    "totalPromisedDelivery = df['promisedDeliveryDays'].count()\n",
    "totalDelivery = df['actualDeliveryDays'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:35:26.284631Z",
     "iopub.status.busy": "2021-02-26T14:35:26.284276Z",
     "iopub.status.idle": "2021-02-26T14:35:26.530091Z",
     "shell.execute_reply": "2021-02-26T14:35:26.529364Z",
     "shell.execute_reply.started": "2021-02-26T14:35:26.284581Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create table for plot\n",
    "periodTable = pd.concat([df['caseDays'].value_counts().sort_index(),\n",
    "                         df['returnDays'].value_counts().sort_index(),\n",
    "                         df['cancellationDays'].value_counts().sort_index(),\n",
    "                         df['promisedDeliveryDays'].value_counts().sort_index(),\n",
    "                         df['actualDeliveryDays'].value_counts().sort_index()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:35:26.532498Z",
     "iopub.status.busy": "2021-02-26T14:35:26.532233Z",
     "iopub.status.idle": "2021-02-26T14:35:26.549978Z",
     "shell.execute_reply": "2021-02-26T14:35:26.548228Z",
     "shell.execute_reply.started": "2021-02-26T14:35:26.532473Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create percantages per day and calculate running sum\n",
    "periodTable['caseDays%'] = (periodTable['caseDays'] / totalCase).cumsum()\n",
    "periodTable['returnDays%'] = (periodTable['returnDays'] / totalReturn).cumsum()\n",
    "periodTable['cancellationDays%'] = (periodTable['cancellationDays'] / totalCancel).cumsum()\n",
    "periodTable['promisedDeliveryDays%'] = (periodTable['promisedDeliveryDays'] / totalPromisedDelivery).cumsum()\n",
    "periodTable['actualDeliveryDays%'] = (periodTable['actualDeliveryDays'] / df.shape[0]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:57:18.556843Z",
     "iopub.status.busy": "2021-02-26T14:57:18.556597Z",
     "iopub.status.idle": "2021-02-26T14:57:18.567970Z",
     "shell.execute_reply": "2021-02-26T14:57:18.566843Z",
     "shell.execute_reply.started": "2021-02-26T14:57:18.556820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.7)(1, 28.2)(2, 50.0)(3, 57.6)(4, 61.5)(5, 62.9)(6, 63.5)(7, 63.8)(8, 64.0)(9, 64.0)(10, 64.1)(11, 64.2)(12, 64.2)(13, 64.2)(14, 64.2)(15, 64.2)(16, 64.2)(17, 64.2)(18, 64.2)(19, 64.2)(20, 64.2)(21, 64.2)(22, 64.2)(23, 64.2)(24, 64.2)(25, 64.2)(26, 64.2)(27, 64.2)(28, 64.2)(29, 64.2)"
     ]
    }
   ],
   "source": [
    "col = periodTable['actualDeliveryDays%']\n",
    "for i in range(30):\n",
    "    if i < 13:\n",
    "        print((i,round(col[i]*100,1)), end = '')\n",
    "    else:\n",
    "        print((i,64.2), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:52:00.101266Z",
     "iopub.status.busy": "2021-02-26T14:52:00.100945Z",
     "iopub.status.idle": "2021-02-26T14:52:00.155063Z",
     "shell.execute_reply": "2021-02-26T14:52:00.153570Z",
     "shell.execute_reply.started": "2021-02-26T14:52:00.101236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseDays</th>\n",
       "      <th>returnDays</th>\n",
       "      <th>cancellationDays</th>\n",
       "      <th>promisedDeliveryDays</th>\n",
       "      <th>actualDeliveryDays</th>\n",
       "      <th>caseDays%</th>\n",
       "      <th>returnDays%</th>\n",
       "      <th>cancellationDays%</th>\n",
       "      <th>promisedDeliveryDays%</th>\n",
       "      <th>actualDeliveryDays%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10221.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>34537.0</td>\n",
       "      <td>35338.0</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.195796</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.007404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20425.0</td>\n",
       "      <td>34083.0</td>\n",
       "      <td>6940.0</td>\n",
       "      <td>1699249.0</td>\n",
       "      <td>1310846.0</td>\n",
       "      <td>0.186459</td>\n",
       "      <td>0.125180</td>\n",
       "      <td>0.488710</td>\n",
       "      <td>0.363252</td>\n",
       "      <td>0.282044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>22459.0</td>\n",
       "      <td>42638.0</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>1319161.0</td>\n",
       "      <td>1041357.0</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.277158</td>\n",
       "      <td>0.600051</td>\n",
       "      <td>0.639635</td>\n",
       "      <td>0.500223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>19048.0</td>\n",
       "      <td>35268.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>592789.0</td>\n",
       "      <td>363063.0</td>\n",
       "      <td>0.438999</td>\n",
       "      <td>0.402866</td>\n",
       "      <td>0.664289</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.576290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>16078.0</td>\n",
       "      <td>28205.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>433153.0</td>\n",
       "      <td>183553.0</td>\n",
       "      <td>0.536822</td>\n",
       "      <td>0.503399</td>\n",
       "      <td>0.730849</td>\n",
       "      <td>0.854584</td>\n",
       "      <td>0.614747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>12818.0</td>\n",
       "      <td>22366.0</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>297018.0</td>\n",
       "      <td>68269.0</td>\n",
       "      <td>0.614810</td>\n",
       "      <td>0.583119</td>\n",
       "      <td>0.807074</td>\n",
       "      <td>0.916814</td>\n",
       "      <td>0.629050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>9714.0</td>\n",
       "      <td>17796.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>34360.0</td>\n",
       "      <td>27708.0</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.646551</td>\n",
       "      <td>0.859410</td>\n",
       "      <td>0.924013</td>\n",
       "      <td>0.634856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7836.0</td>\n",
       "      <td>15306.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>170636.0</td>\n",
       "      <td>14698.0</td>\n",
       "      <td>0.721589</td>\n",
       "      <td>0.701107</td>\n",
       "      <td>0.902503</td>\n",
       "      <td>0.959763</td>\n",
       "      <td>0.637935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>5623.0</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>60228.0</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>0.755801</td>\n",
       "      <td>0.743024</td>\n",
       "      <td>0.941713</td>\n",
       "      <td>0.972382</td>\n",
       "      <td>0.639524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>4301.0</td>\n",
       "      <td>9360.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>34774.0</td>\n",
       "      <td>4443.0</td>\n",
       "      <td>0.781970</td>\n",
       "      <td>0.776386</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.979668</td>\n",
       "      <td>0.640455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>3731.0</td>\n",
       "      <td>7696.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>35359.0</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>0.804670</td>\n",
       "      <td>0.803817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987076</td>\n",
       "      <td>0.641124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>3316.0</td>\n",
       "      <td>6554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13120.0</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>0.824846</td>\n",
       "      <td>0.827178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989825</td>\n",
       "      <td>0.641596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>3067.0</td>\n",
       "      <td>5932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36578.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>0.843506</td>\n",
       "      <td>0.848322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.641888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>2839.0</td>\n",
       "      <td>5496.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860780</td>\n",
       "      <td>0.867912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>2693.0</td>\n",
       "      <td>5153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877164</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>2107.0</td>\n",
       "      <td>4269.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889984</td>\n",
       "      <td>0.901495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>2052.0</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902469</td>\n",
       "      <td>0.914876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>2166.0</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915648</td>\n",
       "      <td>0.927144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>1897.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.927189</td>\n",
       "      <td>0.937649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>1653.0</td>\n",
       "      <td>2564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937247</td>\n",
       "      <td>0.946788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>1537.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946598</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>1459.0</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955475</td>\n",
       "      <td>0.962364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>1158.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962521</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>1060.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968970</td>\n",
       "      <td>0.974597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>909.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974501</td>\n",
       "      <td>0.979320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>882.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979867</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>828.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984905</td>\n",
       "      <td>0.988159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>797.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989754</td>\n",
       "      <td>0.992287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995230</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>784.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      caseDays  returnDays  cancellationDays  promisedDeliveryDays  \\\n",
       "0.0    10221.0      1037.0            4639.0               34537.0   \n",
       "1.0    20425.0     34083.0            6940.0             1699249.0   \n",
       "2.0    22459.0     42638.0            2638.0             1319161.0   \n",
       "3.0    19048.0     35268.0            1522.0              592789.0   \n",
       "4.0    16078.0     28205.0            1577.0              433153.0   \n",
       "5.0    12818.0     22366.0            1806.0              297018.0   \n",
       "6.0     9714.0     17796.0            1240.0               34360.0   \n",
       "7.0     7836.0     15306.0            1021.0              170636.0   \n",
       "8.0     5623.0     11760.0             929.0               60228.0   \n",
       "9.0     4301.0      9360.0             508.0               34774.0   \n",
       "10.0    3731.0      7696.0             873.0               35359.0   \n",
       "11.0    3316.0      6554.0               NaN               13120.0   \n",
       "12.0    3067.0      5932.0               NaN               36578.0   \n",
       "13.0    2839.0      5496.0               NaN                8289.0   \n",
       "14.0    2693.0      5153.0               NaN                1979.0   \n",
       "15.0    2107.0      4269.0               NaN                 999.0   \n",
       "16.0    2052.0      3754.0               NaN                 416.0   \n",
       "17.0    2166.0      3442.0               NaN                 252.0   \n",
       "18.0    1897.0      2947.0               NaN                  10.0   \n",
       "19.0    1653.0      2564.0               NaN                   4.0   \n",
       "20.0    1537.0      2265.0               NaN                   5.0   \n",
       "21.0    1459.0      2105.0               NaN                   6.0   \n",
       "22.0    1158.0      1810.0               NaN                   4.0   \n",
       "23.0    1060.0      1622.0               NaN                   6.0   \n",
       "24.0     909.0      1325.0               NaN                   1.0   \n",
       "25.0     882.0      1277.0               NaN                   2.0   \n",
       "26.0     828.0      1203.0               NaN                   2.0   \n",
       "27.0     797.0      1158.0               NaN                   NaN   \n",
       "28.0     900.0      1150.0               NaN                   2.0   \n",
       "29.0     784.0      1014.0               NaN                  10.0   \n",
       "49.0       NaN         NaN               NaN                   1.0   \n",
       "\n",
       "      actualDeliveryDays  caseDays%  returnDays%  cancellationDays%  \\\n",
       "0.0              35338.0   0.062187     0.003696           0.195796   \n",
       "1.0            1310846.0   0.186459     0.125180           0.488710   \n",
       "2.0            1041357.0   0.323106     0.277158           0.600051   \n",
       "3.0             363063.0   0.438999     0.402866           0.664289   \n",
       "4.0             183553.0   0.536822     0.503399           0.730849   \n",
       "5.0              68269.0   0.614810     0.583119           0.807074   \n",
       "6.0              27708.0   0.673913     0.646551           0.859410   \n",
       "7.0              14698.0   0.721589     0.701107           0.902503   \n",
       "8.0               7583.0   0.755801     0.743024           0.941713   \n",
       "9.0               4443.0   0.781970     0.776386           0.963154   \n",
       "10.0              3196.0   0.804670     0.803817           1.000000   \n",
       "11.0              2251.0   0.824846     0.827178                NaN   \n",
       "12.0              1394.0   0.843506     0.848322                NaN   \n",
       "13.0                 NaN   0.860780     0.867912                NaN   \n",
       "14.0                 NaN   0.877164     0.886279                NaN   \n",
       "15.0                 NaN   0.889984     0.901495                NaN   \n",
       "16.0                 NaN   0.902469     0.914876                NaN   \n",
       "17.0                 NaN   0.915648     0.927144                NaN   \n",
       "18.0                 NaN   0.927189     0.937649                NaN   \n",
       "19.0                 NaN   0.937247     0.946788                NaN   \n",
       "20.0                 NaN   0.946598     0.954861                NaN   \n",
       "21.0                 NaN   0.955475     0.962364                NaN   \n",
       "22.0                 NaN   0.962521     0.968815                NaN   \n",
       "23.0                 NaN   0.968970     0.974597                NaN   \n",
       "24.0                 NaN   0.974501     0.979320                NaN   \n",
       "25.0                 NaN   0.979867     0.983871                NaN   \n",
       "26.0                 NaN   0.984905     0.988159                NaN   \n",
       "27.0                 NaN   0.989754     0.992287                NaN   \n",
       "28.0                 NaN   0.995230     0.996386                NaN   \n",
       "29.0                 NaN   1.000000     1.000000                NaN   \n",
       "49.0                 NaN        NaN          NaN                NaN   \n",
       "\n",
       "      promisedDeliveryDays%  actualDeliveryDays%  \n",
       "0.0                0.007236             0.007404  \n",
       "1.0                0.363252             0.282044  \n",
       "2.0                0.639635             0.500223  \n",
       "3.0                0.763833             0.576290  \n",
       "4.0                0.854584             0.614747  \n",
       "5.0                0.916814             0.629050  \n",
       "6.0                0.924013             0.634856  \n",
       "7.0                0.959763             0.637935  \n",
       "8.0                0.972382             0.639524  \n",
       "9.0                0.979668             0.640455  \n",
       "10.0               0.987076             0.641124  \n",
       "11.0               0.989825             0.641596  \n",
       "12.0               0.997488             0.641888  \n",
       "13.0               0.999225                  NaN  \n",
       "14.0               0.999640                  NaN  \n",
       "15.0               0.999849                  NaN  \n",
       "16.0               0.999936                  NaN  \n",
       "17.0               0.999989                  NaN  \n",
       "18.0               0.999991                  NaN  \n",
       "19.0               0.999992                  NaN  \n",
       "20.0               0.999993                  NaN  \n",
       "21.0               0.999994                  NaN  \n",
       "22.0               0.999995                  NaN  \n",
       "23.0               0.999996                  NaN  \n",
       "24.0               0.999996                  NaN  \n",
       "25.0               0.999997                  NaN  \n",
       "26.0               0.999997                  NaN  \n",
       "27.0                    NaN                  NaN  \n",
       "28.0               0.999998                  NaN  \n",
       "29.0               1.000000                  NaN  \n",
       "49.0               1.000000                  NaN  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periodTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:24:24.050673Z",
     "iopub.status.busy": "2021-02-24T20:24:24.048805Z",
     "iopub.status.idle": "2021-02-24T20:24:24.083590Z",
     "shell.execute_reply": "2021-02-24T20:24:24.081558Z",
     "shell.execute_reply.started": "2021-02-24T20:24:24.050578Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "DATE = ['orderDate']\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength','promisedDeliveryDays','partnerSellingDays', 'orderCorona']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "YEAR = ['orderYear2020']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "HISTORICX = []\n",
    "historic_variable = ['transporterCode','sellerId','productGroup']\n",
    "for x in range(len(historic_variable)):\n",
    "    HISTORICX = HISTORICX + [historic_variable[x]+'HistoricHappyX',historic_variable[x]+'HistoricUnhappyX',historic_variable[x]+'HistoricUnknownX']\n",
    "\n",
    "#Determinants:\n",
    "DETERMINANT = ['noReturn', 'noCase', 'noCancellation', 'onTimeDelivery']\n",
    "\n",
    "#Classifications\n",
    "CLASSIFICATION = ['generalMatchClassification','detailedMatchClassification','binaryMatchClassification','determinantClassification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:24:24.510886Z",
     "iopub.status.busy": "2021-02-24T20:24:24.510622Z",
     "iopub.status.idle": "2021-02-24T20:24:24.517050Z",
     "shell.execute_reply": "2021-02-24T20:24:24.515490Z",
     "shell.execute_reply.started": "2021-02-24T20:24:24.510850Z"
    }
   },
   "outputs": [],
   "source": [
    "X_col = BASIC + WEEK + MONTH + YEAR + GROUP + TRANSPORTERX + KNOWNX + PRODUCTX + SELLERX + HISTORICX\n",
    "Y_col = ['detailedMatchClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T21:07:12.927452Z",
     "iopub.status.busy": "2021-02-26T21:07:12.927164Z",
     "iopub.status.idle": "2021-02-26T21:07:25.596622Z",
     "shell.execute_reply": "2021-02-26T21:07:25.592830Z",
     "shell.execute_reply.started": "2021-02-26T21:07:12.927427Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = df.sample(n = 100000, replace = False, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:24:33.146819Z",
     "iopub.status.busy": "2021-02-24T20:24:33.146548Z",
     "iopub.status.idle": "2021-02-24T20:24:50.393511Z",
     "shell.execute_reply": "2021-02-24T20:24:50.390304Z",
     "shell.execute_reply.started": "2021-02-24T20:24:33.146795Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_ contains a sample of training + validation data\n",
    "random.seed(100)\n",
    "df_ = df.iloc[:int(0.8*len(df))].sample(n=1100000, replace=False, random_state=1).sort_values(by = 'orderDate').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:24:50.401425Z",
     "iopub.status.busy": "2021-02-24T20:24:50.400070Z",
     "iopub.status.idle": "2021-02-24T20:24:50.510963Z",
     "shell.execute_reply": "2021-02-24T20:24:50.509739Z",
     "shell.execute_reply.started": "2021-02-24T20:24:50.401369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderDate</th>\n",
       "      <th>productId</th>\n",
       "      <th>sellerId</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>quantityOrdered</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>cancellationDate</th>\n",
       "      <th>cancellationReasonCode</th>\n",
       "      <th>promisedDeliveryDate</th>\n",
       "      <th>shipmentDate</th>\n",
       "      <th>transporterCode</th>\n",
       "      <th>transporterName</th>\n",
       "      <th>transporterNameOther</th>\n",
       "      <th>dateTimeFirstDeliveryMoment</th>\n",
       "      <th>fulfilmentType</th>\n",
       "      <th>startDateCase</th>\n",
       "      <th>cntDistinctCaseIds</th>\n",
       "      <th>returnDateTime</th>\n",
       "      <th>quantityReturned</th>\n",
       "      <th>returnCode</th>\n",
       "      <th>productTitle</th>\n",
       "      <th>brickName</th>\n",
       "      <th>chunkName</th>\n",
       "      <th>productGroup</th>\n",
       "      <th>productSubGroup</th>\n",
       "      <th>productSubSubGroup</th>\n",
       "      <th>registrationDateSeller</th>\n",
       "      <th>countryOriginSeller</th>\n",
       "      <th>currentCountryAvailabilitySeller</th>\n",
       "      <th>calculationDefinitive</th>\n",
       "      <th>noCancellation</th>\n",
       "      <th>onTimeDelivery</th>\n",
       "      <th>noCase</th>\n",
       "      <th>hasOneCase</th>\n",
       "      <th>hasMoreCases</th>\n",
       "      <th>noReturn</th>\n",
       "      <th>detailedMatchClassification</th>\n",
       "      <th>generalMatchClassification</th>\n",
       "      <th>caseDays</th>\n",
       "      <th>returnDays</th>\n",
       "      <th>cancellationDays</th>\n",
       "      <th>actualDeliveryDays</th>\n",
       "      <th>shipmentDays</th>\n",
       "      <th>partnerSellingDays</th>\n",
       "      <th>promisedDeliveryDays</th>\n",
       "      <th>orderYear</th>\n",
       "      <th>orderMonth</th>\n",
       "      <th>orderWeekday</th>\n",
       "      <th>orderCorona</th>\n",
       "      <th>orderMonday</th>\n",
       "      <th>orderTuesday</th>\n",
       "      <th>orderWednesday</th>\n",
       "      <th>orderThursday</th>\n",
       "      <th>orderFriday</th>\n",
       "      <th>orderSaturday</th>\n",
       "      <th>orderSunday</th>\n",
       "      <th>orderJanuary</th>\n",
       "      <th>orderFebruary</th>\n",
       "      <th>orderMarch</th>\n",
       "      <th>orderApril</th>\n",
       "      <th>orderMay</th>\n",
       "      <th>orderJune</th>\n",
       "      <th>orderJuly</th>\n",
       "      <th>orderAugust</th>\n",
       "      <th>orderSeptember</th>\n",
       "      <th>orderOctober</th>\n",
       "      <th>orderNovember</th>\n",
       "      <th>orderDecember</th>\n",
       "      <th>orderYear2020</th>\n",
       "      <th>productTitleLength</th>\n",
       "      <th>fulfilmentByBol</th>\n",
       "      <th>countryCodeNL</th>\n",
       "      <th>countryOriginNL</th>\n",
       "      <th>countryOriginBE</th>\n",
       "      <th>countryOriginDE</th>\n",
       "      <th>determinantClassification</th>\n",
       "      <th>binaryMatchClassification</th>\n",
       "      <th>transporterCodeGeneral</th>\n",
       "      <th>productGroupGeneral</th>\n",
       "      <th>groupHealth</th>\n",
       "      <th>groupHome</th>\n",
       "      <th>groupSports</th>\n",
       "      <th>groupComputer</th>\n",
       "      <th>groupPets</th>\n",
       "      <th>groupToys</th>\n",
       "      <th>groupBooks</th>\n",
       "      <th>groupBaby</th>\n",
       "      <th>groupMusic</th>\n",
       "      <th>groupFood</th>\n",
       "      <th>groupOffice</th>\n",
       "      <th>groupFashion</th>\n",
       "      <th>groupOther</th>\n",
       "      <th>groupCar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000084842057</td>\n",
       "      <td>1003805</td>\n",
       "      <td>3.662279</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 10:54:16</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YONO Aroma Diffuser Luchtbevochtiger 400ml – V...</td>\n",
       "      <td>Oliediffusors (Niet-elektrisch)</td>\n",
       "      <td>Aromadiffuser</td>\n",
       "      <td>Health PG</td>\n",
       "      <td>Ontspanning</td>\n",
       "      <td>Aromatherapie</td>\n",
       "      <td>2014-11-10</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1513</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>155</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Health &amp; Care</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000102226038</td>\n",
       "      <td>1377785</td>\n",
       "      <td>2.638343</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 08:41:01</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby fruitspeen – Gezonde speen – Roze – Duopack</td>\n",
       "      <td>Fopspenen/Bijtringen</td>\n",
       "      <td>Fopspeen</td>\n",
       "      <td>Baby PG</td>\n",
       "      <td>Eten en Drinken Baby</td>\n",
       "      <td>Babyvoeding Accessoires</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Baby &amp; Kids</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000082827166</td>\n",
       "      <td>1159544</td>\n",
       "      <td>2.830268</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT_BRIEF</td>\n",
       "      <td>PostNL Briefpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 14:13:40</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fosco Zakmes - Zwart - 19.5cm - 100% Metaal</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Camping and Outdoor</td>\n",
       "      <td>Outdooruitrusting</td>\n",
       "      <td>Outdooruitrusting</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1025</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>BRIEF</td>\n",
       "      <td>Sports, Outdoor &amp; Travel</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000086651881</td>\n",
       "      <td>1134056</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 07:20:01</td>\n",
       "      <td>FBR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Premium Starter Kit XL voor Nintendo Switch (m...</td>\n",
       "      <td>Spelcomputer – Accessoires</td>\n",
       "      <td>Console start- of accessoirepakket</td>\n",
       "      <td>Games Accessories</td>\n",
       "      <td>Games Accessories</td>\n",
       "      <td>Games Accessories</td>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1114</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>153</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Music, Film &amp; Games</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000043474064</td>\n",
       "      <td>829931</td>\n",
       "      <td>2.297573</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>BRIEFPOST</td>\n",
       "      <td>Briefpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FBR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zwart S-line TPU hoesje LG G4</td>\n",
       "      <td>Hoesjes voor Mobiele Telefoon</td>\n",
       "      <td>Hoesje voor mobiele telefoon</td>\n",
       "      <td>Telephone and Tablet Accessories</td>\n",
       "      <td>Telefonie en Tablet Bescherming</td>\n",
       "      <td>Telefonie Bescherming</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown delivery</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BRIEF</td>\n",
       "      <td>Computer &amp; Electronics</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orderDate         productId  sellerId  totalPrice  quantityOrdered  \\\n",
       "0 2019-01-01  9200000084842057   1003805    3.662279                1   \n",
       "1 2019-01-01  9200000102226038   1377785    2.638343                1   \n",
       "2 2019-01-01  9200000082827166   1159544    2.830268                1   \n",
       "3 2019-01-01  9200000086651881   1134056    3.314186                1   \n",
       "4 2019-01-01  9200000043474064    829931    2.297573                1   \n",
       "\n",
       "  countryCode cancellationDate cancellationReasonCode promisedDeliveryDate  \\\n",
       "0          BE              NaT                    NaN           2019-01-03   \n",
       "1          NL              NaT                    NaN           2019-01-03   \n",
       "2          NL              NaT                    NaN           2019-01-08   \n",
       "3          NL              NaT                    NaN           2019-01-03   \n",
       "4          NL              NaT                    NaN           2019-01-03   \n",
       "\n",
       "  shipmentDate transporterCode   transporterName transporterNameOther  \\\n",
       "0   2019-01-02             TNT            PostNL                  NaN   \n",
       "1   2019-01-02             TNT            PostNL                  NaN   \n",
       "2   2019-01-02       TNT_BRIEF  PostNL Briefpost                  NaN   \n",
       "3   2019-01-02             TNT            PostNL                  NaN   \n",
       "4   2019-01-02       BRIEFPOST         Briefpost                  NaN   \n",
       "\n",
       "  dateTimeFirstDeliveryMoment fulfilmentType startDateCase  \\\n",
       "0         2019-01-03 10:54:16            FBB           NaT   \n",
       "1         2019-01-03 08:41:01            FBB           NaT   \n",
       "2         2019-01-03 14:13:40            FBB           NaT   \n",
       "3         2019-01-03 07:20:01            FBR           NaT   \n",
       "4                         NaT            FBR           NaT   \n",
       "\n",
       "   cntDistinctCaseIds returnDateTime  quantityReturned returnCode  \\\n",
       "0                 NaN            NaT               NaN        NaN   \n",
       "1                 NaN            NaT               NaN        NaN   \n",
       "2                 NaN            NaT               NaN        NaN   \n",
       "3                 NaN            NaT               NaN        NaN   \n",
       "4                 NaN            NaT               NaN        NaN   \n",
       "\n",
       "                                        productTitle  \\\n",
       "0  YONO Aroma Diffuser Luchtbevochtiger 400ml – V...   \n",
       "1   Baby fruitspeen – Gezonde speen – Roze – Duopack   \n",
       "2        Fosco Zakmes - Zwart - 19.5cm - 100% Metaal   \n",
       "3  Premium Starter Kit XL voor Nintendo Switch (m...   \n",
       "4                      Zwart S-line TPU hoesje LG G4   \n",
       "\n",
       "                         brickName                           chunkName  \\\n",
       "0  Oliediffusors (Niet-elektrisch)                       Aromadiffuser   \n",
       "1             Fopspenen/Bijtringen                            Fopspeen   \n",
       "2    Hobbymessen (Niet-elektrisch)                              Zakmes   \n",
       "3       Spelcomputer – Accessoires  Console start- of accessoirepakket   \n",
       "4    Hoesjes voor Mobiele Telefoon        Hoesje voor mobiele telefoon   \n",
       "\n",
       "                       productGroup                  productSubGroup  \\\n",
       "0                         Health PG                      Ontspanning   \n",
       "1                           Baby PG             Eten en Drinken Baby   \n",
       "2               Camping and Outdoor                Outdooruitrusting   \n",
       "3                 Games Accessories                Games Accessories   \n",
       "4  Telephone and Tablet Accessories  Telefonie en Tablet Bescherming   \n",
       "\n",
       "        productSubSubGroup registrationDateSeller countryOriginSeller  \\\n",
       "0            Aromatherapie             2014-11-10                  NL   \n",
       "1  Babyvoeding Accessoires             2018-08-12                  NL   \n",
       "2        Outdooruitrusting             2016-03-12                  NL   \n",
       "3        Games Accessories             2015-12-14                  NL   \n",
       "4    Telefonie Bescherming             2013-07-31                  NL   \n",
       "\n",
       "  currentCountryAvailabilitySeller  calculationDefinitive  noCancellation  \\\n",
       "0                               NL                   True            True   \n",
       "1                               NL                   True            True   \n",
       "2                               NL                   True            True   \n",
       "3                               NL                   True            True   \n",
       "4                               NL                   True            True   \n",
       "\n",
       "  onTimeDelivery  noCase  hasOneCase  hasMoreCases  noReturn  \\\n",
       "0           True    True         0.0           0.0      True   \n",
       "1           True    True         0.0           0.0      True   \n",
       "2           True    True         0.0           0.0      True   \n",
       "3           True    True         0.0           0.0      True   \n",
       "4            NaN    True         0.0           0.0      True   \n",
       "\n",
       "  detailedMatchClassification generalMatchClassification  caseDays  \\\n",
       "0                       HAPPY                      HAPPY       NaN   \n",
       "1                       HAPPY                      HAPPY       NaN   \n",
       "2                       HAPPY                      HAPPY       NaN   \n",
       "3                       HAPPY                      HAPPY       NaN   \n",
       "4                     UNKNOWN                    UNKNOWN       NaN   \n",
       "\n",
       "   returnDays  cancellationDays  actualDeliveryDays  shipmentDays  \\\n",
       "0         NaN               NaN                 2.0           1.0   \n",
       "1         NaN               NaN                 2.0           1.0   \n",
       "2         NaN               NaN                 2.0           1.0   \n",
       "3         NaN               NaN                 2.0           1.0   \n",
       "4         NaN               NaN                 NaN           1.0   \n",
       "\n",
       "   partnerSellingDays  promisedDeliveryDays  orderYear  orderMonth  \\\n",
       "0                1513                     2       2019           1   \n",
       "1                 142                     2       2019           1   \n",
       "2                1025                     7       2019           1   \n",
       "3                1114                     2       2019           1   \n",
       "4                1980                     2       2019           1   \n",
       "\n",
       "   orderWeekday  orderCorona  orderMonday  orderTuesday  orderWednesday  \\\n",
       "0             1        False        False          True           False   \n",
       "1             1        False        False          True           False   \n",
       "2             1        False        False          True           False   \n",
       "3             1        False        False          True           False   \n",
       "4             1        False        False          True           False   \n",
       "\n",
       "   orderThursday  orderFriday  orderSaturday  orderSunday  orderJanuary  \\\n",
       "0          False        False          False        False          True   \n",
       "1          False        False          False        False          True   \n",
       "2          False        False          False        False          True   \n",
       "3          False        False          False        False          True   \n",
       "4          False        False          False        False          True   \n",
       "\n",
       "   orderFebruary  orderMarch  orderApril  orderMay  orderJune  orderJuly  \\\n",
       "0          False       False       False     False      False      False   \n",
       "1          False       False       False     False      False      False   \n",
       "2          False       False       False     False      False      False   \n",
       "3          False       False       False     False      False      False   \n",
       "4          False       False       False     False      False      False   \n",
       "\n",
       "   orderAugust  orderSeptember  orderOctober  orderNovember  orderDecember  \\\n",
       "0        False           False         False          False          False   \n",
       "1        False           False         False          False          False   \n",
       "2        False           False         False          False          False   \n",
       "3        False           False         False          False          False   \n",
       "4        False           False         False          False          False   \n",
       "\n",
       "   orderYear2020  productTitleLength  fulfilmentByBol  countryCodeNL  \\\n",
       "0          False                 155             True          False   \n",
       "1          False                  48             True           True   \n",
       "2          False                  43             True           True   \n",
       "3          False                 153            False           True   \n",
       "4          False                  29            False           True   \n",
       "\n",
       "   countryOriginNL  countryOriginBE  countryOriginDE  \\\n",
       "0             True            False            False   \n",
       "1             True            False            False   \n",
       "2             True            False            False   \n",
       "3             True            False            False   \n",
       "4             True            False            False   \n",
       "\n",
       "  determinantClassification binaryMatchClassification transporterCodeGeneral  \\\n",
       "0                  All good                     KNOWN                 POSTNL   \n",
       "1                  All good                     KNOWN                 POSTNL   \n",
       "2                  All good                     KNOWN                  BRIEF   \n",
       "3                  All good                     KNOWN                 POSTNL   \n",
       "4          Unknown delivery                   UNKNOWN                  BRIEF   \n",
       "\n",
       "        productGroupGeneral  groupHealth  groupHome  groupSports  \\\n",
       "0             Health & Care         True      False        False   \n",
       "1               Baby & Kids        False      False        False   \n",
       "2  Sports, Outdoor & Travel        False      False         True   \n",
       "3       Music, Film & Games        False      False        False   \n",
       "4    Computer & Electronics        False      False        False   \n",
       "\n",
       "   groupComputer  groupPets  groupToys  groupBooks  groupBaby  groupMusic  \\\n",
       "0          False      False      False       False      False       False   \n",
       "1          False      False      False       False       True       False   \n",
       "2          False      False      False       False      False       False   \n",
       "3          False      False      False       False      False        True   \n",
       "4           True      False      False       False      False       False   \n",
       "\n",
       "   groupFood  groupOffice  groupFashion  groupOther  groupCar  \n",
       "0      False        False         False       False     False  \n",
       "1      False        False         False       False     False  \n",
       "2      False        False         False       False     False  \n",
       "3      False        False         False       False     False  \n",
       "4      False        False         False       False     False  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:27:36.613118Z",
     "iopub.status.busy": "2021-02-24T20:27:36.612825Z",
     "iopub.status.idle": "2021-02-24T20:27:36.620102Z",
     "shell.execute_reply": "2021-02-24T20:27:36.618385Z",
     "shell.execute_reply.started": "2021-02-24T20:27:36.613086Z"
    }
   },
   "outputs": [],
   "source": [
    "Tree = ClassHierarchy('ORDERS')\n",
    "Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "# combinations = [('RF','DT','NN'),('DT','RF','NN'),\n",
    "#                 ('RF','DT','DT'),('DT','RF','DT'),\n",
    "#                 ('RF','DT','RF'),('DT','RF','RF')]\n",
    "\n",
    "combinations = [('LR','RF','RF'),('RF','LR','LR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T09:54:32.864251Z",
     "iopub.status.busy": "2021-02-26T09:54:32.862345Z",
     "iopub.status.idle": "2021-02-26T09:54:32.888097Z",
     "shell.execute_reply": "2021-02-26T09:54:32.883764Z",
     "shell.execute_reply.started": "2021-02-26T09:54:32.864157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,11):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T08:31:20.055572Z",
     "iopub.status.busy": "2021-02-19T08:31:20.055018Z",
     "iopub.status.idle": "2021-02-19T08:31:52.407681Z",
     "shell.execute_reply": "2021-02-19T08:31:52.406890Z",
     "shell.execute_reply.started": "2021-02-19T08:31:20.055511Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_preBurn, y_preBurn = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 0)\n",
    "index = range(0, X_preBurn.shape[0])\n",
    "\n",
    "X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "#X_train_val = X.iloc[0:int(0.75*len(X))]\n",
    "X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "       \n",
    "#y_train_val = y.iloc[0:int(0.75*len(y))]\n",
    "y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "\n",
    "#X_test_full = X.iloc[int(0.75*len(X)):]\n",
    "#y_test_full = y.iloc[int(0.75*len(y)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T09:56:09.891484Z",
     "iopub.status.busy": "2021-02-26T09:56:09.891191Z",
     "iopub.status.idle": "2021-02-26T14:22:15.575481Z",
     "shell.execute_reply": "2021-02-26T14:22:15.567619Z",
     "shell.execute_reply.started": "2021-02-26T09:56:09.891459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [39:10<00:00, 117.53s/trial, best loss: -0.9852817062604355]\n",
      "100%|██████████| 20/20 [3:45:08<00:00, 675.44s/trial, best loss: -0.9804503807902645]  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "output = {}\n",
    "\n",
    "for DAY in range(10,11):\n",
    "    \n",
    "    X_preBurn, y_preBurn = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAY)\n",
    "    index = range(0, X_preBurn.shape[0])\n",
    "\n",
    "    X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "    y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "    #X_train_val = X.iloc[0:int(0.75*len(X))]\n",
    "    X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "    X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "\n",
    "    #y_train_val = y.iloc[0:int(0.75*len(y))]\n",
    "    y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "    y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "\n",
    "    #X_test_full = X.iloc[int(0.75*len(X)):]\n",
    "    #y_test_full = y.iloc[int(0.75*len(y)):]\n",
    "\n",
    "    output[DAY] = {}\n",
    "\n",
    "    for combination in combinations:\n",
    "\n",
    "        best_param, f1, accuracy = hyperopt(get_hyperspace(combination), X_train, y_train, X_val, y_val, 20)\n",
    "\n",
    "        output[DAY][str(combination)] = (DAY, best_param, f1, accuracy)\n",
    "\n",
    "        with open('/Users/LV/Desktop/validationPart3.json', 'w') as f:\n",
    "            json.dump(output, f, cls = NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T11:15:33.450204Z",
     "iopub.status.busy": "2021-02-21T11:15:33.448320Z",
     "iopub.status.idle": "2021-02-21T11:15:33.510769Z",
     "shell.execute_reply": "2021-02-21T11:15:33.509102Z",
     "shell.execute_reply.started": "2021-02-21T11:15:33.450093Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/LV/Desktop/Validation/validation1.json') as f:\n",
    "    results1 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Validation/validation2.json') as f:\n",
    "    results2 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Validation/validation3.json') as f:\n",
    "    results3 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Validation/validation4.json') as f:\n",
    "    results4 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-21T12:14:17.662425Z",
     "iopub.status.busy": "2021-02-21T12:14:17.662130Z",
     "iopub.status.idle": "2021-02-21T12:14:17.820882Z",
     "shell.execute_reply": "2021-02-21T12:14:17.820156Z",
     "shell.execute_reply.started": "2021-02-21T12:14:17.662398Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'DT')</th>\n",
       "      <td>0.854815</td>\n",
       "      <td>0.876907</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.920188</td>\n",
       "      <td>0.936639</td>\n",
       "      <td>0.954157</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>0.971652</td>\n",
       "      <td>0.976273</td>\n",
       "      <td>0.980445</td>\n",
       "      <td>0.981540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'RF')</th>\n",
       "      <td>0.851265</td>\n",
       "      <td>0.871202</td>\n",
       "      <td>0.896070</td>\n",
       "      <td>0.921924</td>\n",
       "      <td>0.937989</td>\n",
       "      <td>0.954333</td>\n",
       "      <td>0.963244</td>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.976259</td>\n",
       "      <td>0.977721</td>\n",
       "      <td>0.981673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'RF')</th>\n",
       "      <td>0.851975</td>\n",
       "      <td>0.879984</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.920837</td>\n",
       "      <td>0.942735</td>\n",
       "      <td>0.955765</td>\n",
       "      <td>0.967191</td>\n",
       "      <td>0.974183</td>\n",
       "      <td>0.979108</td>\n",
       "      <td>0.981989</td>\n",
       "      <td>0.984803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'DT')</th>\n",
       "      <td>0.845037</td>\n",
       "      <td>0.865596</td>\n",
       "      <td>0.896348</td>\n",
       "      <td>0.914484</td>\n",
       "      <td>0.939641</td>\n",
       "      <td>0.954634</td>\n",
       "      <td>0.964196</td>\n",
       "      <td>0.970961</td>\n",
       "      <td>0.975027</td>\n",
       "      <td>0.978087</td>\n",
       "      <td>0.981287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'DT')</th>\n",
       "      <td>0.849603</td>\n",
       "      <td>0.881825</td>\n",
       "      <td>0.899603</td>\n",
       "      <td>0.921985</td>\n",
       "      <td>0.942769</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.973198</td>\n",
       "      <td>0.977740</td>\n",
       "      <td>0.980778</td>\n",
       "      <td>0.983854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'RF')</th>\n",
       "      <td>0.840994</td>\n",
       "      <td>0.863138</td>\n",
       "      <td>0.891179</td>\n",
       "      <td>0.914802</td>\n",
       "      <td>0.939100</td>\n",
       "      <td>0.954785</td>\n",
       "      <td>0.965408</td>\n",
       "      <td>0.971422</td>\n",
       "      <td>0.976147</td>\n",
       "      <td>0.979192</td>\n",
       "      <td>0.981252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'DT')</th>\n",
       "      <td>0.843224</td>\n",
       "      <td>0.866109</td>\n",
       "      <td>0.895169</td>\n",
       "      <td>0.916512</td>\n",
       "      <td>0.939995</td>\n",
       "      <td>0.955726</td>\n",
       "      <td>0.966212</td>\n",
       "      <td>0.973129</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.980805</td>\n",
       "      <td>0.983939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'RF')</th>\n",
       "      <td>0.839108</td>\n",
       "      <td>0.862149</td>\n",
       "      <td>0.892034</td>\n",
       "      <td>0.918828</td>\n",
       "      <td>0.940897</td>\n",
       "      <td>0.957314</td>\n",
       "      <td>0.967233</td>\n",
       "      <td>0.974205</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.982009</td>\n",
       "      <td>0.984831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1         2         3         4  \\\n",
       "('RF', 'DT', 'DT')  0.854815  0.876907  0.894954  0.920188  0.936639   \n",
       "('RF', 'DT', 'RF')  0.851265  0.871202  0.896070  0.921924  0.937989   \n",
       "('DT', 'DT', 'RF')  0.851975  0.879984  0.899471  0.920837  0.942735   \n",
       "('RF', 'RF', 'DT')  0.845037  0.865596  0.896348  0.914484  0.939641   \n",
       "('DT', 'DT', 'DT')  0.849603  0.881825  0.899603  0.921985  0.942769   \n",
       "('RF', 'RF', 'RF')  0.840994  0.863138  0.891179  0.914802  0.939100   \n",
       "('DT', 'RF', 'DT')  0.843224  0.866109  0.895169  0.916512  0.939995   \n",
       "('DT', 'RF', 'RF')  0.839108  0.862149  0.892034  0.918828  0.940897   \n",
       "\n",
       "                           5         6         7         8         9        10  \n",
       "('RF', 'DT', 'DT')  0.954157  0.966417  0.971652  0.976273  0.980445  0.981540  \n",
       "('RF', 'DT', 'RF')  0.954333  0.963244  0.968697  0.976259  0.977721  0.981673  \n",
       "('DT', 'DT', 'RF')  0.955765  0.967191  0.974183  0.979108  0.981989  0.984803  \n",
       "('RF', 'RF', 'DT')  0.954634  0.964196  0.970961  0.975027  0.978087  0.981287  \n",
       "('DT', 'DT', 'DT')  0.956585  0.966699  0.973198  0.977740  0.980778  0.983854  \n",
       "('RF', 'RF', 'RF')  0.954785  0.965408  0.971422  0.976147  0.979192  0.981252  \n",
       "('DT', 'RF', 'DT')  0.955726  0.966212  0.973129  0.978035  0.980805  0.983939  \n",
       "('DT', 'RF', 'RF')  0.957314  0.967233  0.974205  0.979100  0.982009  0.984831  "
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame.from_dict(results1)\n",
    "results_df2 = pd.DataFrame.from_dict(results2)\n",
    "results_df3 = pd.DataFrame.from_dict(results3)\n",
    "results_df4 = pd.DataFrame.from_dict(results4)\n",
    "for i in range(11):\n",
    "    results_df1[str(i)] = results_df1[str(i)].apply(lambda x: x[2])\n",
    "    results_df2[str(i)] = results_df2[str(i)].apply(lambda x: x[2])\n",
    "    results_df3[str(i)] = results_df3[str(i)].apply(lambda x: x[1])\n",
    "    results_df4[str(i)] = results_df4[str(i)].apply(lambda x: x[2])\n",
    "results_df = pd.concat([results_df1,results_df2,results_df3,results_df4])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-21T12:08:56.509253Z",
     "iopub.status.busy": "2021-02-21T12:08:56.508999Z",
     "iopub.status.idle": "2021-02-21T12:08:56.655176Z",
     "shell.execute_reply": "2021-02-21T12:08:56.650017Z",
     "shell.execute_reply.started": "2021-02-21T12:08:56.509230Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'DT')</th>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'RF')</th>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'RF')</th>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'DT')</th>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 14.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 6.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'DT')</th>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'RF')</th>\n",
       "      <td>{'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...</td>\n",
       "      <td>{'RF_max_depth_0': 12.0, 'RF_max_depth_1': 11....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...</td>\n",
       "      <td>{'RF_max_depth_0': 14.0, 'RF_max_depth_1': 9.0...</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 10.0, 'RF_max_depth_1': 9.0...</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'DT')</th>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 0, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'RF')</th>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_max_depth_0': 14.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...   \n",
       "\n",
       "                                                                    1  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 0, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 12.0, 'RF_max_depth_1': 11....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...   \n",
       "\n",
       "                                                                    2  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...   \n",
       "\n",
       "                                                                    3  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 9.0, '...   \n",
       "\n",
       "                                                                    4  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 14.0, 'RF_max_depth_1': 9.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 0, 'DT_max_depth_0': 14.0, ...   \n",
       "\n",
       "                                                                    5  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...   \n",
       "\n",
       "                                                                    6  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...   \n",
       "\n",
       "                                                                    7  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 14.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...   \n",
       "\n",
       "                                                                    8  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 10.0, 'RF_max_depth_1': 9.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...   \n",
       "\n",
       "                                                                    9  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...   \n",
       "\n",
       "                                                                   10  \n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...  \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...  \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...  \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 6.0, '...  \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...  \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....  \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 0, 'DT...  \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...  "
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame.from_dict(results1)\n",
    "results_df2 = pd.DataFrame.from_dict(results2)\n",
    "results_df3 = pd.DataFrame.from_dict(results3)\n",
    "results_df4 = pd.DataFrame.from_dict(results4)\n",
    "for i in range(11):\n",
    "    results_df1[str(i)] = results_df1[str(i)].apply(lambda x: x[1])\n",
    "    results_df2[str(i)] = results_df2[str(i)].apply(lambda x: x[1])\n",
    "    results_df3[str(i)] = results_df3[str(i)].apply(lambda x: x[0])\n",
    "    results_df4[str(i)] = results_df4[str(i)].apply(lambda x: x[1])\n",
    "hypers_df = pd.concat([results_df1,results_df2,results_df3,results_df4])\n",
    "hypers_df\n",
    "#DTDTRF = hypers_df.reset_index().loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Hierarchy Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T13:54:54.032061Z",
     "iopub.status.busy": "2021-02-14T13:54:54.029871Z",
     "iopub.status.idle": "2021-02-14T13:54:54.062616Z",
     "shell.execute_reply": "2021-02-14T13:54:54.050111Z",
     "shell.execute_reply.started": "2021-02-14T13:54:54.031976Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "# classifier = RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = 10)\n",
    "# classifier = svm.LinearSVC(C=1, penalty=\"l1\", dual=False, class_weight = 'balanced')\n",
    "# classifier = HistGradientBoostingClassifier(random_state=0)\n",
    "# classifier = DecisionTreeClassifier(random_state=0, max_depth=10, class_weight='balanced')\n",
    "# classifier = KerasClassifier(build_fn = functions.neuralNetwork,epochs = 10,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T15:42:42.945736Z",
     "iopub.status.busy": "2021-02-24T15:42:42.945498Z",
     "iopub.status.idle": "2021-02-24T15:42:42.965706Z",
     "shell.execute_reply": "2021-02-24T15:42:42.964230Z",
     "shell.execute_reply.started": "2021-02-24T15:42:42.945713Z"
    }
   },
   "outputs": [],
   "source": [
    "Tree = ClassHierarchy('ORDERS')\n",
    "Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "HC = HierarchicalClassifier(Tree)\n",
    "# HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "#                     'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "#                     'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = 40, max_depth = 10)})\n",
    "HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced'),\n",
    "                            'KNOWN'   : LogisticRegression(random_state=0, class_weight='balanced'),\n",
    "                            'UNHAPPY' : LogisticRegression(random_state=0, class_weight='balanced')})\n",
    "\n",
    "THRESHOLDS = {'KNOWN'          :0.95,\n",
    "              'UNKNOWN'        :0.95,\n",
    "              'HAPPY'          :0.7,\n",
    "              'UNHAPPY'        :0.7,\n",
    "              'HEAVILY UNHAPPY':0.7,\n",
    "              'MEDIUM UNHAPPY' :0.8,\n",
    "              'MILDLY UNHAPPY' :0.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Single fit single point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T15:42:46.256732Z",
     "iopub.status.busy": "2021-02-24T15:42:46.256475Z",
     "iopub.status.idle": "2021-02-24T15:42:53.120397Z",
     "shell.execute_reply": "2021-02-24T15:42:53.119669Z",
     "shell.execute_reply.started": "2021-02-24T15:42:46.256709Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 0)\n",
    "index = range(0, X.shape[0])\n",
    "X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size = 0.2, random_state = 0, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T15:42:56.195458Z",
     "iopub.status.busy": "2021-02-24T15:42:56.195200Z",
     "iopub.status.idle": "2021-02-24T15:43:03.464818Z",
     "shell.execute_reply": "2021-02-24T15:43:03.463335Z",
     "shell.execute_reply.started": "2021-02-24T15:42:56.195433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDERS</th>\n",
       "      <th>KNOWN</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>HAPPY</th>\n",
       "      <th>UNHAPPY</th>\n",
       "      <th>HEAVILY UNHAPPY</th>\n",
       "      <th>MEDIUM UNHAPPY</th>\n",
       "      <th>MILDLY UNHAPPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973726</td>\n",
       "      <td>0.026274</td>\n",
       "      <td>0.674793</td>\n",
       "      <td>0.325207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907652</td>\n",
       "      <td>0.092348</td>\n",
       "      <td>0.553734</td>\n",
       "      <td>0.446266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972427</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>0.666976</td>\n",
       "      <td>0.333024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973924</td>\n",
       "      <td>0.026076</td>\n",
       "      <td>0.643522</td>\n",
       "      <td>0.356478</td>\n",
       "      <td>0.131056</td>\n",
       "      <td>0.236707</td>\n",
       "      <td>0.632237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444113</td>\n",
       "      <td>0.555887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962158</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.667667</td>\n",
       "      <td>0.332333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.137679</td>\n",
       "      <td>0.862321</td>\n",
       "      <td>0.811409</td>\n",
       "      <td>0.111217</td>\n",
       "      <td>0.077374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976305</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>0.672058</td>\n",
       "      <td>0.327942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105306</td>\n",
       "      <td>0.894694</td>\n",
       "      <td>0.177532</td>\n",
       "      <td>0.822468</td>\n",
       "      <td>0.382414</td>\n",
       "      <td>0.431204</td>\n",
       "      <td>0.186381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>0.913570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ORDERS     KNOWN   UNKNOWN     HAPPY   UNHAPPY  HEAVILY UNHAPPY  \\\n",
       "80000    NaN  0.973726  0.026274  0.674793  0.325207              NaN   \n",
       "80001    NaN  0.907652  0.092348  0.553734  0.446266              NaN   \n",
       "80002    NaN  0.972427  0.027573  0.666976  0.333024              NaN   \n",
       "80003    NaN  0.973924  0.026076  0.643522  0.356478         0.131056   \n",
       "80004    NaN  0.444113  0.555887       NaN       NaN              NaN   \n",
       "...      ...       ...       ...       ...       ...              ...   \n",
       "99995    NaN  0.962158  0.037842  0.667667  0.332333              NaN   \n",
       "99996    NaN  0.252000  0.748000  0.137679  0.862321         0.811409   \n",
       "99997    NaN  0.976305  0.023695  0.672058  0.327942              NaN   \n",
       "99998    NaN  0.105306  0.894694  0.177532  0.822468         0.382414   \n",
       "99999    NaN  0.086430  0.913570       NaN       NaN              NaN   \n",
       "\n",
       "       MEDIUM UNHAPPY  MILDLY UNHAPPY  \n",
       "80000             NaN             NaN  \n",
       "80001             NaN             NaN  \n",
       "80002             NaN             NaN  \n",
       "80003        0.236707        0.632237  \n",
       "80004             NaN             NaN  \n",
       "...               ...             ...  \n",
       "99995             NaN             NaN  \n",
       "99996        0.111217        0.077374  \n",
       "99997             NaN             NaN  \n",
       "99998        0.431204        0.186381  \n",
       "99999             NaN             NaN  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'UNKNOWN': 0.9545210531404656, 'KNOWN': 0.9874215652680951, #11761   #42\n",
    "HC = HC.fit(X_train,y_train)\n",
    "probs = HC.get_probabilities(X_test, y_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-18T17:03:14.646493Z",
     "iopub.status.busy": "2021-02-18T17:03:14.646075Z",
     "iopub.status.idle": "2021-02-18T17:03:14.944861Z",
     "shell.execute_reply": "2021-02-18T17:03:14.943787Z",
     "shell.execute_reply.started": "2021-02-18T17:03:14.646459Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4614711304590311"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score_ancestors(ch, y_test_internal['detailedMatchClassification'], pred_internal, beta=1)\n",
    "#precision_score_ancestors(ch, y_test_internal['detailedMatchClassification'], pred_internal)\n",
    "recall_score_ancestors(ch, y_test_internal['detailedMatchClassification'], pred_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-22T15:35:18.521412Z",
     "iopub.status.busy": "2021-02-22T15:35:18.521155Z",
     "iopub.status.idle": "2021-02-22T15:35:20.715792Z",
     "shell.execute_reply": "2021-02-22T15:35:20.708844Z",
     "shell.execute_reply.started": "2021-02-22T15:35:18.521386Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          HAPPY       0.89      0.24      0.38     27774\n",
      "HEAVILY UNHAPPY       0.87      0.12      0.21       535\n",
      "          KNOWN       0.00      0.00      0.00         0\n",
      " MEDIUM UNHAPPY       0.00      0.00      0.00       956\n",
      " MILDLY UNHAPPY       0.16      0.01      0.01      4453\n",
      "         ORDERS       0.00      0.00      0.00         0\n",
      "        UNHAPPY       0.00      0.00      0.00         0\n",
      "        UNKNOWN       0.90      0.74      0.81     16282\n",
      "\n",
      "       accuracy                           0.38     50000\n",
      "      macro avg       0.35      0.14      0.18     50000\n",
      "   weighted avg       0.81      0.38      0.48     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class_report(y_test['detailedMatchClassification'], pred)\n",
    "# global_scores(y_test['detailedMatchClassification'], pred)\n",
    "# local_scores(y_test['detailedMatchClassification'], pred)\n",
    "# precision_score_ancestors(ch, y_test['detailedMatchClassification'], pred)\n",
    "# recall_score_ancestors(ch, y_test['detailedMatchClassification'], pred)\n",
    "# f1_score_ancestors(ch, y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T08:40:49.847357Z",
     "iopub.status.busy": "2021-02-24T08:40:49.840018Z",
     "iopub.status.idle": "2021-02-24T08:41:10.808475Z",
     "shell.execute_reply": "2021-02-24T08:41:10.807777Z",
     "shell.execute_reply.started": "2021-02-24T08:40:49.846959Z"
    }
   },
   "outputs": [],
   "source": [
    "hypers = pd.DataFrame({'1_criterion'   : ['entropy', 'gini',    'gini', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
    "                       '2_criterion'   : ['entropy', 'gini', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy'], \n",
    "                       '1_max_depth'   : [5,  6,  11, 11, 11, 11, 11,  5,  5,  5,  5],\n",
    "                       '2_max_depth'   : [6,  7,  11,  5,  5,  5,  5,  6,  6,  6,  6], \n",
    "                       '3_max_depth'   : [14, 10,  8,  9,  9,  9,  9, 14, 14, 14, 14],\n",
    "                       '3_n_estimators': [40, 30, 20, 45, 45, 45, 45, 40, 40, 40, 40]})\n",
    "\n",
    "day = 3\n",
    "HC = HierarchicalClassifier(Tree)\n",
    "HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '1_criterion'], max_depth = hypers.loc[day, '1_max_depth']),\n",
    "                    'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '2_criterion'], max_depth = hypers.loc[day, '2_max_depth']),\n",
    "                    'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[day, '3_max_depth'], n_estimators = hypers.loc[day, '3_n_estimators'])})\n",
    "\n",
    "X, y  = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, day)\n",
    "index = range(0, X.shape[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "HC.fit(X_train,y_train)\n",
    "y_hat = HC.get_probabilities(X_train, y_train)\n",
    "\n",
    "probs = pd.concat([y_train, y_hat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T09:04:57.287256Z",
     "iopub.status.busy": "2021-02-24T09:04:57.286777Z",
     "iopub.status.idle": "2021-02-24T09:04:57.651275Z",
     "shell.execute_reply": "2021-02-24T09:04:57.647529Z",
     "shell.execute_reply.started": "2021-02-24T09:04:57.287216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = 'HAPPY'\n",
    "check_pos = probs[(probs[check]>0.5) & (probs['detailedMatchClassification'].isin([check]))]\n",
    "check_neg = probs[(probs[check]>0.5) & (~probs['detailedMatchClassification'].isin([check]))]\n",
    "check_pos[check].hist()\n",
    "check_neg[check].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T09:21:35.420508Z",
     "iopub.status.busy": "2021-02-24T09:21:35.420258Z",
     "iopub.status.idle": "2021-02-24T09:21:35.436432Z",
     "shell.execute_reply": "2021-02-24T09:21:35.434479Z",
     "shell.execute_reply.started": "2021-02-24T09:21:35.420485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830901    789\n",
       "0.897491    397\n",
       "0.695356    367\n",
       "0.804675    149\n",
       "0.658031      9\n",
       "Name: HAPPY, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_neg['HAPPY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T14:32:17.906622Z",
     "iopub.status.busy": "2021-02-17T14:32:17.906323Z",
     "iopub.status.idle": "2021-02-17T14:32:17.912083Z",
     "shell.execute_reply": "2021-02-17T14:32:17.909928Z",
     "shell.execute_reply.started": "2021-02-17T14:32:17.906590Z"
    }
   },
   "outputs": [],
   "source": [
    "#combinations = [i for i in product(['DT','RF','NN'],repeat=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:25:45.137476Z",
     "iopub.status.busy": "2021-02-24T20:25:45.137205Z",
     "iopub.status.idle": "2021-02-24T20:25:45.161065Z",
     "shell.execute_reply": "2021-02-24T20:25:45.159695Z",
     "shell.execute_reply.started": "2021-02-24T20:25:45.137451Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hyperspace(combination):\n",
    "    \n",
    "    param_hyperopt = {}\n",
    "    \n",
    "    for node, clf in enumerate(combination):\n",
    "        \n",
    "        if clf == 'DT':\n",
    "            hyper = {'DT_criterion_'+str(node)   : hp.choice('DT_criterion_'+str(node) ,['gini','entropy']),\n",
    "                     'DT_max_depth_'+str(node)   : scope.int(hp.quniform('DT_max_depth_'+str(node), 5, 15, 1))}\n",
    "        elif clf == 'RF':\n",
    "            hyper = {'RF_max_depth_'   +str(node) : scope.int(hp.quniform('RF_max_depth_'+str(node), 5, 15, 1)),\n",
    "                     'RF_n_estimators_'+str(node) : scope.int(hp.quniform('RF_n_estimators_'+str(node), 10, 50, 5))}\n",
    "        elif clf == 'NN':\n",
    "            hyper = {'NN_dropout_'+str(node)  : hp.uniform('NN_dropout_'+str(node), 0, 0.5),\n",
    "                     'NN_nodes_'  +str(node)  : scope.int(hp.quniform('NN_nodes_'+str(node), 5, 50, 5)),\n",
    "                     'NN_layers_' +str(node)  : scope.int(hp.quniform('NN_layers_'+str(node), 1, 2, 1))}\n",
    "        elif clf == 'LR':\n",
    "            hyper = {'LR_penalty_' + str(node) : hp.choice('LR_penalty_' + str(node), ['l1','l2'])}\n",
    "            \n",
    "        param_hyperopt = {**param_hyperopt, **hyper}\n",
    "        \n",
    "    return param_hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:26:09.329707Z",
     "iopub.status.busy": "2021-02-24T20:26:09.329435Z",
     "iopub.status.idle": "2021-02-24T20:26:09.341430Z",
     "shell.execute_reply": "2021-02-24T20:26:09.340062Z",
     "shell.execute_reply.started": "2021-02-24T20:26:09.329681Z"
    }
   },
   "outputs": [],
   "source": [
    "def clf_hypers(params):\n",
    "\n",
    "    clf = {}\n",
    "    \n",
    "    for ix, node in enumerate(['ORDERS','KNOWN','UNHAPPY']):\n",
    "\n",
    "        node_hypers = [x for x in list(params.keys()) if x[-1] == str(ix)]\n",
    "\n",
    "        if combination[ix] == 'DT':\n",
    "            clf[node] = DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = params[node_hypers[1]], criterion = params[node_hypers[0]])\n",
    "        elif combination[ix] == 'RF':\n",
    "            clf[node] = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = params[node_hypers[0]], n_estimators = params[node_hypers[1]])\n",
    "        elif combination[ix] == 'NN':\n",
    "            if ix == 2:\n",
    "                output = 3\n",
    "            else:\n",
    "                output = 1\n",
    "            clf[node] = KerasClassifier(functions.neuralNetwork, output = output, nodes = params[node_hypers[1]], layers = params[node_hypers[2]], droprate = params[node_hypers[0]], epochs = 15, verbose = 0)\n",
    "        elif combination[ix] == 'LR':\n",
    "            clf[node] = LogisticRegression(penalty = params[node_hypers[0]], class_weight = 'balanced', solver = 'liblinear')\n",
    "            \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:26:26.643740Z",
     "iopub.status.busy": "2021-02-24T20:26:26.643465Z",
     "iopub.status.idle": "2021-02-24T20:26:26.654504Z",
     "shell.execute_reply": "2021-02-24T20:26:26.651754Z",
     "shell.execute_reply.started": "2021-02-24T20:26:26.643716Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    \n",
    "    HC = HierarchicalClassifier(Tree)\n",
    "    HC.fit_classifiers(clf_hypers(params))\n",
    "    \n",
    "    HC = HC.fit(X_train,y_train)\n",
    "    pred = HC.predict(X_val)\n",
    "    \n",
    "    score = f1_score_ancestors(Tree, y_val['detailedMatchClassification'], pred, beta=1)\n",
    "    accuracy = metrics.accuracy_score(y_val, pred)\n",
    "    #cross validation score to be implemented\n",
    "    \n",
    "    return {'loss': -score, 'status': STATUS_OK, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:26:32.158019Z",
     "iopub.status.busy": "2021-02-24T20:26:32.157778Z",
     "iopub.status.idle": "2021-02-24T20:26:32.166409Z",
     "shell.execute_reply": "2021-02-24T20:26:32.165229Z",
     "shell.execute_reply.started": "2021-02-24T20:26:32.157996Z"
    }
   },
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X_train, y_train, X_val, y_val, num_eval):\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    best_param = fmin(objective_function, \n",
    "                      param_space, \n",
    "                      algo = tpe.suggest, \n",
    "                      max_evals = num_eval, \n",
    "                      trials = trials,\n",
    "                      rstate = np.random.RandomState(1))\n",
    "    \n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    index_min_loss = loss.index(min(loss))\n",
    "    accuracy_scores = [x['result']['accuracy'] for x in trials.trials]\n",
    "    \n",
    "    f1 = min(loss)*-1\n",
    "    accuracy = accuracy_scores[index_min_loss]\n",
    "    \n",
    "    return best_param, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-17T20:16:56.130427Z",
     "iopub.status.busy": "2021-02-17T20:16:56.128273Z",
     "iopub.status.idle": "2021-02-17T22:17:13.700600Z",
     "shell.execute_reply": "2021-02-17T22:17:13.691358Z",
     "shell.execute_reply.started": "2021-02-17T20:16:56.130312Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [2:00:17<13:21, 801.93s/trial, best loss: -0.7816644024189379]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-425-d5cf0371aaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_hyperspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-423-7b9cd86e5e4c>\u001b[0m in \u001b[0;36mhyperopt\u001b[0;34m(param_space, X_train, y_train, X_test, y_test, num_eval)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     best_param = fmin(objective_function, \n\u001b[0m\u001b[1;32m      6\u001b[0m                       \u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-422-27897c696584>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mHC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-407-50e5fafd7f05>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0my_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mstage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mstage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "combination = ('NN', 'NN', 'NN')\n",
    "best_param, trials = hyperopt(get_hyperspace(combination), X_train, y_train, X_test, y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System: Non-mandaroty dynamic prediction X days after order date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T12:13:49.794500Z",
     "iopub.status.busy": "2021-02-21T12:13:49.794209Z",
     "iopub.status.idle": "2021-02-21T12:13:49.807537Z",
     "shell.execute_reply": "2021-02-21T12:13:49.806315Z",
     "shell.execute_reply.started": "2021-02-21T12:13:49.794473Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "DT_C0 = DTDTRF.apply(lambda x: x['DT_criterion_0']).replace((0,1),('gini','entropy'))\n",
    "DT_C1 = DTDTRF.apply(lambda x: x['DT_criterion_1']).replace((0,1),('gini','entropy'))\n",
    "DT_D0 = DTDTRF.apply(lambda x: int(x['DT_max_depth_0']))\n",
    "DT_D1 = DTDTRF.apply(lambda x: int(x['DT_max_depth_1']))\n",
    "RF_D2 = DTDTRF.apply(lambda x: int(x['RF_max_depth_2']))\n",
    "RF_N2 = DTDTRF.apply(lambda x: int(x['RF_n_estimators_2']))\n",
    "\n",
    "# HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = DT_D0[DAYS], criterion = DT_C0[DAYS]),\n",
    "#                     'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = DT_D1[DAYS], criterion = DT_C1[DAYS]),\n",
    "#                     'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = RF_N2[DAYS], max_depth = RF_D2[DAYS])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T21:15:52.559034Z",
     "iopub.status.busy": "2021-02-26T21:15:52.558748Z",
     "iopub.status.idle": "2021-02-26T21:15:52.583603Z",
     "shell.execute_reply": "2021-02-26T21:15:52.582188Z",
     "shell.execute_reply.started": "2021-02-26T21:15:52.559007Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamicHierarchicalClassifier(START, END, threshold = None, threshold_type = None):  \n",
    "  \n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "  \n",
    "    if threshold_type == 'dynamic':\n",
    "        threshold_list = np.linspace(0.95,threshold,(END-START))\n",
    "    elif threshold_type == 'static':\n",
    "        threshold_list = np.full((END-START),threshold)\n",
    "    threshold_count = 0\n",
    "    \n",
    "    hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "                           '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "                           '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "                           '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "\n",
    "    certainty = 0.99 #lourens = 0.99 / thomas = 0.98 / mathilde = 0.97 / jim = 0.96\n",
    "    #certainty_list = np.linspace(0.98,0.4,11)\n",
    "    \n",
    "    statistics, previous_pred_block, feature_importances, decision_trees = None, None, None, None\n",
    "\n",
    "    for DAYS in range(START, END+1):\n",
    "        \n",
    "        X, y = functions.dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "        \n",
    "        X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "        y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "        \n",
    "        X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "        y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "        \n",
    "        X_test = X.iloc[int(0.8*len(X)):]\n",
    "        y_test = y.iloc[int(0.8*len(y)):]\n",
    "        #print('Data pre-processing done')\n",
    "        \n",
    "        N_test = len(y_test)\n",
    "\n",
    "        HC = HierarchicalClassifier(Tree)\n",
    "        HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "                            'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "                            'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "    \n",
    "        \n",
    "        HC = HC.fit(X_train,y_train)\n",
    "        #print('Hierarchy fitted')\n",
    "        \n",
    "        y_train_hat = HC.get_probabilities(X_train, y_train)\n",
    "        probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "        #print('Thresholds calculated')\n",
    "        \n",
    "        THRESHOLDS = {}\n",
    "        for node in range(1,8):\n",
    "            name, threshold = opt_threshold(probs, node, DAYS, certainty)\n",
    "            THRESHOLDS[name] = threshold\n",
    "\n",
    "        if DAYS == START: #create dataframe to save predictions\n",
    "            y_hat = pd.DataFrame([Tree.root] * len(X_test),\n",
    "                                    columns=[DAYS],\n",
    "                                    index=X_test.index)\n",
    "            index_no_leaf = X_test.index\n",
    "        else:\n",
    "            y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "        if DAYS < END:\n",
    "            pred = HC.predict_proba2(X_test.loc[index_no_leaf], THRESHOLDS = THRESHOLDS)\n",
    "\n",
    "            check_no_leaf = ~pred.isin(Tree._get_leaf_nodes())\n",
    "            index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "            check_leaf    = pred.isin(Tree._get_leaf_nodes())      #from current non_leaf predictions which are now leaf\n",
    "            index_leaf    = check_leaf[check_leaf].index\n",
    "            y_hat_stage   = pd.DataFrame(pred, index = index_leaf)\n",
    "        else:\n",
    "            pred        = HC.predict(X_test.loc[index_no_leaf]) #last day you want a label for each order\n",
    "            y_hat_stage = pd.DataFrame(pred, index = index_no_leaf)\n",
    "            index_leaf  = index_no_leaf\n",
    "            \n",
    "        y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "        y_hat.stage_col = y_hat.stage_col.fillna(y_hat[DAYS]) #fill previously predicted labels\n",
    "        y_hat = y_hat.drop(DAYS, axis=1)\n",
    "        y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "        \n",
    "        current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "        statistics, feature_importances, decision_trees, previous_pred_block = get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, \n",
    "                                                                               previous_pred_block, THRESHOLDS, y_test, Tree, HC, feature_importances, decision_trees, statistics)\n",
    "\n",
    "        threshold_count += 1\n",
    "        \n",
    "        with open('/Users/LV/Desktop/statistics.json', 'w') as f:\n",
    "            json.dump(statistics, f, cls = NumpyEncoder)\n",
    "            \n",
    "        print('DAYS: ',DAYS)\n",
    "     \n",
    "    final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "    return final_pred, statistics, feature_importances, decision_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-26T21:07:59.429504Z",
     "iopub.status.busy": "2021-02-26T21:07:59.429187Z",
     "iopub.status.idle": "2021-02-26T21:09:46.763069Z",
     "shell.execute_reply": "2021-02-26T21:09:46.762041Z",
     "shell.execute_reply.started": "2021-02-26T21:07:59.429478Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pre-processing done\n",
      "Hierarchy fitted\n",
      "Thresholds calculated\n",
      "DAYS:  0\n",
      "Data pre-processing done\n",
      "Hierarchy fitted\n",
      "Thresholds calculated\n",
      "DAYS:  1\n",
      "Data pre-processing done\n",
      "Hierarchy fitted\n",
      "Thresholds calculated\n",
      "DAYS:  2\n"
     ]
    }
   ],
   "source": [
    "pred, statistics, feature_importances, decision_trees = dynamicHierarchicalClassifier(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-26T21:12:17.592156Z",
     "iopub.status.busy": "2021-02-26T21:12:17.591869Z",
     "iopub.status.idle": "2021-02-26T21:12:17.641096Z",
     "shell.execute_reply": "2021-02-26T21:12:17.640037Z",
     "shell.execute_reply.started": "2021-02-26T21:12:17.592130Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%classified</th>\n",
       "      <td>0.14055</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_classified</th>\n",
       "      <td>2811</td>\n",
       "      <td>2337</td>\n",
       "      <td>14852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_predicted</th>\n",
       "      <td>20000</td>\n",
       "      <td>17189</td>\n",
       "      <td>14852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaf_accuracy</th>\n",
       "      <td>0.914977</td>\n",
       "      <td>0.948652</td>\n",
       "      <td>0.861904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_leaf_accuracy</th>\n",
       "      <td>0.914977</td>\n",
       "      <td>0.930264</td>\n",
       "      <td>0.8795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaf_precision</th>\n",
       "      <td>0.94052</td>\n",
       "      <td>0.969648</td>\n",
       "      <td>0.883739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_leaf_precision</th>\n",
       "      <td>0.94052</td>\n",
       "      <td>0.95516</td>\n",
       "      <td>0.901541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaf_recall</th>\n",
       "      <td>0.879045</td>\n",
       "      <td>0.945304</td>\n",
       "      <td>0.862622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_leaf_recall</th>\n",
       "      <td>0.879045</td>\n",
       "      <td>0.911648</td>\n",
       "      <td>0.875049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_precision</th>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.883739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_recall</th>\n",
       "      <td>0.573052</td>\n",
       "      <td>0.589851</td>\n",
       "      <td>0.862622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_precision</th>\n",
       "      <td>0.991328</td>\n",
       "      <td>0.990973</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_recall</th>\n",
       "      <td>0.468131</td>\n",
       "      <td>0.473846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_Nchange</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0249763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_Pchange</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree_error</th>\n",
       "      <td>0.289221</td>\n",
       "      <td>0.16089</td>\n",
       "      <td>0.450983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thresholds</th>\n",
       "      <td>{'UNKNOWN': 0.9695845123894807, 'KNOWN': 0.947...</td>\n",
       "      <td>{'UNKNOWN': 0.9759953480694773, 'KNOWN': 0.926...</td>\n",
       "      <td>{'UNKNOWN': 0.9787118341054708, 'KNOWN': 0.826...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_UNKNOWN</th>\n",
       "      <td>0.924107</td>\n",
       "      <td>0.936803</td>\n",
       "      <td>0.87488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_UNKNOWN</th>\n",
       "      <td>0.802326</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.717275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_UNKNOWN</th>\n",
       "      <td>0.858921</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.788277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_HAPPY</th>\n",
       "      <td>0.950729</td>\n",
       "      <td>0.982346</td>\n",
       "      <td>0.962587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_HAPPY</th>\n",
       "      <td>0.918846</td>\n",
       "      <td>0.965304</td>\n",
       "      <td>0.938973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_HAPPY</th>\n",
       "      <td>0.934516</td>\n",
       "      <td>0.97375</td>\n",
       "      <td>0.950633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_MILDLY UNHAPPY</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.928177</td>\n",
       "      <td>0.616689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_MILDLY UNHAPPY</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.769929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_MILDLY UNHAPPY</th>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.938547</td>\n",
       "      <td>0.684841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_MEDIUM UNHAPPY</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_MEDIUM UNHAPPY</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.840708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_MEDIUM UNHAPPY</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.815451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_HEAVILY UNHAPPY</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_HEAVILY UNHAPPY</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_HEAVILY UNHAPPY</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%blockORDERS</th>\n",
       "      <td>0.54315</td>\n",
       "      <td>0.487463</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%blockKNOWN</th>\n",
       "      <td>0.809701</td>\n",
       "      <td>0.774903</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%blockUNHAPPY</th>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           0  \\\n",
       "%classified                                                          0.14055   \n",
       "N_classified                                                            2811   \n",
       "N_predicted                                                            20000   \n",
       "leaf_accuracy                                                       0.914977   \n",
       "total_leaf_accuracy                                                 0.914977   \n",
       "leaf_precision                                                       0.94052   \n",
       "total_leaf_precision                                                 0.94052   \n",
       "leaf_recall                                                         0.879045   \n",
       "total_leaf_recall                                                   0.879045   \n",
       "label_precision                                                     0.970787   \n",
       "label_recall                                                        0.573052   \n",
       "block_precision                                                     0.991328   \n",
       "block_recall                                                        0.468131   \n",
       "block_Nchange                                                            NaN   \n",
       "block_Pchange                                                            NaN   \n",
       "tree_error                                                          0.289221   \n",
       "thresholds                 {'UNKNOWN': 0.9695845123894807, 'KNOWN': 0.947...   \n",
       "precision_UNKNOWN                                                   0.924107   \n",
       "recall_UNKNOWN                                                      0.802326   \n",
       "f1_UNKNOWN                                                          0.858921   \n",
       "precision_HAPPY                                                     0.950729   \n",
       "recall_HAPPY                                                        0.918846   \n",
       "f1_HAPPY                                                            0.934516   \n",
       "precision_MILDLY UNHAPPY                                            0.666667   \n",
       "recall_MILDLY UNHAPPY                                               0.740741   \n",
       "f1_MILDLY UNHAPPY                                                   0.701754   \n",
       "precision_MEDIUM UNHAPPY                                                   1   \n",
       "recall_MEDIUM UNHAPPY                                                      1   \n",
       "f1_MEDIUM UNHAPPY                                                          1   \n",
       "precision_HEAVILY UNHAPPY                                           0.955556   \n",
       "recall_HEAVILY UNHAPPY                                              0.955556   \n",
       "f1_HEAVILY UNHAPPY                                                  0.955556   \n",
       "%blockORDERS                                                         0.54315   \n",
       "%blockKNOWN                                                         0.809701   \n",
       "%blockUNHAPPY                                                       0.380952   \n",
       "\n",
       "                                                                           1  \\\n",
       "%classified                                                           0.2574   \n",
       "N_classified                                                            2337   \n",
       "N_predicted                                                            17189   \n",
       "leaf_accuracy                                                       0.948652   \n",
       "total_leaf_accuracy                                                 0.930264   \n",
       "leaf_precision                                                      0.969648   \n",
       "total_leaf_precision                                                 0.95516   \n",
       "leaf_recall                                                         0.945304   \n",
       "total_leaf_recall                                                   0.911648   \n",
       "label_precision                                                     0.982453   \n",
       "label_recall                                                        0.589851   \n",
       "block_precision                                                     0.990973   \n",
       "block_recall                                                        0.473846   \n",
       "block_Nchange                                                      0.0249763   \n",
       "block_Pchange                                                       0.185109   \n",
       "tree_error                                                           0.16089   \n",
       "thresholds                 {'UNKNOWN': 0.9759953480694773, 'KNOWN': 0.926...   \n",
       "precision_UNKNOWN                                                   0.936803   \n",
       "recall_UNKNOWN                                                      0.831683   \n",
       "f1_UNKNOWN                                                          0.881119   \n",
       "precision_HAPPY                                                     0.982346   \n",
       "recall_HAPPY                                                        0.965304   \n",
       "f1_HAPPY                                                             0.97375   \n",
       "precision_MILDLY UNHAPPY                                            0.928177   \n",
       "recall_MILDLY UNHAPPY                                               0.949153   \n",
       "f1_MILDLY UNHAPPY                                                   0.938547   \n",
       "precision_MEDIUM UNHAPPY                                            0.939394   \n",
       "recall_MEDIUM UNHAPPY                                               0.939394   \n",
       "f1_MEDIUM UNHAPPY                                                   0.939394   \n",
       "precision_HEAVILY UNHAPPY                                           0.984127   \n",
       "recall_HEAVILY UNHAPPY                                              0.984127   \n",
       "f1_HEAVILY UNHAPPY                                                  0.984127   \n",
       "%blockORDERS                                                        0.487463   \n",
       "%blockKNOWN                                                         0.774903   \n",
       "%blockUNHAPPY                                                       0.228261   \n",
       "\n",
       "                                                                           2  \n",
       "%classified                                                                1  \n",
       "N_classified                                                           14852  \n",
       "N_predicted                                                            14852  \n",
       "leaf_accuracy                                                       0.861904  \n",
       "total_leaf_accuracy                                                   0.8795  \n",
       "leaf_precision                                                      0.883739  \n",
       "total_leaf_precision                                                0.901541  \n",
       "leaf_recall                                                         0.862622  \n",
       "total_leaf_recall                                                   0.875049  \n",
       "label_precision                                                     0.883739  \n",
       "label_recall                                                        0.862622  \n",
       "block_precision                                                          NaN  \n",
       "block_recall                                                             NaN  \n",
       "block_Nchange                                                              0  \n",
       "block_Pchange                                                              1  \n",
       "tree_error                                                          0.450983  \n",
       "thresholds                 {'UNKNOWN': 0.9787118341054708, 'KNOWN': 0.826...  \n",
       "precision_UNKNOWN                                                    0.87488  \n",
       "recall_UNKNOWN                                                      0.717275  \n",
       "f1_UNKNOWN                                                          0.788277  \n",
       "precision_HAPPY                                                     0.962587  \n",
       "recall_HAPPY                                                        0.938973  \n",
       "f1_HAPPY                                                            0.950633  \n",
       "precision_MILDLY UNHAPPY                                            0.616689  \n",
       "recall_MILDLY UNHAPPY                                               0.769929  \n",
       "f1_MILDLY UNHAPPY                                                   0.684841  \n",
       "precision_MEDIUM UNHAPPY                                            0.791667  \n",
       "recall_MEDIUM UNHAPPY                                               0.840708  \n",
       "f1_MEDIUM UNHAPPY                                                   0.815451  \n",
       "precision_HEAVILY UNHAPPY                                           0.822222  \n",
       "recall_HEAVILY UNHAPPY                                              0.860465  \n",
       "f1_HEAVILY UNHAPPY                                                  0.840909  \n",
       "%blockORDERS                                                             NaN  \n",
       "%blockKNOWN                                                              NaN  \n",
       "%blockUNHAPPY                                                            NaN  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(statistics)\n",
    "\n",
    "for ix, node in enumerate(['ORDERS','KNOWN','UNHAPPY']):\n",
    "    col_name = '%block'+node\n",
    "    results[col_name] = results['%blocking'].apply(lambda x: x[node])\n",
    "\n",
    "results_plot = results.drop(['%blocking'], axis = 1)\n",
    "results = results_plot.transpose()\n",
    "#results.transpose().to_excel('/Users/LV/Desktop/output.xlsx')\n",
    "#feature_importances.to_excel('/Users/LV/Desktop/featureimportance.xlsx')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-23T11:27:36.736165Z",
     "iopub.status.busy": "2021-02-23T11:27:36.735878Z",
     "iopub.status.idle": "2021-02-23T11:27:37.057709Z",
     "shell.execute_reply": "2021-02-23T11:27:37.055693Z",
     "shell.execute_reply.started": "2021-02-23T11:27:36.736139Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot parameters\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Colors\n",
    "bol_darkblue  = '#0009AA' #dark blue\n",
    "bol_lightblue = '#D2EFFF' #light blue\n",
    "bol_happy     = '#26DD8C' #green\n",
    "bol_unknown   = '#BFBFBF' #grey\n",
    "bol_mildly    = '#FFBC89' #light orange\n",
    "bol_medium    = '#FF7B18' #medium orange\n",
    "bol_heavy     = '#D23C00' #red\n",
    "bol_order     = '#78CEFF' #light blue\n",
    "bol_lines     = '#B7B18B' #taupe\n",
    "\n",
    "### Plotten\n",
    "#plt.plot(data, color = , marker = , linewidth = , label = , clip_on = False)\n",
    "plt.figure(figsize = (16,8))\n",
    "\n",
    "plt.plot(results_plot['%classified']*100  , color = bol_darkblue, marker = 'o', label = 'Classified', clip_on = False)\n",
    "plt.plot(results_plot['leaf_accuracy']*100, color = bol_medium  , marker = 'o', label = 'Accuracy')\n",
    "\n",
    "### Titel\n",
    "plt.title('', fontweight = 'bold')\n",
    "\n",
    "### Assen\n",
    "plt.ylabel('Percentage', fontweight = 'normal')\n",
    "plt.ylim(30,100)\n",
    "\n",
    "plt.xlabel('Days after order date', fontweight = 'normal')\n",
    "plt.xticks(range(11))\n",
    "#plt.xlim(-0.1, 30.1)\n",
    "\n",
    "### Legend\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "### Grafiek Lay-out\n",
    "plt.grid(color='#C0C0C0', linestyle='--', linewidth=1, axis='y')\n",
    "plt.tick_params(axis='x', direction='in', length=5, colors='black')\n",
    "plt.tick_params(axis='y', length=0)\n",
    "sns.despine(left=False, bottom=False, right=True)\n",
    "\n",
    "#plt.savefig('plot.png',dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Non-mandatory predictions 0,1,2,... days after order date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-12T09:31:38.310871Z",
     "iopub.status.busy": "2021-02-12T09:31:38.310537Z",
     "iopub.status.idle": "2021-02-12T09:34:19.938146Z",
     "shell.execute_reply": "2021-02-12T09:34:19.936876Z",
     "shell.execute_reply.started": "2021-02-12T09:31:38.310843Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n"
     ]
    }
   ],
   "source": [
    "PREDICT_DAYS = 10\n",
    "threshold = 0.8\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "results = {}\n",
    "\n",
    "dynamic_threshold = np.linspace(0.95,threshold,PREDICT_DAYS+1)\n",
    "dynamic_count = 0\n",
    "\n",
    "for DAYS in range(PREDICT_DAYS+1):\n",
    "    \n",
    "    X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "    HC = HierarchicalClassifier(Tree)\n",
    "    HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "                        'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "                        'UNHAPPY' : KerasClassifier(build_fn = functions.neuralNetwork, epochs = 15, verbose = 0)})\n",
    "    \n",
    "    HC = HC.fit(X_train,y_train['detailedMatchClassification'])\n",
    "    pred = HC.predict_proba(X_test, threshold = dynamic_threshold[dynamic_count])\n",
    "    \n",
    "    fraction_label, fraction_leaf, accuracy_leaf = day_block_scores(HC, y_test['detailedMatchClassification'], pred)\n",
    "    \n",
    "    predictions[DAYS] = pred\n",
    "    results['DAY '+str(DAYS)] = (fraction_label, fraction_leaf, accuracy_leaf)\n",
    "    \n",
    "    dynamic_count += 1\n",
    "    \n",
    "    print('DAYS: ',DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T09:34:19.942295Z",
     "iopub.status.busy": "2021-02-12T09:34:19.941636Z",
     "iopub.status.idle": "2021-02-12T09:34:20.006608Z",
     "shell.execute_reply": "2021-02-12T09:34:20.002309Z",
     "shell.execute_reply.started": "2021-02-12T09:34:19.942247Z"
    }
   },
   "outputs": [],
   "source": [
    "changes = {}\n",
    "for i in range(0,predictions.shape[1]-1):\n",
    "    col_t0 = predictions.iloc[:,i]\n",
    "    col_t1 = predictions.iloc[:,i+1]\n",
    "    \n",
    "    check_leaf_t0 = col_t0.isin(Tree._get_leaf_nodes())\n",
    "    index_leaf_t0 = check_leaf_t0[check_leaf_t0].index\n",
    "    \n",
    "    col_t0_leaf = col_t0.loc[index_leaf_t0]\n",
    "    col_t1_leaf = col_t1.loc[index_leaf_t0]\n",
    "    \n",
    "    check_similarity = (col_t0_leaf == col_t1_leaf)\n",
    "    if i == 0:\n",
    "        ix = check_similarity[check_similarity == False].index\n",
    "    \n",
    "    changes['DAY '+str(i+1)] = 1 - (check_similarity.sum() / col_t0_leaf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T09:34:20.020310Z",
     "iopub.status.busy": "2021-02-12T09:34:20.019700Z",
     "iopub.status.idle": "2021-02-12T09:34:20.069459Z",
     "shell.execute_reply": "2021-02-12T09:34:20.054155Z",
     "shell.execute_reply.started": "2021-02-12T09:34:20.020250Z"
    }
   },
   "outputs": [],
   "source": [
    "days0, stats = zip(*results.items())\n",
    "fraction_label, fraction_leaf, accuracy_leaf = zip(*stats)\n",
    "days1, change = zip(*changes.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-12T15:17:44.732108Z",
     "iopub.status.busy": "2021-02-12T15:17:44.731830Z",
     "iopub.status.idle": "2021-02-12T15:17:44.918889Z",
     "shell.execute_reply": "2021-02-12T15:17:44.917573Z",
     "shell.execute_reply.started": "2021-02-12T15:17:44.732082Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffa756a1310>]"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmdklEQVR4nO3deXRc5X3/8fd3du22JRmvso0tBwwYMMLGgI0dkgBpCKFNwpKTpElafrShy8kvaZbmNL/fL13I2iSFhFIOSclSmiZpQ9MsTdsEGzCLzGKzBNvYeMFgW7KtxdLsz++PZySN5LEkm5FHM/q8zpkzM/dejb6ja3/mmec+97nmnENERMpfoNQFiIhIcSjQRUQqhAJdRKRCKNBFRCqEAl1EpEIo0EVEKsSYgW5m95rZQTN79gTrzcy+ZmY7zGyLma0ofpkiIjKW8bTQvwVcPcr6a4DW3O0W4BuvvywRETlZobE2cM5tMLOFo2xyHXCf82coPWpm08xstnPu1dFet6mpyS1cONrLiojISJs3b+5wzjUXWjdmoI/DXGBv3vN9uWWjBvrChQtpb28vwq8XEZk6zGz3idYV46CoFVhWcD4BM7vFzNrNrP3QoUNF+NUiIjKgGIG+D5if93wesL/Qhs65u51zbc65tubmgt8YRETkFBUj0B8A3pcb7XIJ0DVW/7mIiBTfmH3oZvZPwDqgycz2AZ8BwgDOubuAnwJvBXYAfcAHJqpYERE5sfGMcrlpjPUO+HDRKhIRkVOiM0VFRCqEAl1EpEIUYxy6iIgAzjkS6Szd8RQ98TS98bS/T6ToHngcT7NiwTTWtBZ/pJ8CXUQEyGQdvYk0PQNhnPe4Jy+Y85+P3LY3kSaVOdFlPTNgaSyQ5oOXtirQRURGGmgVFwrYgeDt7k/RneinK95Pd7yfnmQ/PYl+epNx+pJx+lJx4pmkD1xLQyDl7/OeY2kCgTSRcJZwKEMwmCUUThOMZTBLUx9IU28pnKVxpMmSIuOSpLMpUi5J1mUGa66f/XvAhUX/WyjQRWTCZbIZEpkEyUxy2H1/OkFXvJ+ueB9d8T6643F6Enlhm/K3/lSCeDpBfyZBMvfzyWySdDZJ2iVx+JYvgyGcgkB6KJQD6eEFBYHq3A1/MLF6jPcQtBDRYIRoMErkuPsokWAd0WB0+PLA0Hb5P3NO4znF/yOjQBepeM45UtkUiUxiMExHBuvAfSI7fNlx60eEcX8qQX8qTn/aB24ikySZTZDKJEm5JBmXIuNSODJjFzrmGwljLkQgECYYiBAOhKm2COFghEig2odpKEpV7lYdjlETiVEb8fdV4diwgM0P3+MDesT6QIRgIPj638MEU6CLTALOOfrT/fSn++lL9w0+7k/305fqK/h45LbDtsstj6fjJDKJIhQYwAiDC+GyYbLZIC4bAhfGuSC4MGRDOFcLbhrOhSAbJmRhwsEo0WCEWChKLBSlOhe21bmwrY1UUReN0RCroj5aRUNVNdOrqpleXc2M6mqmRasJB8OYFZo2SvIp0EXGaaCle6Lw7Ev30Z8aO2RPFM4nIxwIUxWqoipURSRQRciiBIlirppAtoGqTJhwOkwsFSKVDpJKB0ikgiSSAeKpALjQYDjjgjjnw9qHcogAYWoiVdSGY9TFYjTEotTGQtRVhaiLhaiNhqmLhYZu0bBfHwtRHwtTGw1RGwsRDmpk9OmkQJeKk86mRw3OgeAdszU8sC4vpDNu/F0HAQtQFaqiOlQ9GL7V4Wpqw7U0VzUPXxf2j2PBGAGLkk6FSaZC9CdC9CcDHOsL0RM3uo7BkWNGZ2+Gzt4kr/SnCv7uaChAU22UxtqID9jaXBDHQtTFwtTHQtRG/eOB5fW5dbXRENWRoFrEZUiBLiWR38UwWtfBaK3cEwV1Mps8qVoGwnYwdHMhO6t61mDQ5gfyyO1GLh94HglEMDMyWceRviSdvUk6ehO5W5LO3OOXB5f7+0Q6m6ssCwy9l4aqME21ERpro5w9q4bG2shgaDfVRmkafB6lRoE8JSnQhazLDo4aSGaSpDL+AFoy6x8PLB/YZuSyVDZFMpMknomPu483no7jCk+bX1B+F0N+eM6IzTguSE8YsrkArg5VD7WIQzECdvLdAvFUhs5juVDuygvlnqN0HjtAR29iMMAPH0uSLfBWQwGjsTZCY02Uprooi5traaqL0lgzMqijzKiJEAmp+0JGp0A/zZxzpLPpMUNytOAcbdmwnxl4jfz1BbZPu/TYhY9DoS6GqlDVqF0MJwzjvO2qQlWEA+Gi1Hgizjm64+lcq3mo9TzQah4I585jSTp6EvQkCv/NaiJBGnOt5fkzqrmwZXpey3l4S7o+FiYQUCtaiqfiAz2TzRwfZqUK0dyyYglakEjQD98aGFoVCUYIB8ODjyOByODX/4HhWWNtX2hZODj8ZwotCwcm10iEdCbL4b4kHT1JOo8lBoP5UH5A590nM9njXsMMpldHBlvN58ypHxbK+UHdWBuhOlLx/6VkEiu7f32bD2zmnq33jDtET+Yg1ljyg3BY4OUtqwnVEImOLzjzAzEajJ7wNU8UxuUwLrbY+pOZgv3QhVrSR/qSuAJdHZFgYFgIv2FWHY21EZrzw7kmSlNdhBnVEUIaqSFlouwCPZlJciR+ZDDUasI1U7L1WSmyWUdXf4rOYwkODbSke3JdGwWCui9Z+AO6Lhoa7H9e3FzLykXHHygcOKBYHwtpX0pFKrtAXz1nNavnrC51GTKKVCY7bETHyP7njtx95zG/Ll3giGHAYEbNUCC3tFSfcERHY02EWHjqfVsRGansAl0mD+ccLx06xsbth3hoewcvdx6jozdJ1xhjo5tqI8xuiHHu3Pph/dDNeS3padURgjpgKHJSFOhyUo72JXl4Rycbtx9i4/YOXjnqz3A8s6mGs2bXcVle/3NjTZTmuqFheRobLTKxFOgyqlQmy9N7j7Jx2yE2bO9gy76jZB3UxUJcvqSJD69fwprWJubPGGuuOhGZaAp0Oc7uzmNs2N7Bxm2H2PRSJz2JNAGDC1um88dX+on5z5/XoNEfIpOMAl3oiad45KWhbpTdnX0AzJtexbUXzGFtaxOrFzfRUDWxJ/eIyOujQJ+CMlnHln1H2bi9g43bD/HknqNkso6aSJDVi5v40OWLWNPazMLGavV5i5QRBfoU8crRfjZu8y3wh3Z00NWfwgyWz23gD65YzJrWJi5sma75QkTKmAK9QvUl0zy6s5MN23wr/KVDxwCYVR/jqnPOYE1rM5ctaWJGTaTElYpIsSjQK0Q263j+1W42bD/Exm0dtO8+TCrjiIUDrFrUyM2rFrC2tYklM2vVjSJSoRToZexgd9yPRsmd2NN5zE/8dfbsej542SLWLm3mogXTdRalyBShQC8j8VSGJ14+zIZcX/hvXusBoKk2wtqlzaxd2sRlS5qYWRcrcaUiUgoK9EnMOce2A71s2HaIDdsP8fiuwyTSWSLBABcvms4nrzmLNa3NnDWrTvNqi4gCfbLp7E3w0I6OwYOZB3v8FdtbZ9bynlULWLu0iVWLGqmKqBtFRIZToJdYMp1l8+4j/mDm9kM8+0o3ANOqw1y+pIm1rc2sWdrE7IaqElcqIpOdAv00c86xs+PY4Nwoj+7spC+ZIRQwViyYzkffspS1S5s5Z06DZhsUkZOiQD8NuvpSPPxSx+DBzIEZChc11fDOi+axprWZ1YsbqY1qd4jIqVOCTIB0bobCDdt9iOfPUHjZ4ib+cP1i1rY2a4ZCkakknYAXfwpPfhuWvR0u+t2i/4pxBbqZXQ18FQgC9zjnbh+xvgH4DtCSe80vOue+WeRaJ7U9nX1s2H6IDSNmKLxg/jT+6I2trF3axPnzpmmGQpGp5uALPsS33A99nVA/D2xiBjWMGehmFgTuBN4M7AOeMLMHnHPP5232YeB559y1ZtYMvGhm33XOFe8S95NMTzzFppc62bi9gw3bDw3OUDh3WhVvO9/PUHjp4iYaqjVDociUk+iB5/4VnrwP9j0BgTCc9Va48H2weD1M0AXex9NCXwnscM7tBDCz+4HrgPxAd0Cd+XPKa4HDQLrItZZUJuvY+kpX7mDm0AyF1ZEgly5u5IOXLWJNaxOLmmp0ar3IVOScD+8n/xGe/VdIHYOmN8Bb/grOvxFqmia8hPEE+lxgb97zfcCqEdvcATwA7AfqgBucc9mRL2RmtwC3ALS0tJxKvafV/qP9bNzuR6M8vKODo31+hsLz5jZw6xVnsqa1mRWaoVBkajvWAc/c71vjHS9CuAbOvR5WvB/mXQynsYE3nkAvVM3Iy7RfBTwNvBFYDPzSzDY657qH/ZBzdwN3A7S1tR1/qfcS60umeWzn4cG+8IEZCs+oj/Lms89gzdJmLlvcSGNttMSVikhJZTPw0q/gqfvgNz+FbMqH97Vfg3N/G6J1JSlrPIG+D5if93weviWe7wPA7c45B+wws13AWcDjRalyggzMUDhwoYf2l4+QzGSJhgKsOrORm1a2sHZpM62aoVBEAI7shqe/C099F7r3QdUMWHkLrHgvzDy71NWNK9CfAFrNbBHwCnAjcPOIbfYAVwIbzewM4A3AzmIWWiwHu+ODAf7Qjg46ev1x27Nm1fGByxayprWZtoWaoVBEctIJ+M1/+C6Vnb/2yxa/Ea76S3jDWyE0eb6xjxnozrm0md0G/AI/bPFe59xzZnZrbv1dwGeBb5nZVnwXzcedcx0TWPe4DcxQuDE3Jjx/hsLLlzSxdmkzly9pYma9ZigUkTwHnoenvu37x/sPQ8N8WPcJuOBmmDY5jwGa7yU5/dra2lx7e3vRX3dghsKBg5mP7ewcnKGwbeF01rT6aWbPnlWvGQpFZLhEDzz7Qz9u/JX23HDD34IV74Mz103YcMOTYWabnXNthdZVxJmiAzMUDnSlHOj2MxQumVnLzat8P/iqRTOojlTE2xWRYnIO9j7mQ/y5H0GqD5rPhqv+GpbfCDWNpa5w3Moy4QZmKNy43c+N8uz+LpzzMxRetqSJta1NrGltZs40zVAoIifQewie+SffrdKxDSK1cN47/ck/89pO63DDYim7QP/5s6/yke8/MzRDYct0PvImP0PhuXM1Q6GIjCKbgZf+x5/88+LPIJuGeSvh7XfAOddDtLbUFb4uZRfoS2bW8Tsr5rGmtYnVixupi+nUehEZw5GX4anvwNPfg+5XoLoRVt0KF74XZp5V6uqKpgwDvZbPvuPcUpchIpNdKg6/+YkfbrjrQcBgyZVw9d/A0msgFCl1hUVXdoEuIjKq154dGm4YPwoNLbDuU7nhhvPH/PFypkAXkfIX74Znf+BHqux/EoIROOtt/gzOResgMDXmW1Kgi0h5cg72POq7VJ7/Nz/ccOYyuPp2WH4DVM8odYWnnQJdRMpL70E/3PDJb0Pn9txww3f52Q3nrijL4YbFokAXkckvk4aX/tu3xrf93A83nH8JXP6nsOwdZT/csFgU6CIyeR3elRtu+F3oeRWqm+CSP/An/zQvLXV1k44CXUQml1QcXvh3P9f4rg1gAVjyJrjm87D06oocblgsCnQRmRxe2+q7VLZ83w83nNYC6z/thxs2zC11dWVBgS4ipRPvgq0/8EH+6tN+uOHZ1/rZDReunTLDDYtFgS4ip5dzsPsRf/LPc/8G6X6YeQ5c/TlY/u4pOdywWBToInJ69ByAZ77nD3J27oBIHZx/oz/5Z87UHm5YLAp0EZk4mTTs+KUfM77t5+Ay0HIprPnfsOw6iNSUusKKokAXkeLrfGlodsPe16CmGS69zc9u2NRa6uoqlgJdRIoj1e+HGz55H7y8MTfc8M2w4kuw9CoIaqrriaZAF5HX59VnfJfK1u/7USvTF8IbPw0XvAfq55S6uilFgS4iJ6//KGz9Fz9S5dVnIBiFZW/3ww0XXK7hhiWiQBeR8XEOXn7Ih/jzP4Z0HM44D675gr8Wp4YblpwCXURG1/Oan0vlqe/A4Z0Qrfdnb654H8y+QMMNJxEFuogcL5OG7f/pD3Bu/08/3HDBZXDFx+Hst0OkutQVSgEKdBEZ0vmS71J5+nvQewBqz4BL/yg33HBJqauTMSjQRaa6ZB+88IAfqbL7IT/csPUqfwZn61s03LCMKNBFpqr9T/sula0/gEQXTF8EV/4FnH8z1M8udXVyChToIlNJ/xHY8i9+rvHXtkIo5vvEV7zP95FruGFZU6CLVLps1nelPHkfPP8AZBIwazm89Yt+uGHV9FJXKEWiQBepVMc6YfM3/UHOIy9DtMH3i1/4XphzQamrkwmgQBepNP1H4JE74LG7INkLC9fAuk/5MznDVaWuTiaQAl2kUsS74NFvwKY7IdENy94B6z4BM88udWVymijQRcpdohce/3t4+Gv+WpxnvQ3WfRJmnVvqyuQ0G1egm9nVwFeBIHCPc+72AtusA74ChIEO59wVRatSRI6X7IMn7oGHvwJ9nX7s+PpPwpwLS12ZlMiYgW5mQeBO4M3APuAJM3vAOfd83jbTgK8DVzvn9pjZzAmqV0RScdj8LXjoy/5szjPXw/o/h/kXl7oyKbHxtNBXAjucczsBzOx+4Drg+bxtbgZ+5JzbA+CcO1jsQkWmvHTSjx/f8CXo2e8Pdr7rW7Dg0lJXJpPEeAJ9LrA37/k+YNWIbZYCYTP7NVAHfNU5d9/IFzKzW4BbAFpaWk6lXpGpJ5Pyc6ts+AJ07YX5q+D6u+BM9WrKcOMJ9EJzY7oCr3MRcCVQBWwys0edc9uG/ZBzdwN3A7S1tY18DRHJl0n7i0g8+Dk4sgvmrIBrvwKLr9SUtVLQeAJ9HzA/7/k8YH+BbTqcc8eAY2a2ATgf2IaInJxsFp77Efz6dujcDrPOg5vuh6VXK8hlVOMJ9CeAVjNbBLwC3IjvM8/3Y+AOMwsBEXyXzN8Ws1CRipfNwm/+HX71N3DoBZi5DN79bT8MUXOsyDiMGejOubSZ3Qb8Aj9s8V7n3HNmdmtu/V3OuRfM7OfAFiCLH9r47EQWLlIxnIMXfwa/+ms4sBWalsI774Vl1yvI5aSYc6Xpym5ra3Pt7e0l+d0ik4JzsOO/4Vd/Bfuf9NPXrvsEnPcuCARLXZ1MUma22TnXVmidzhQVOd2cg10P+hb53segoQXefgecf6MuJiGviwJd5HR6+WHfIt/9MNTNgd/6sp/9MBQpdWVSARToIqfD3sd9kO/8tb9O5zWfhxXvh3Cs1JVJBVGgi0ykV570XSs7fgnVTfCWv4K2D0KkutSVSQVSoItMhNe2+uGHL/6HvyLQlZ+BlbdAtLbUlUkFU6CLFNPBF+DXfwPP/9hfIWj9n8OqWyFWX+rKZApQoIsUQ8cOePB22PoDiNTA2o/B6g/rep1yWinQRV6Pw7vgwc/DlvshFIPL/gQu/WOoaSx1ZTIFKdBFTsXRPbDhi/D0dyEQgkv+0Id5rS4FIKWjQBc5Gd37YeOXYPM/+omy2j4Il38E6meXujIRBbrIuPQcgIf+FtrvBZfxJwOt/Sg0zCt1ZSKDFOgioznWAQ9/FR7/B8gk4fyb4IqPwfSFpa5M5DgKdJFC+g7Dpjvgsb+H5DFY/m644uPQuLjUlYmckAJdJF+8Cx79Bmy6ExLdcM71sO6T0PyGUlcmMiYFughAohceuwse+TuIH/UXlVj/KTjjnFJXJjJuCnSZ2pJ98MQ/+H7yvk5/mbd1n4Q5F5S6MpGTpkCXqSkVh83fhI1fhmMH/YWX138K5hW8boBIWVCgy9SSTsCT9/mx5D2vwsI18O77YMHqUlcm8rop0GVqyKTg6e/Bhi9A116Yfwn89t2waG2pKxMpGgW6VLZMGrZ+Hx78HBx5GeZeBNd+FRa/0Z/pKVJBFOhSmbIZePZHfgbEzh0waznc9M+w9CoFuVQsBbpUlmwWXnjAz0l+6Dcw8xy44Tt+GKKCXCqcAl0qg3Pw4k/9VYIObIWmpfDOb8Kyd0AgUOrqRE4LBbqUN+dgx3/5CzDvfwpmnAnX3w3nvRMCwVJXJ3JaKdClPDkHO3/tL8C873GY1gLX3QnLb4Sg/lnL1KR/+VJ+Xn7Yt8h3Pwz18+BtX4EL3gOhSKkrEykpBbqUj72Pw//8Jex6EGpnwTVfgIveD6FoqSsTmRQU6DL5vfKk71rZ8UuoaYar/tpfKShcVerKRCYVBbpMXq9u8cMPX/wpVE2HN/0fWHkLRGpKXZnIpKRAl8nn4Au+Rf7CAxBrgPWfhlX/C2L1pa5MZFJToMvk0bEdfn07PPtDiNT6KwRd8odQNa3UlYmUBQW6lN7hnfDg52HLP0MoBpf/KVz6x1A9o9SViZQVBbqUztE9fvbDp74LwbBvjV/2p1DbXOrKRMrSuALdzK4GvgoEgXucc7efYLuLgUeBG5xzPyhalVJZuvfDhi/6ecnN4OLfgzUfgbpZpa5MpKyNGehmFgTuBN4M7AOeMLMHnHPPF9juc8AvJqJQqQA9B+Chv4X2e8FlYcV7Yc1HoWFuqSsTqQjjaaGvBHY453YCmNn9wHXA8yO2+yPgh8DFRa1Qyt+xDnj4K/D4PZBJwgU3w9qPwfQFpa5MpKKMJ9DnAnvznu8DVuVvYGZzgeuBN6JAlwF9h+GRv4PH/h7S/XDeu+GKP4PGxaWuTKQijSfQC00i7UY8/wrwcedcxkaZc9rMbgFuAWhpaRlniVJ24l2w6evw6Nch0QPn/jZc8QloXlrqykQq2ngCfR8wP+/5PGD/iG3agPtzYd4EvNXM0s65f8vfyDl3N3A3QFtb28gPBSl3iR547C7fKo93wdnXwrpPwRnLSl2ZyJQwnkB/Amg1s0XAK8CNwM35GzjnFg08NrNvAT8ZGeZSoVL9sK8ddm2AJ+6B/sOw9BpY/0mYfX6pqxOZUsYMdOdc2sxuw49eCQL3OueeM7Nbc+vvmuAaZTLpPwJ7HoM9j8DuTf6iEtkUYLDkSt8in3dRqasUmZLMudL0fLS1tbn29vaS/G45Cd37YfcjsGeTD/CDzwMOAmGYuwJaVsOCS2H+Sj+BlohMKDPb7JxrK7ROZ4rKEOegc0degD8CR3f7dZFaH9rnXA8LVsPcizR9rcgko0CfyjJpf0Hl3Zt8F8qeR+HYIb+uuglaLoFVt/oAP+M8XdpNZJLT/9CpJNUPr2weCvC9j0Oy16+b1gKLr/Th3XIpNLX60/JFpGwo0CtZ/1HY+9hQF8r+p/yZmgAzl8HyG3z/d8tqnX4vUgEU6JWk+9Wh0Sd7NsGB5/AHMEMw58Jc98mlMH+VpqYVqUAK9HLlHHS+lBfgj8CRl/26cA3MvxjWfTJ3ALMNItUlLVdEJp4CvVxkM/Da1qHRJ3sehWMH/brqRt9tcvHv+wCfdb4OYIpMQfpfP1ml4v4A5kALfO/jkOzx6xpaYPH6oTHgTUt1AFNEFOiTRrxrxBmYTw4dwGw+G5a/y48+WbAaGuaVtlYRmZQU6KXS89rwMzAPPMvgAczZF/ir3Ldc6seC6wCmiIyDAv10cM5fCDn/DMwju/y6cDXMuxjWfcJ3ocxrg0hNaesVkbKkQJ8I2Yxvceefgdl7wK+rmpE7gPkh3wKfvdxfIFlE5HVSoBdDKu77vAda4Hsfh0S3X9cwHxZdkXcG5lIIBEpbr4hUJAX6qYh3+9De/bAP8FeehEzCr2s+C879naEzMKfNH/21RESKRIE+Hr0Hh/d/H3jWX7XegjDnAlj5+7kzMC+BmsZSVysiU5QCfSTn/AHLgf7v3Zvg8Et+XajKn4G59s98F8q8i3UAU0QmDQV6NuMv2pAf4L2v+XWxab7b5KL35w5gng+hSEnLFRE5kakX6OmEn3VwoAtlz2OQ6PLr6ufCwsuHDmA2n6UDmCJSNio/0OPdsO/xoRkI97UPHcBsWgrnvCPvAGaLTqEXkbJVeYHee3Do7Ms9j/gJrQYOYM5eDhf/Xq4FvhpqmkpdrYhI0ZR3oDvnp4wdnIFwk78mJkAo5g9arvlo7gDmSojWlrRcEZGJVH6B3rUPXvzZUID3vOqXxxp8q/vC9/oulNkX6ACmiEwp5Rfo+9rhpx+FujlDfd8LLvUzEuoApohMYeUX6EveBH/yDExboAOYIiJ5yi/Qo7XqCxcRKUB9FCIiFUKBLiJSIRToIiIVQoEuIlIhFOgiIhVCgS4iUiEU6CIiFUKBLiJSIRToIiIVYlyBbmZXm9mLZrbDzD5RYP17zGxL7vaImZ1f/FJFRGQ0Ywa6mQWBO4FrgGXATWa2bMRmu4ArnHPLgc8Cdxe7UBERGd14WugrgR3OuZ3OuSRwP3Bd/gbOuUecc0dyTx8F5hW3TBERGct4An0usDfv+b7cshP5EPCzQivM7BYzazez9kOHDo2/ShERGdN4Ar3QHLWu4IZm6/GB/vFC651zdzvn2pxzbc3NzeOvUkRExjSe6XP3AfPzns8D9o/cyMyWA/cA1zjnOotTnoiIjNd4WuhPAK1mtsjMIsCNwAP5G5hZC/Aj4L3OuW3FL1NERMYyZgvdOZc2s9uAXwBB4F7n3HNmdmtu/V3AXwCNwNfNX0Uo7Zxrm7iyRURkJHOuYHf4hGtra3Pt7e0l+d0iIuXKzDafqMGsM0VFRCqEAl1EpEIo0EVEKoQCXUSkQijQRUQqhAJdRKRCKNBFRCqEAl1EpEIo0EVEKoQCXUSkQijQRUQqhAJdRKRCKNBFRCqEAl1EpEIo0EVEKoQCXUSkQijQRUQqhAJdRKRCKNBFRCqEAl1EpEIo0EVEKoQCXUSkQijQRUQqRKjUBYjIyXPZLNmeHjLd3WS6usl0HSU78Li7m2x3F5muLrL9cSwSIRCLYtEYFosSGLiPxbBobHBdIBbFYjEsOmJdLEYgGsXC4VK/bRmDAl2kRJxzZHt7yXTlAri7m8zRLjLdXcPCOdPVlQvo3PPubrLd3eDcCV/bwmEC0xoIVFXjkklcPE42kcDF46P+3KiCQR/ssfwPhtjgssH7gQ+PaHT4h8WwD5ITfGgMWxfFAupEOBkKdJHXwTlH9ljfUCB3dftA7soP4C6yXT6Yhz3v6YFM5sQvHgoRbGggWF/vb40ziCxa5Jc11BOorydY7x8HGxr889z2FothZgXrdamUD/h4HJcL+Ww8gUvk38dx8QTZhL8fXBePDy4buS7d3T34oZF/Typ1yn9fi0QKf1gU+kAZ7VtINDL6t4/cPeFwwb9buVCgy5TnnMPF4z5w81vLgyGcC+BcGGe68p93Qzp94hcPBgnW1fnAbWgg2NBAZP58Ag0D4ZsXzrn1AwFu1dVFDxczwyIRiEQI1tcX9bVPxGUyw0M+/0MjkRzfB0mBD5RMbw+uo+O4D5DX9S0kECj8reO4byZ5Hyin8C0kWFdHoKamuH9oFOhSQbKJRC5sR7SWB7syCrWWu8l2deFGa0WaDWv9BuvrCc+Zkwvjwq3lYH09gYYGAjU1Zd3iKwYLBrGamgkJsEKK/i0kMdRlle3oJTXyG0o8Pvq/nwJmfOiDnPGxjxX9vSvQZVJxyeRg0B7Xn3xcazl3MDD33CUSo752oK7OB3JDA4GGeqJnnJF77sN3MJDr6wnUNxCclgvm2lr15ZaRkn0LSSTyvoWM/kESW7p0QupQoEvRuVSKTE/POFrL3Xnr/b3r7x/1tQM1NbnuimkE6+uJLjrTP89rLQ8Gcn5rua4OCwZP019AphoLBrHqagLV1SWtQ4EuRbH7Ax8guXs32aNdZPv6Rt3WqquHDvQ1NBBumU+s/txRWsv1BKdNI1hXh4X0T1bkRPS/Q4oisnAh4TNm5R3gmzY8kAcO+NXV+a/DIlJ0CnQpitmf+UypSxCZ8sZ1pMfMrjazF81sh5l9osB6M7Ov5dZvMbMVxS9VRERGM2agm1kQuBO4BlgG3GRmy0Zsdg3QmrvdAnyjyHWKiMgYxtNCXwnscM7tdM4lgfuB60Zscx1wn/MeBaaZ2ewi1yoiIqMYT6DPBfbmPd+XW3ay22Bmt5hZu5m1Hzp06GRrFRGRUYwn0Aud5jbyvNrxbINz7m7nXJtzrq25uXk89YmIyDiNJ9D3AfPzns8D9p/CNiIiMoHGE+hPAK1mtsjMIsCNwAMjtnkAeF9utMslQJdz7tUi1yoiIqMYcxy6cy5tZrcBvwCCwL3OuefM7Nbc+ruAnwJvBXYAfcAHJq5kEREpxNypTjP5en+x2SFg9yn+eBPQUcRypDi0XyYf7ZPJ6fXslwXOuYIHIUsW6K+HmbU759pKXYcMp/0y+WifTE4TtV80J6iISIVQoIuIVIhyDfS7S12AFKT9Mvlon0xOE7JfyrIPXUREjleuLXQRERmh5IFuZhkze9rMnjOzZ8zsI2YWGLHNj81sU+7xTDPbZWaz8tZ//QTT+r7fzLbnbu+f+HdTGSZ4n/zczI6a2U8m/p1UlonaL2Z2gZltyr3uFjO74fS8o/I3gftkgZltznvtW8dVkHOupDegN+/xTOC/gP+bt2wafuKvF4BFuWW3At/JPV4BbAHCI153BrAzdz8993h6qd9vOdwmap/k1l0JXAv8pNTvs9xuE/h/ZSnQmns8B3gVmFbq91sOtwncJxEgmntcC7wMzBmrnpK30PM55w7i51O/zcwGJvz6HeDf8dP23phbdjew2MzWA3cAtznnUiNe7irgl865w865I8Avgasn+j1UmiLvE5xz/w30THjhFa6Y+8U5t805tz33eD9wENDseSepyPsk6ZxL5J5GGWdvyqQKdADn3E58XTNzi24C/il3uym3TRb4A+CHwDbn3IYCLzWuKX1lbEXcJ1JEE7FfzGwlvnX40gSVXdGKuU/MbL6ZbcHn2OdyH7ajmnSBnmMAZnYGsAR4yDm3DUib2bkAzrmngWeBr4/2GiNoSM+pK8Y+keIr2n7JXZTm28AHcqEjp6Yo+8Q5t9c5tzz3Gu/Pvd6oJl2gm9mZQAb/te8GfP/3LjN7GVjI0NcWgGzuVoim9C2SIu4TKaJi7hczqwf+A/i081cdk1MwEf9Xci3z54A1Y207qQLdzJqBu4A7nD8acBNwtXNuoXNuIXARw/8go/kF8BYzm25m04G35JbJSSjyPpEiKeZ+MT8t9r/iLyP5LxNUcsUr8j6ZZ2ZVucfTgcuAF8f6uTGnzz0NqszsaSAMpPFf+b5sZguBFmCwteCc22Vm3Wa2yjn32Ggv6pw7bGafxc/nDvD/nHOHJ+INVKAJ2ScAZrYROAuoNbN9wIecc/qgHZ+J2i/vBtYCjWb2u7llv5vrFpDRTdQ+ORv4kpk5fBfOF51zW8cqRmeKiohUiEnV5SIiIqdOgS4iUiEU6CIiFUKBLiJSIRToIiIVQoEuIlIhFOgiIhVCgS4iUiH+P6DjaUknUmk+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(days0,fraction_label)\n",
    "plt.plot(days0,fraction_leaf)\n",
    "plt.plot(days0,accuracy_leaf)\n",
    "plt.plot(days1,change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T16:13:36.803002Z",
     "iopub.status.busy": "2021-02-26T16:13:36.802695Z",
     "iopub.status.idle": "2021-02-26T16:13:36.857531Z",
     "shell.execute_reply": "2021-02-26T16:13:36.854168Z",
     "shell.execute_reply.started": "2021-02-26T16:13:36.802970Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, previous_pred_block, THRESHOLDS, y_test, Tree, HC, feature_importances, decision_trees, statistics):\n",
    "    \n",
    "    #Initialize Dictionary at Day 0\n",
    "    \n",
    "    if DAYS == 0:\n",
    "        statistics = {'%classified'     :{}, 'N_classified'         :{},  'N_predicted' : {},\n",
    "                      'leaf_accuracy'   :{}, 'total_leaf_accuracy'  :{},\n",
    "                      'leaf_precision'  :{}, 'total_leaf_precision' :{},\n",
    "                      'leaf_recall'     :{}, 'total_leaf_recall'    :{},\n",
    "                      'label_precision' :{}, \n",
    "                      'label_recall'    :{}, \n",
    "                      'block_precision' :{},\n",
    "                      'block_recall'    :{},\n",
    "                      'block_Nchange'   :{}, 'block_Pchange'        :{},\n",
    "                      '%blocking'       :{},\n",
    "                      'tree_error'      :{},\n",
    "                      'thresholds'      :{}}\n",
    "\n",
    "        for leaf in Tree._get_leaf_nodes(): \n",
    "            statistics['precision_'+leaf] = {}\n",
    "            statistics['recall_'+leaf]    = {}\n",
    "            statistics['f1_'+leaf]        = {}\n",
    "            \n",
    "        feature_importances = pd.DataFrame(index = X_col)\n",
    "        decision_trees = {}\n",
    "    \n",
    "    #Get Daily information\n",
    "    \n",
    "    check_block = pred.isin(Tree._get_internal_nodes())\n",
    "    index_block = check_block[check_block].index        \n",
    "        \n",
    "    total_check_leaf = current_pred.isin(Tree._get_leaf_nodes())   #of all predictions which are now leaf\n",
    "    total_index_leaf = total_check_leaf[total_check_leaf].index\n",
    "        \n",
    "    if DAYS > 0:\n",
    "        block = pd.concat([previous_pred_block, pred.loc[previous_pred_block.index]], axis=1, keys = [0,1])\n",
    "        block['Nchange'] = block.apply(lambda row: 0 if row[1] in Tree._get_descendants(row[0])+[row[0]] else 1, axis = 1)\n",
    "        block['Pchange'] = block.apply(lambda row: 1 if row[1] in Tree._get_descendants(row[0]) else 0, axis = 1)\n",
    "    previous_pred_block = pred.loc[index_block]\n",
    "    #previous_index_block = index_block\n",
    "\n",
    "    y_test = y_test['detailedMatchClassification']\n",
    "    test_pred = pd.concat([y_test.loc[index_leaf], current_pred[index_leaf]], axis=1, keys = [0,1])\n",
    "    test_pred['TE'] = test_pred.apply(lambda row: Tree._tree_distance(row[0], row[1]), axis = 1)\n",
    "    \n",
    "    #Update Dictionary\n",
    "    \n",
    "    statistics['thresholds'][DAYS]      = THRESHOLDS\n",
    "    statistics['%classified'][DAYS]     = current_pred.isin(Tree._get_leaf_nodes()).sum() / len(y_test)\n",
    "    statistics['N_classified'][DAYS]    = int(len(index_leaf))\n",
    "    statistics['N_predicted'][DAYS]     = int(len(pred))\n",
    "\n",
    "    statistics['leaf_accuracy'][DAYS]   = metrics.accuracy_score(y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "    statistics['leaf_precision'][DAYS]  = precision_score_ancestors(Tree, y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "    statistics['leaf_recall'][DAYS]     = recall_score_ancestors(Tree, y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "\n",
    "    for leaf in Tree._get_leaf_nodes():\n",
    "        leaf_ix = pred.loc[pred == leaf].index\n",
    "        statistics['precision_'+leaf][DAYS] = precision_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "        statistics['recall_'+leaf][DAYS]    = recall_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "        statistics['f1_'+leaf][DAYS]        = f1_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix], beta = 1)\n",
    "        \n",
    "    for clf in list(HC.stages.keys()):\n",
    "        feature_importances[clf+'_'+str(DAYS)] = HC.stages[clf]['classifier'].feature_importances_ if isinstance(HC.stages[clf]['classifier'],RandomForestClassifier) else None\n",
    "        decision_trees[clf+'_'+str(DAYS)]      = HC.stages[clf]['classifier'].tree_ if isinstance(HC.stages[clf]['classifier'],DecisionTreeClassifier) else None\n",
    "\n",
    "    statistics['total_leaf_accuracy'][DAYS]  = metrics.accuracy_score(y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "    statistics['total_leaf_precision'][DAYS] = precision_score_ancestors(Tree, y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "    statistics['total_leaf_recall'][DAYS]    = recall_score_ancestors(Tree, y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "\n",
    "    statistics['label_precision'][DAYS]  = precision_score_ancestors(Tree, y_test.loc[index_leaf.union(index_block)], pred.loc[index_leaf.union(index_block)]) \n",
    "    statistics['label_recall'][DAYS]     = recall_score_ancestors(Tree, y_test.loc[index_leaf.union(index_block)], pred.loc[index_leaf.union(index_block)])  \n",
    "\n",
    "    statistics['block_precision'][DAYS] = precision_score_ancestors(Tree, y_test.loc[index_block], pred.loc[index_block]) if DAYS < END else None\n",
    "    statistics['block_recall'][DAYS]    = recall_score_ancestors(Tree, y_test.loc[index_block], pred.loc[index_block]) if DAYS < END else None\n",
    "    statistics['block_Nchange'][DAYS]   = block['Nchange'].sum() / block['Nchange'].count() if DAYS > 0 else None\n",
    "    statistics['block_Pchange'][DAYS]   = block['Pchange'].sum() / block['Pchange'].count() if DAYS > 0 else None\n",
    "    statistics['%blocking'][DAYS]       = HC.blocking if len(total_index_leaf) != len(y_test) else {'ORDERS':None,'KNOWN':None,'UNHAPPY':None}\n",
    "\n",
    "    statistics['tree_error'][DAYS]      = np.mean(test_pred['TE'])\n",
    "        \n",
    "    return statistics, feature_importances, decision_trees, previous_pred_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T21:13:03.309771Z",
     "iopub.status.busy": "2021-02-26T21:13:03.309490Z",
     "iopub.status.idle": "2021-02-26T21:13:03.345780Z",
     "shell.execute_reply": "2021-02-26T21:13:03.344041Z",
     "shell.execute_reply.started": "2021-02-26T21:13:03.309744Z"
    }
   },
   "outputs": [],
   "source": [
    "def global_scores(y_true, y_pred, average = 'macro'):\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = average)\n",
    "    return accuracy, scores[0], scores[1], scores[2]\n",
    "\n",
    "def local_scores(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = None, labels = labels, beta = 1)\n",
    "    return scores[0], scores[1], scores[2]\n",
    "\n",
    "def class_report(y_true, y_pred):\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "\n",
    "def _aggregate_class_sets(set_function, y_true, y_pred):\n",
    "    intersection_sum = 0\n",
    "    true_sum = 0\n",
    "    predicted_sum = 0\n",
    "    for true, pred in zip(list(y_true), list(y_pred)):\n",
    "        true_set = set([true] + set_function(true))\n",
    "        pred_set = set([pred] + set_function(pred))\n",
    "        intersection_sum += len(true_set.intersection(pred_set))\n",
    "        true_sum += len(true_set)\n",
    "        predicted_sum += len(pred_set)\n",
    "    return (true_sum, predicted_sum, intersection_sum)\n",
    "\n",
    "def precision_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    if predicted_sum == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return intersection_sum / predicted_sum\n",
    "\n",
    "def recall_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    if true_sum == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return intersection_sum / true_sum\n",
    "\n",
    "def f1_score_ancestors(class_hierarchy, y_true, y_pred, beta):\n",
    "    precision = precision_score_ancestors(class_hierarchy, y_true, y_pred)\n",
    "    recall = recall_score_ancestors(class_hierarchy, y_true, y_pred)\n",
    "    if (precision == None) or (recall == None):\n",
    "        return None\n",
    "    elif (precision == 0) or (recall == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T22:57:33.376747Z",
     "iopub.status.busy": "2021-02-23T22:57:33.376493Z",
     "iopub.status.idle": "2021-02-23T22:57:33.395484Z",
     "shell.execute_reply": "2021-02-23T22:57:33.393929Z",
     "shell.execute_reply.started": "2021-02-23T22:57:33.376723Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ClassHierarchy:\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.nodes = {}\n",
    "        \n",
    "    def add_node(self, children, parent):\n",
    "        for child in children:\n",
    "            self.nodes[child] = parent\n",
    "            \n",
    "    def _get_leaf_nodes(self):\n",
    "        leaf_nodes = []\n",
    "        for child in self.nodes.keys():\n",
    "            if self._get_children(child) == []:\n",
    "                leaf_nodes.append(child)\n",
    "        return leaf_nodes\n",
    "    \n",
    "    def _get_internal_nodes(self):\n",
    "        internal_nodes = []\n",
    "        leaves = self._get_leaf_nodes()\n",
    "        for child in self.nodes.keys():\n",
    "            if (child != self.root) and (child not in leaves):\n",
    "                internal_nodes.append(child)\n",
    "        return internal_nodes\n",
    "\n",
    "    def _get_children(self, parent):\n",
    "        return sorted([child for child, childs_parent in\n",
    "                       self.nodes.items() if childs_parent == parent])\n",
    "    \n",
    "    def _get_parent(self, child):\n",
    "        return self.nodes[child] if (child in self.nodes and child != self.root) else self.root\n",
    "    \n",
    "    def _get_ancestors(self, child):\n",
    "        # Not including root, not including the child\n",
    "        ancestors = []\n",
    "        while True:\n",
    "            child = self._get_parent(child)\n",
    "            if child == self.root:\n",
    "                break\n",
    "            ancestors.append(child)\n",
    "        return ancestors\n",
    "    \n",
    "    def _get_descendants(self, parent):\n",
    "        # Return a list of the descendants of this node, not including the parent\n",
    "        descendants = []\n",
    "        self._depth_first(parent, descendants)\n",
    "        descendants.remove(parent)\n",
    "        return descendants\n",
    "    \n",
    "    def _depth_first(self, parent, classes):\n",
    "        classes.append(parent)\n",
    "        for node in self._get_children(parent):\n",
    "            self._depth_first(node, classes)\n",
    "            \n",
    "    def _tree_distance(self, y_test, pred):\n",
    "        \n",
    "        y_test_path = [y_test] + self._get_ancestors(y_test) + [self.root] if y_test != self.root else [y_test] + self._get_ancestors(y_test)\n",
    "        pred_path   = [pred] + self._get_ancestors(pred) + [self.root] if pred != self.root else [pred] + self._get_ancestors(pred)\n",
    "        \n",
    "        y_test_edges = []\n",
    "        for ix, node in enumerate(y_test_path):\n",
    "            length = len(y_test_path)\n",
    "            if ix < length - 1:\n",
    "                y_test_edges.append((node, y_test_path[ix+1]))\n",
    "                \n",
    "        pred_edges = []\n",
    "        for ix, node in enumerate(pred_path):\n",
    "            length = len(pred_path)\n",
    "            if ix < length - 1:\n",
    "                pred_edges.append((node, pred_path[ix+1]))        \n",
    "        \n",
    "        tree_distance = len([edge for edge in y_test_edges + pred_edges if edge not in pred_edges or edge not in y_test_edges])\n",
    "        \n",
    "        return tree_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T15:36:21.347391Z",
     "iopub.status.busy": "2021-02-24T15:36:21.347141Z",
     "iopub.status.idle": "2021-02-24T15:36:21.406946Z",
     "shell.execute_reply": "2021-02-24T15:36:21.405842Z",
     "shell.execute_reply.started": "2021-02-24T15:36:21.347367Z"
    }
   },
   "outputs": [],
   "source": [
    "class HierarchicalClassifier:\n",
    "\n",
    "    def __init__(self, class_hierarchy):\n",
    "        self.stages = {}\n",
    "        self.class_hierarchy = class_hierarchy\n",
    "        self._create_stages(self.stages, self.class_hierarchy.root, 0)\n",
    "\n",
    "    def _create_stages(self, stages, parent, depth):\n",
    "        # Get the children of this parent\n",
    "        children = self.class_hierarchy._get_children(parent)\n",
    "        \n",
    "        if len(children) > 0:\n",
    "            stage = {}\n",
    "            stage['depth'] = depth\n",
    "            stage['labels'] = children\n",
    "            stage['classes'] = stage['labels'] + [parent]\n",
    "            stage['target'] = 'target_stage_' + parent\n",
    "            stages[parent] = stage\n",
    "\n",
    "            for node in children:\n",
    "                self._create_stages(stages, node, depth + 1)\n",
    "                \n",
    "    def _recode_label(self, classes, label):\n",
    "\n",
    "        while label != self.class_hierarchy.root and label not in classes:\n",
    "            label = self.class_hierarchy._get_parent(label)\n",
    "        return label\n",
    "                \n",
    "    def _prep_data(self, X, y):\n",
    "        \n",
    "        Xcols = range(0, X.shape[1])\n",
    "        Ycol = X.shape[1]\n",
    "        \n",
    "        df = pd.concat([X, y], axis=1, ignore_index=True)\n",
    "        # Create a target column for each stage with the recoded labels\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            df[stage_info['target']] = pd.DataFrame.apply(df[[Ycol]],\n",
    "                                    lambda row: self._recode_label(stage_info['classes'], row[Ycol]),\n",
    "                                    axis=1)\n",
    "        return df, Xcols\n",
    "    \n",
    "    def _label_mapping(self, y_train, stage_name):\n",
    "        labels = np.unique(y_train)\n",
    "        int_label_mapping = dict(enumerate(labels))\n",
    "        label_int_mapping = {y:x for x,y in int_label_mapping.items()}\n",
    "        self.stages[stage_name]['mapping'] = {'int_label':int_label_mapping,\n",
    "                                              'label_int':label_int_mapping}\n",
    "        \n",
    "    def _class_weights(self, y_train, stage_name):\n",
    "        class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        self.stages[stage_name]['classifier'].set_params(class_weight = class_weights)\n",
    "    \n",
    "    def fit_classifiers(self, classifiers):\n",
    "        \"\"\"\n",
    "        Fit a classifier to each stage\n",
    "        \"\"\"\n",
    "        if classifiers.keys() != self.stages.keys():\n",
    "             raise ValueError('Your assigned classifiers do not match the stages of the hierarchy, fit a classifier to each of: '+self.stages.keys())\n",
    "        else:\n",
    "            for stage, classifier in classifiers.items():\n",
    "                self.stages[stage]['classifier'] = classifier\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a multi-classifier from training data (X, y).\n",
    "        \"\"\"\n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        self.scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_train = dfFilter[Xcols]\n",
    "            y_train = dfFilter[[stage_info['target']]]\n",
    "                        \n",
    "            #warning - no samples to fit for stage\n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                y_train_col = pd.Series(np.ravel(y_train))\n",
    "                \n",
    "                self._class_weights(y_train_col, stage_name)\n",
    "                self._label_mapping(y_train_col, stage_name)\n",
    "\n",
    "                y_encoded = y_train_col.map(stage_info['mapping']['label_int'])\n",
    "\n",
    "                if len(stage_info['labels']) > 2:\n",
    "                    y_dummy = pd.DataFrame(np_utils.to_categorical(y_encoded))\n",
    "                    y_train_NN = y_dummy\n",
    "                else:\n",
    "                    y_train_NN = np.asarray(y_encoded).reshape((-1,1))\n",
    "\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_train))\n",
    "                stage_info['classifier'].fit(X_scaled, y_train_NN)\n",
    "            else:\n",
    "                stage_info['classifier'] = stage_info['classifier'].fit(X_train, y_train)\n",
    "            #print('Stage '+stage_name+' succesfully fitted')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if X_test.empty:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                if len(stage_info['labels']) == 2:\n",
    "                    y_pred = pd.Series(stage_info['classifier'].predict(X_scaled).flatten()).map(stage_info['mapping']['int_label'])\n",
    "                else:\n",
    "                    y_pred = pd.Series(stage_info['classifier'].predict(X_scaled)).map(stage_info['mapping']['int_label'])\n",
    "                y_hat_stage = pd.DataFrame(y_pred.values, index = X_test.index)\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(stage_info['classifier'].predict(X_test), index = X_test.index)\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]     \n",
    "    \n",
    "    def predict_proba(self, X, threshold = 0.5):\n",
    "        \n",
    "        self.blocking = {}\n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            max_prob = np.amax(y_proba, axis=1)              #max probability of classes\n",
    "            max_class = np.argmax(y_proba, axis=1)           #class number with max probability\n",
    "            accept_index = np.where(max_prob >= threshold)[0]#indexes which are above threshold\n",
    "            accept_class = np.take(max_class, accept_index)  #filtered list of orders which are above threshold\n",
    "            \n",
    "            if len(accept_class) > 0: #check if samples reach threshold\n",
    "                accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             #convert class number into label\n",
    "                y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  #set labels to correct position\n",
    "                self.blocking[stage_name] = 1 - (len(accept_class) / len(max_class)) #blocking factor\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "                self.blocking[stage_name] = 1\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "    \n",
    "    def predict_proba2(self, X, THRESHOLDS):\n",
    "        \n",
    "        self.blocking = {}\n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if X_test.empty:\n",
    "                self.blocking[stage_name] = 1\n",
    "                continue\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            max_prob = np.amax(y_proba, axis=1)              #max probability of classes\n",
    "            max_class = np.argmax(y_proba, axis=1)           #class number with max probability\n",
    "            max_class_thresholds = np.vectorize(lambda x: THRESHOLDS[y_classes[x]])(max_class)  #get node specific threshold\n",
    "            \n",
    "            #print(pd.DataFrame({'max_prob':max_prob,'max_class':max_class,'max_class_thresholds':max_class_thresholds}))\n",
    "            \n",
    "            accept_index = np.where(max_prob >= max_class_thresholds)[0]\n",
    "\n",
    "            accept_class = np.take(max_class, accept_index)  #filtered list of orders which are above threshold\n",
    "            \n",
    "            if len(accept_class) > 0: #check if samples reach threshold\n",
    "                accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             #convert class number into label\n",
    "                y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  #set labels to correct position\n",
    "                \n",
    "#                 pja = pd.DataFrame({'max_prob':max_prob,'max_class':np.vectorize(lambda x: y_classes[x])(max_class)})\n",
    "#                 pja['accept_class'] = pd.Series(data = accept_class, index = accept_index)\n",
    "#                 print(pja)\n",
    "                \n",
    "                self.blocking[stage_name] = 1 - (len(accept_class) / len(max_class)) #blocking factor\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "                self.blocking[stage_name] = 1\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "    \n",
    "    def get_probabilities(self, X, y):\n",
    "        \n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        \n",
    "        stage_number = 0\n",
    "        \n",
    "        y_hat = pd.DataFrame(columns = [self.class_hierarchy.root], index = X.index)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "                \n",
    "            stage_number += 1             \n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_test = dfFilter[Xcols]\n",
    "            y_test = dfFilter[[stage_info['target']]]\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            y_hat_stage = pd.DataFrame(y_proba, index = X_test.index)\n",
    "\n",
    "            for col, label in enumerate(y_classes):\n",
    "                y_hat[label] = y_hat_stage[col]\n",
    "               \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T21:14:52.219105Z",
     "iopub.status.busy": "2021-02-26T21:14:52.218819Z",
     "iopub.status.idle": "2021-02-26T21:14:52.255803Z",
     "shell.execute_reply": "2021-02-26T21:14:52.254770Z",
     "shell.execute_reply.started": "2021-02-26T21:14:52.219079Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_probs(day):\n",
    "    HC = HierarchicalClassifier(ch)\n",
    "    HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '1_criterion'], max_depth = hypers.loc[day, '1_max_depth']),\n",
    "                        'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '2_criterion'], max_depth = hypers.loc[day, '2_max_depth']),\n",
    "                        'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[day, '3_max_depth'], n_estimators = hypers.loc[day, '3_n_estimators'])})\n",
    "    \n",
    "    X, y  = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, day)\n",
    "    index = range(0, X.shape[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "    HC.fit(X_train,y_train)\n",
    "    y_hat = HC.get_probabilities(X_train, y_train)\n",
    "\n",
    "    probs = pd.concat([y_train, y_hat], axis=1)\n",
    "    \n",
    "    return(probs)\n",
    "\n",
    "def opt_threshold(probs, node, day, certainty, stepsize = 0.005):\n",
    "    \n",
    "    if node == 1:\n",
    "        probabilities_for = 'UNKNOWN'\n",
    "        y_pos_filter_list = ['UNKNOWN']\n",
    "        y_neg_filter_list = ['HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "    elif node == 2:\n",
    "        probabilities_for = 'KNOWN'\n",
    "        y_pos_filter_list = ['HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['UNKNOWN']\n",
    "    elif node == 3:\n",
    "        probabilities_for = 'HAPPY'\n",
    "        y_pos_filter_list = ['HAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "    elif node == 4:\n",
    "        probabilities_for = 'UNHAPPY'\n",
    "        y_pos_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['HAPPY']\n",
    "    elif node == 5:\n",
    "        probabilities_for = 'MILDLY UNHAPPY'\n",
    "        y_pos_filter_list = ['MILDLY UNHAPPY']\n",
    "        y_neg_filter_list = ['MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "    elif node == 6:\n",
    "        probabilities_for = 'MEDIUM UNHAPPY'\n",
    "        y_pos_filter_list = ['MEDIUM UNHAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "    elif node == 7:\n",
    "        probabilities_for = 'HEAVILY UNHAPPY'\n",
    "        y_pos_filter_list = ['HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY']\n",
    "    else:\n",
    "        raise Exception('''Error: undefined node has been passed. Node options (integer input):\n",
    "                           1: Unknown\n",
    "                           2: Known\n",
    "                           3: Happy\n",
    "                           4: Unhappy\n",
    "                           5: Mildly Unhappy\n",
    "                           6: Medium Unhappy\n",
    "                           7: Heavily Unhappy''')\n",
    "        \n",
    "    y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)][probabilities_for]\n",
    "    y_pos = y_pos.sort_values()\n",
    "    y_pos = y_pos.reset_index(drop = True)    \n",
    "    \n",
    "    y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)][probabilities_for]\n",
    "    y_neg = y_neg.sort_values()\n",
    "    y_neg = y_neg.reset_index(drop = True)\n",
    "\n",
    "    if node < 5:\n",
    "        boundary = 0.5\n",
    "    else:\n",
    "        boundary = (1/3)\n",
    "    \n",
    "#     y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)]#[probabilities_for]\n",
    "#     y_pos = y_pos[y_pos[probabilities_for] > boundary][probabilities_for]\n",
    "#     y_pos = y_pos.sort_values()\n",
    "#     y_pos = y_pos.reset_index(drop = True)  \n",
    "\n",
    "#     y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)]#[probabilities_for]\n",
    "#     y_neg = y_neg[y_neg[probabilities_for] > boundary][probabilities_for]\n",
    "#     y_neg = y_neg.sort_values()\n",
    "#     y_neg = y_neg.reset_index(drop = True)\n",
    "    \n",
    "    lowerbound = y_neg[(math.floor(certainty * (len(y_neg)-1) ))]\n",
    "    \n",
    "    # Potential thresholds\n",
    "    V = np.concatenate((y_pos, y_neg))\n",
    "    V = np.append(V, 0.5)\n",
    "    V = np.unique(V) # np.unique() also sorts\n",
    "    \n",
    "    #V = V[0:(len(V)-1)] #discard the highest probability as option, putting that as threshold is nonsensical since criterion is 'probability > threshold'\n",
    "    V = V[V >= max(lowerbound, 0.5)] #define allowed search space\n",
    "    #V_length = len(V) \n",
    "    \n",
    "    steps = math.floor((V.max() - V.min()) / stepsize)\n",
    "    S = np.linspace(V.min(), V.max(), steps)\n",
    "    \n",
    "    thresholds = pd.DataFrame({'threshold'     : [0]*steps,\n",
    "                               'F_score'       : [0]*steps})\n",
    "#                                'perc_rejected' : [0]*steps,\n",
    "#                                'perc_accepted' : [0]*steps,\n",
    "#                                'count_rejected': [0]*steps,\n",
    "#                                'count_accepted': [0]*steps})\n",
    "    \n",
    "#     thresholds = pd.DataFrame({'threshold'      : [0]*V_length,\n",
    "#                                'F_score'        : [0]*V_length})\n",
    "    \n",
    "    for i in range(steps):        \n",
    "        threshold = S[i]       \n",
    "#         threshold = V[i] \n",
    "        beta      = 1\n",
    "        positives = len(y_pos[y_pos >= threshold])  #CHANGED > into >=\n",
    "        negatives = len(y_neg[y_neg >= threshold])  #CHANGED > into >=\n",
    "        recall    = positives / len(y_pos)\n",
    "        precision = positives / (positives + negatives)\n",
    "\n",
    "        thresholds.loc[i, 'threshold']       = threshold\n",
    "        thresholds.loc[i, 'F_score']         = ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall) if ((beta ** 2 * precision) + recall) != 0 else 0\n",
    "        \n",
    "    #print(thresholds)\n",
    "        \n",
    "    F_score         = thresholds['F_score'].max()\n",
    "    opt_index       = thresholds['F_score'].argmax()\n",
    "    threshold       = thresholds.loc[opt_index, 'threshold']\n",
    "    \n",
    "    return(probabilities_for, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
