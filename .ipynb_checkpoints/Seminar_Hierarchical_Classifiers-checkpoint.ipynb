{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:49:58.888811Z",
     "iopub.status.busy": "2021-02-08T09:49:58.886520Z",
     "iopub.status.idle": "2021-02-08T09:50:07.183639Z",
     "shell.execute_reply": "2021-02-08T09:50:07.182739Z",
     "shell.execute_reply.started": "2021-02-08T09:49:58.888326Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectPercentile, mutual_info_classif, RFE, RFECV, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T15:38:51.952989Z",
     "iopub.status.busy": "2021-02-09T15:38:51.950880Z",
     "iopub.status.idle": "2021-02-09T15:38:52.158150Z",
     "shell.execute_reply": "2021-02-09T15:38:52.155447Z",
     "shell.execute_reply.started": "2021-02-09T15:38:51.952892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/Users/LV/Documents/GitHub/Seminar-QM-BA/functions.py'>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:50:09.509338Z",
     "iopub.status.busy": "2021-02-08T09:50:09.509056Z",
     "iopub.status.idle": "2021-02-08T09:51:55.845037Z",
     "shell.execute_reply": "2021-02-08T09:51:55.842421Z",
     "shell.execute_reply.started": "2021-02-08T09:50:09.509311Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/LV/Desktop/data_bol_complete.csv', low_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:51:55.849349Z",
     "iopub.status.busy": "2021-02-08T09:51:55.849024Z",
     "iopub.status.idle": "2021-02-08T09:52:23.470921Z",
     "shell.execute_reply": "2021-02-08T09:52:23.469765Z",
     "shell.execute_reply.started": "2021-02-08T09:51:55.849316Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['orderDate']                   = pd.to_datetime(df['orderDate'])\n",
    "df['cancellationDate']            = pd.to_datetime(df['cancellationDate'])\n",
    "df['promisedDeliveryDate']        = pd.to_datetime(df['promisedDeliveryDate'])\n",
    "df['shipmentDate']                = pd.to_datetime(df['shipmentDate'])\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'])\n",
    "df['startDateCase']               = pd.to_datetime(df['startDateCase'])\n",
    "df['returnDateTime']              = pd.to_datetime(df['returnDateTime'])\n",
    "df['registrationDateSeller']      = pd.to_datetime(df['registrationDateSeller'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:52:23.476152Z",
     "iopub.status.busy": "2021-02-08T09:52:23.475773Z",
     "iopub.status.idle": "2021-02-08T09:52:23.487507Z",
     "shell.execute_reply": "2021-02-08T09:52:23.486555Z",
     "shell.execute_reply.started": "2021-02-08T09:52:23.476114Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "DATE = ['orderDate']\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength','promisedDeliveryDays','partnerSellingDays', 'orderCorona']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "YEAR = ['orderYear2020']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "HISTORICX = []\n",
    "historic_variable = ['transporterCode','sellerId','productGroup']\n",
    "for x in range(len(historic_variable)):\n",
    "    HISTORICX = HISTORICX + [historic_variable[x]+'HistoricHappyX',historic_variable[x]+'HistoricUnhappyX',historic_variable[x]+'HistoricUnknownX']\n",
    "\n",
    "#Determinants:\n",
    "DETERMINANT = ['noReturn', 'noCase', 'noCancellation', 'onTimeDelivery']\n",
    "\n",
    "#Classifications\n",
    "CLASSIFICATION = ['generalMatchClassification','detailedMatchClassification','binaryMatchClassification','determinantClassification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T11:19:00.487012Z",
     "iopub.status.busy": "2021-02-09T11:19:00.486742Z",
     "iopub.status.idle": "2021-02-09T11:19:00.492745Z",
     "shell.execute_reply": "2021-02-09T11:19:00.491580Z",
     "shell.execute_reply.started": "2021-02-09T11:19:00.486987Z"
    }
   },
   "outputs": [],
   "source": [
    "X_col = BASIC + WEEK + MONTH + YEAR + GROUP + TRANSPORTERX + KNOWNX + PRODUCTX + SELLERX + HISTORICX\n",
    "Y_col = ['detailedMatchClassification','generalMatchClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T11:42:56.435153Z",
     "iopub.status.busy": "2021-02-09T11:42:56.433426Z",
     "iopub.status.idle": "2021-02-09T11:43:04.405884Z",
     "shell.execute_reply": "2021-02-09T11:43:04.403091Z",
     "shell.execute_reply.started": "2021-02-09T11:42:56.435073Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = df.sample(n = 500000, replace = False, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T10:57:25.324738Z",
     "iopub.status.busy": "2021-02-09T10:57:25.324481Z",
     "iopub.status.idle": "2021-02-09T10:57:25.333030Z",
     "shell.execute_reply": "2021-02-09T10:57:25.330986Z",
     "shell.execute_reply.started": "2021-02-09T10:57:25.324714Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "# classifier = RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = 10)\n",
    "# classifier = svm.LinearSVC(C=1, penalty=\"l1\", dual=False, class_weight = 'balanced')\n",
    "# classifier = HistGradientBoostingClassifier(random_state=0)\n",
    "# classifier = DecisionTreeClassifier(random_state=0, max_depth=10, class_weight='balanced')\n",
    "# classifier = KerasClassifier(build_fn = functions.neuralNetwork,epochs = 10,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:03:38.808059Z",
     "iopub.status.busy": "2021-02-09T18:03:38.807810Z",
     "iopub.status.idle": "2021-02-09T18:03:38.840345Z",
     "shell.execute_reply": "2021-02-09T18:03:38.838921Z",
     "shell.execute_reply.started": "2021-02-09T18:03:38.808035Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = ClassHierarchy('ORDERS')\n",
    "ch.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "ch.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "ch.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "HC = HierarchicalClassifier(ch)\n",
    "HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "                    'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = 20),\n",
    "                    'UNHAPPY' : KerasClassifier(build_fn = functions.neuralNetwork, epochs = 20,verbose = 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T12:58:34.243568Z",
     "iopub.status.busy": "2021-02-09T12:58:34.239924Z",
     "iopub.status.idle": "2021-02-09T12:58:34.513182Z",
     "shell.execute_reply": "2021-02-09T12:58:34.505798Z",
     "shell.execute_reply.started": "2021-02-09T12:58:34.243500Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ch = ClassHierarchy('ORDERS')\n",
    "# ch.add_node(['OTHER','UNHAPPY'], 'ORDERS')\n",
    "# ch.add_node(['HAPPY','UNKNOWN'], 'OTHER')\n",
    "# ch.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "# HC = HierarchicalClassifier(ch)\n",
    "# HC.fit_classifiers({'ORDERS'  : HistGradientBoostingClassifier(random_state=0),\n",
    "#                     'OTHER'   : HistGradientBoostingClassifier(random_state=0),\n",
    "#                     'UNHAPPY' : HistGradientBoostingClassifier(random_state=0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single fit single point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T17:59:30.757739Z",
     "iopub.status.busy": "2021-02-09T17:59:30.757492Z",
     "iopub.status.idle": "2021-02-09T17:59:58.985401Z",
     "shell.execute_reply": "2021-02-09T17:59:58.984504Z",
     "shell.execute_reply.started": "2021-02-09T17:59:30.757714Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 0)\n",
    "index = range(0, X.shape[0])\n",
    "X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size=0.2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:03:41.479280Z",
     "iopub.status.busy": "2021-02-09T18:03:41.479030Z",
     "iopub.status.idle": "2021-02-09T18:04:52.151130Z",
     "shell.execute_reply": "2021-02-09T18:04:52.148582Z",
     "shell.execute_reply.started": "2021-02-09T18:03:41.479256Z"
    }
   },
   "outputs": [],
   "source": [
    "HC = HC.fit(X_train,y_train['detailedMatchClassification'])\n",
    "pred = HC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:04:52.154718Z",
     "iopub.status.busy": "2021-02-09T18:04:52.154027Z",
     "iopub.status.idle": "2021-02-09T18:04:58.913705Z",
     "shell.execute_reply": "2021-02-09T18:04:58.912521Z",
     "shell.execute_reply.started": "2021-02-09T18:04:52.154658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          HAPPY       0.83      0.99      0.91     55546\n",
      "HEAVILY UNHAPPY       0.59      0.15      0.24      1017\n",
      " MEDIUM UNHAPPY       0.12      0.03      0.04      1885\n",
      " MILDLY UNHAPPY       0.18      0.00      0.01      8941\n",
      "        UNKNOWN       0.89      0.91      0.90     32611\n",
      "\n",
      "       accuracy                           0.85    100000\n",
      "      macro avg       0.52      0.42      0.42    100000\n",
      "   weighted avg       0.78      0.85      0.80    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:06:19.525738Z",
     "iopub.status.busy": "2021-02-09T18:06:19.525475Z",
     "iopub.status.idle": "2021-02-09T18:06:20.433229Z",
     "shell.execute_reply": "2021-02-09T18:06:20.424261Z",
     "shell.execute_reply.started": "2021-02-09T18:06:19.525714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84888, 0.5223544184969471, 0.41531793486206575, 0.41820627065516575)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_scores(y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:47:13.490314Z",
     "iopub.status.busy": "2021-02-09T14:47:13.489933Z",
     "iopub.status.idle": "2021-02-09T14:47:13.911203Z",
     "shell.execute_reply": "2021-02-09T14:47:13.909300Z",
     "shell.execute_reply.started": "2021-02-09T14:47:13.490281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97086018, 0.96666667, 0.83463339, 0.93810335, 0.94426518]),\n",
       " array([0.99805574, 0.43364486, 0.55962343, 0.7419717 , 0.98851492]),\n",
       " array([0.98427014, 0.59870968, 0.67000626, 0.82858934, 0.96588352]))"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_scores(y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:06:25.923251Z",
     "iopub.status.busy": "2021-02-09T18:06:25.923003Z",
     "iopub.status.idle": "2021-02-09T18:06:26.229665Z",
     "shell.execute_reply": "2021-02-09T18:06:26.228756Z",
     "shell.execute_reply.started": "2021-02-09T18:06:25.923227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889325916464732"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score_ancestors(ch, y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:06:26.439242Z",
     "iopub.status.busy": "2021-02-09T18:06:26.438994Z",
     "iopub.status.idle": "2021-02-09T18:06:26.737822Z",
     "shell.execute_reply": "2021-02-09T18:06:26.736568Z",
     "shell.execute_reply.started": "2021-02-09T18:06:26.439218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313415015175861"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score_ancestors(ch, y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:06:26.891282Z",
     "iopub.status.busy": "2021-02-09T18:06:26.890996Z",
     "iopub.status.idle": "2021-02-09T18:06:27.209400Z",
     "shell.execute_reply": "2021-02-09T18:06:27.207348Z",
     "shell.execute_reply.started": "2021-02-09T18:06:26.891257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8593567065961507"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_ancestors(ch, y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T11:00:19.203227Z",
     "iopub.status.busy": "2021-02-09T11:00:19.202976Z",
     "iopub.status.idle": "2021-02-09T11:00:19.208321Z",
     "shell.execute_reply": "2021-02-09T11:00:19.206580Z",
     "shell.execute_reply.started": "2021-02-09T11:00:19.203202Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# clf = HierarchicalClassification1(classifier1,classifier2,classifier3)\n",
    "# clf.fit(X_train, y_train)\n",
    "# predictions = clf.predict(X_test)\n",
    "# print(metrics.classification_report(y_test['detailedMatchClassification'], predictions['detailedPrediction']))\n",
    "# print(metrics.classification_report(y_test['generalMatchClassification'], predictions['generalPrediction']))\n",
    "# print(metrics.classification_report(y_test['detailedMatchClassification'], predictions['detailedPrediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-02-05T14:41:50.994819Z",
     "iopub.status.idle": "2021-02-05T14:41:50.995550Z",
     "shell.execute_reply": "2021-02-05T14:41:50.995199Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# a = clf.predict_proba(X_test, y_test, 0.6)\n",
    "# comb = pd.concat([y_test['generalMatchClassification'], a['generalPrediction']],axis=1).dropna()\n",
    "# print(metrics.classification_report(comb['generalMatchClassification'], comb['generalPrediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation single point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T14:01:35.673713Z",
     "iopub.status.busy": "2021-02-08T14:01:35.673082Z",
     "iopub.status.idle": "2021-02-08T14:02:50.433328Z",
     "shell.execute_reply": "2021-02-08T14:02:50.429802Z",
     "shell.execute_reply.started": "2021-02-08T14:01:35.673643Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-08T14:29:51.984635Z",
     "iopub.status.busy": "2021-02-08T14:29:51.984356Z",
     "iopub.status.idle": "2021-02-08T14:32:48.093949Z",
     "shell.execute_reply": "2021-02-08T14:32:48.092775Z",
     "shell.execute_reply.started": "2021-02-08T14:29:51.984606Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>binaryAccuracy</th>\n",
       "      <td>0.922259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryPrecision_KNOWN</th>\n",
       "      <td>0.936825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryRecall_KNOWN</th>\n",
       "      <td>0.951168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryF1_KNOWN</th>\n",
       "      <td>0.943930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryPrecision_UNKNOWN</th>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryRecall_UNKNOWN</th>\n",
       "      <td>0.857556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryF1_UNKNOWN</th>\n",
       "      <td>0.872166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalAccuracy</th>\n",
       "      <td>0.836220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalPrecision_HAPPY</th>\n",
       "      <td>0.840076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalRecall_HAPPY</th>\n",
       "      <td>0.985269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalF1_HAPPY</th>\n",
       "      <td>0.906877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalPrecision_UNHAPPY</th>\n",
       "      <td>0.266828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalRecall_UNHAPPY</th>\n",
       "      <td>0.070149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalF1_UNHAPPY</th>\n",
       "      <td>0.110932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalPrecision_UNKNOWN</th>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalRecall_UNKNOWN</th>\n",
       "      <td>0.857556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalF1_UNKNOWN</th>\n",
       "      <td>0.872166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedAccuracy</th>\n",
       "      <td>0.833517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedPrecision_HAPPY</th>\n",
       "      <td>0.840076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedRecall_HAPPY</th>\n",
       "      <td>0.985269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedF1_HAPPY</th>\n",
       "      <td>0.906877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedPrecision_HEAVILY UNHAPPY</th>\n",
       "      <td>0.388116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedRecall_HEAVILY UNHAPPY</th>\n",
       "      <td>0.214137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedF1_HEAVILY UNHAPPY</th>\n",
       "      <td>0.275521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedPrecision_MEDIUM UNHAPPY</th>\n",
       "      <td>0.131961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedRecall_MEDIUM UNHAPPY</th>\n",
       "      <td>0.040996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedF1_MEDIUM UNHAPPY</th>\n",
       "      <td>0.062551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedPrecision_MILDLY UNHAPPY</th>\n",
       "      <td>0.125526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedRecall_MILDLY UNHAPPY</th>\n",
       "      <td>0.026398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedF1_MILDLY UNHAPPY</th>\n",
       "      <td>0.043462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedPrecision_UNKNOWN</th>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedRecall_UNKNOWN</th>\n",
       "      <td>0.857556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailedF1_UNKNOWN</th>\n",
       "      <td>0.872166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0\n",
       "binaryAccuracy                     0.922259\n",
       "binaryPrecision_KNOWN              0.936825\n",
       "binaryRecall_KNOWN                 0.951168\n",
       "binaryF1_KNOWN                     0.943930\n",
       "binaryPrecision_UNKNOWN            0.887381\n",
       "binaryRecall_UNKNOWN               0.857556\n",
       "binaryF1_UNKNOWN                   0.872166\n",
       "generalAccuracy                    0.836220\n",
       "generalPrecision_HAPPY             0.840076\n",
       "generalRecall_HAPPY                0.985269\n",
       "generalF1_HAPPY                    0.906877\n",
       "generalPrecision_UNHAPPY           0.266828\n",
       "generalRecall_UNHAPPY              0.070149\n",
       "generalF1_UNHAPPY                  0.110932\n",
       "generalPrecision_UNKNOWN           0.887381\n",
       "generalRecall_UNKNOWN              0.857556\n",
       "generalF1_UNKNOWN                  0.872166\n",
       "detailedAccuracy                   0.833517\n",
       "detailedPrecision_HAPPY            0.840076\n",
       "detailedRecall_HAPPY               0.985269\n",
       "detailedF1_HAPPY                   0.906877\n",
       "detailedPrecision_HEAVILY UNHAPPY  0.388116\n",
       "detailedRecall_HEAVILY UNHAPPY     0.214137\n",
       "detailedF1_HEAVILY UNHAPPY         0.275521\n",
       "detailedPrecision_MEDIUM UNHAPPY   0.131961\n",
       "detailedRecall_MEDIUM UNHAPPY      0.040996\n",
       "detailedF1_MEDIUM UNHAPPY          0.062551\n",
       "detailedPrecision_MILDLY UNHAPPY   0.125526\n",
       "detailedRecall_MILDLY UNHAPPY      0.026398\n",
       "detailedF1_MILDLY UNHAPPY          0.043462\n",
       "detailedPrecision_UNKNOWN          0.887381\n",
       "detailedRecall_UNKNOWN             0.857556\n",
       "detailedF1_UNKNOWN                 0.872166"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = HierarchicalClassification1(classifier1,classifier2,classifier3)\n",
    "results = classifyLabelsHC(clf, X, y, 3, scale = None)\n",
    "pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-08T13:28:50.377395Z",
     "iopub.status.busy": "2021-02-08T13:28:50.376392Z",
     "iopub.status.idle": "2021-02-08T13:30:15.531532Z",
     "shell.execute_reply": "2021-02-08T13:30:15.530639Z",
     "shell.execute_reply.started": "2021-02-08T13:28:50.377341Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binaryAccuracy</th>\n",
       "      <th>binaryPrecision_KNOWN</th>\n",
       "      <th>binaryRecall_KNOWN</th>\n",
       "      <th>binaryF1_KNOWN</th>\n",
       "      <th>binaryPrecision_UNKNOWN</th>\n",
       "      <th>binaryRecall_UNKNOWN</th>\n",
       "      <th>binaryF1_UNKNOWN</th>\n",
       "      <th>generalAccuracy</th>\n",
       "      <th>generalPrecision_HAPPY</th>\n",
       "      <th>generalRecall_HAPPY</th>\n",
       "      <th>generalF1_HAPPY</th>\n",
       "      <th>generalPrecision_UNHAPPY</th>\n",
       "      <th>generalRecall_UNHAPPY</th>\n",
       "      <th>generalF1_UNHAPPY</th>\n",
       "      <th>generalPrecision_UNKNOWN</th>\n",
       "      <th>generalRecall_UNKNOWN</th>\n",
       "      <th>generalF1_UNKNOWN</th>\n",
       "      <th>detailedAccuracy</th>\n",
       "      <th>detailedPrecision_HAPPY</th>\n",
       "      <th>detailedRecall_HAPPY</th>\n",
       "      <th>detailedF1_HAPPY</th>\n",
       "      <th>detailedPrecision_HEAVILY UNHAPPY</th>\n",
       "      <th>detailedRecall_HEAVILY UNHAPPY</th>\n",
       "      <th>detailedF1_HEAVILY UNHAPPY</th>\n",
       "      <th>detailedPrecision_MEDIUM UNHAPPY</th>\n",
       "      <th>detailedRecall_MEDIUM UNHAPPY</th>\n",
       "      <th>detailedF1_MEDIUM UNHAPPY</th>\n",
       "      <th>detailedPrecision_MILDLY UNHAPPY</th>\n",
       "      <th>detailedRecall_MILDLY UNHAPPY</th>\n",
       "      <th>detailedF1_MILDLY UNHAPPY</th>\n",
       "      <th>detailedPrecision_UNKNOWN</th>\n",
       "      <th>detailedRecall_UNKNOWN</th>\n",
       "      <th>detailedF1_UNKNOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.902832</td>\n",
       "      <td>0.964288</td>\n",
       "      <td>0.892245</td>\n",
       "      <td>0.926835</td>\n",
       "      <td>0.792926</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>0.853988</td>\n",
       "      <td>0.759539</td>\n",
       "      <td>0.868611</td>\n",
       "      <td>0.793111</td>\n",
       "      <td>0.828991</td>\n",
       "      <td>0.170905</td>\n",
       "      <td>0.167677</td>\n",
       "      <td>0.169169</td>\n",
       "      <td>0.792926</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>0.853988</td>\n",
       "      <td>0.751328</td>\n",
       "      <td>0.868611</td>\n",
       "      <td>0.793111</td>\n",
       "      <td>0.828991</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.018343</td>\n",
       "      <td>0.02209</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.02935</td>\n",
       "      <td>0.134898</td>\n",
       "      <td>0.126293</td>\n",
       "      <td>0.130079</td>\n",
       "      <td>0.792926</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>0.853988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   binaryAccuracy  binaryPrecision_KNOWN  binaryRecall_KNOWN  binaryF1_KNOWN  \\\n",
       "0        0.902832               0.964288            0.892245        0.926835   \n",
       "\n",
       "   binaryPrecision_UNKNOWN  binaryRecall_UNKNOWN  binaryF1_UNKNOWN  \\\n",
       "0                 0.792926              0.925504          0.853988   \n",
       "\n",
       "   generalAccuracy  generalPrecision_HAPPY  generalRecall_HAPPY  \\\n",
       "0         0.759539                0.868611             0.793111   \n",
       "\n",
       "   generalF1_HAPPY  generalPrecision_UNHAPPY  generalRecall_UNHAPPY  \\\n",
       "0         0.828991                  0.170905               0.167677   \n",
       "\n",
       "   generalF1_UNHAPPY  generalPrecision_UNKNOWN  generalRecall_UNKNOWN  \\\n",
       "0           0.169169                  0.792926               0.925504   \n",
       "\n",
       "   generalF1_UNKNOWN  detailedAccuracy  detailedPrecision_HAPPY  \\\n",
       "0           0.853988          0.751328                 0.868611   \n",
       "\n",
       "   detailedRecall_HAPPY  detailedF1_HAPPY  detailedPrecision_HEAVILY UNHAPPY  \\\n",
       "0              0.793111          0.828991                           0.033826   \n",
       "\n",
       "   detailedRecall_HEAVILY UNHAPPY  detailedF1_HEAVILY UNHAPPY  \\\n",
       "0                        0.018343                     0.02209   \n",
       "\n",
       "   detailedPrecision_MEDIUM UNHAPPY  detailedRecall_MEDIUM UNHAPPY  \\\n",
       "0                          0.025296                       0.035721   \n",
       "\n",
       "   detailedF1_MEDIUM UNHAPPY  detailedPrecision_MILDLY UNHAPPY  \\\n",
       "0                    0.02935                          0.134898   \n",
       "\n",
       "   detailedRecall_MILDLY UNHAPPY  detailedF1_MILDLY UNHAPPY  \\\n",
       "0                       0.126293                   0.130079   \n",
       "\n",
       "   detailedPrecision_UNKNOWN  detailedRecall_UNKNOWN  detailedF1_UNKNOWN  \n",
       "0                   0.792926                0.925504            0.853988  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICT_DAYS = 5\n",
    "REP = 3\n",
    "\n",
    "resultDic = {}\n",
    "\n",
    "classifier = HierarchicalClassification1(classifier1,classifier2,classifier3)\n",
    "\n",
    "for DAYS in range(PREDICT_DAYS+1):\n",
    "    \n",
    "    X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "    result = classifyLabelsHC(classifier, X, y, 3)\n",
    "\n",
    "    resultDic[DAYS] = result\n",
    "    \n",
    "    print('DAYS: ',DAYS)\n",
    "\n",
    "RESULT = pd.DataFrame.from_dict(resultDic, orient='columns')\n",
    "RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T16:04:18.152970Z",
     "iopub.status.busy": "2021-02-09T16:04:18.152715Z",
     "iopub.status.idle": "2021-02-09T16:04:18.178260Z",
     "shell.execute_reply": "2021-02-09T16:04:18.176683Z",
     "shell.execute_reply.started": "2021-02-09T16:04:18.152945Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def global_scores(y_true, y_pred, average = 'macro'):\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = average)\n",
    "    return accuracy, scores[0], scores[1], scores[2]\n",
    "\n",
    "def local_scores(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = None, labels = labels, beta = 1)\n",
    "    return scores[0], scores[1], scores[2]\n",
    "\n",
    "def class_report(y_true, y_pred):\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "\n",
    "def _aggregate_class_sets(set_function, y_true, y_pred):\n",
    "    intersection_sum = 0\n",
    "    true_sum = 0\n",
    "    predicted_sum = 0\n",
    "    for true, pred in zip(list(y_true), list(y_pred)):\n",
    "        true_set = set([true] + set_function(true))\n",
    "        pred_set = set([pred] + set_function(pred))\n",
    "        intersection_sum += len(true_set.intersection(pred_set))\n",
    "        true_sum += len(true_set)\n",
    "        predicted_sum += len(pred_set)\n",
    "    return (true_sum, predicted_sum, intersection_sum)\n",
    "\n",
    "def _fbeta_score_class_sets(set_function, y_true, y_pred, beta=1):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(set_function, y_true, y_pred)\n",
    "    precision = intersection_sum / predicted_sum\n",
    "    recall = intersection_sum / true_sum\n",
    "    return ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall)\n",
    "\n",
    "def precision_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    return intersection_sum / predicted_sum\n",
    "\n",
    "def recall_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    return intersection_sum / true_sum\n",
    "\n",
    "def f1_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    return _fbeta_score_class_sets(class_hierarchy._get_ancestors, y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T16:04:19.022926Z",
     "iopub.status.busy": "2021-02-09T16:04:19.022647Z",
     "iopub.status.idle": "2021-02-09T16:04:19.041600Z",
     "shell.execute_reply": "2021-02-09T16:04:19.040413Z",
     "shell.execute_reply.started": "2021-02-09T16:04:19.022900Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ClassHierarchy:\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.nodes = {}\n",
    "        \n",
    "    def add_node(self, children, parent):\n",
    "        for child in children:\n",
    "            self.nodes[child] = parent\n",
    "    \n",
    "    def _get_children(self, parent):\n",
    "        return sorted([child for child, childs_parent in\n",
    "                       self.nodes.items() if childs_parent == parent])\n",
    "    \n",
    "    def _get_parent(self, child):\n",
    "        return self.nodes[child] if (child in self.nodes and child != self.root) else self.root\n",
    "    \n",
    "    def _get_ancestors(self, child):\n",
    "        # Not including root, not including the child\n",
    "        ancestors = []\n",
    "        while True:\n",
    "            child = self._get_parent(child)\n",
    "            if child == self.root:\n",
    "                break\n",
    "            ancestors.append(child)\n",
    "        return ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T17:56:21.209459Z",
     "iopub.status.busy": "2021-02-09T17:56:21.209106Z",
     "iopub.status.idle": "2021-02-09T17:56:21.238426Z",
     "shell.execute_reply": "2021-02-09T17:56:21.237544Z",
     "shell.execute_reply.started": "2021-02-09T17:56:21.209416Z"
    }
   },
   "outputs": [],
   "source": [
    "class HierarchicalClassifier:\n",
    "\n",
    "    def __init__(self, class_hierarchy):\n",
    "        self.stages = {}\n",
    "        self.class_hierarchy = class_hierarchy\n",
    "        self._create_stages(self.stages, self.class_hierarchy.root, 0)\n",
    "\n",
    "    def _create_stages(self, stages, parent, depth):\n",
    "        # Get the children of this parent\n",
    "        children = self.class_hierarchy._get_children(parent)\n",
    "        \n",
    "        if len(children) > 0:\n",
    "            stage = {}\n",
    "            stage['depth'] = depth\n",
    "            stage['labels'] = children\n",
    "            stage['classes'] = stage['labels'] + [parent]\n",
    "            stage['target'] = 'target_stage_' + parent\n",
    "            stages[parent] = stage\n",
    "\n",
    "            for node in children:\n",
    "                self._create_stages(stages, node, depth + 1)\n",
    "                \n",
    "    def _recode_label(self, classes, label):\n",
    "\n",
    "        while label != self.class_hierarchy.root and label not in classes:\n",
    "            label = self.class_hierarchy._get_parent(label)\n",
    "        return label\n",
    "                \n",
    "    def _prep_data(self, X, y):\n",
    "        \n",
    "        Xcols = range(0, X.shape[1])\n",
    "        Ycol = X.shape[1]\n",
    "        \n",
    "        df = pd.concat([X, y], axis=1, ignore_index=True)\n",
    "        # Create a target column for each stage with the recoded labels\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            df[stage_info['target']] = pd.DataFrame.apply(df[[Ycol]],\n",
    "                                    lambda row: self._recode_label(stage_info['classes'], row[Ycol]),\n",
    "                                    axis=1)\n",
    "        return df, Xcols\n",
    "    \n",
    "    def _label_mapping(self, y_train, stage_name):\n",
    "        labels = np.unique(y_train)\n",
    "        int_label_mapping = dict(enumerate(labels))\n",
    "        label_int_mapping = {y:x for x,y in int_label_mapping.items()}\n",
    "        self.stages[stage_name]['mapping'] = {'int_label':int_label_mapping,\n",
    "                                              'label_int':label_int_mapping}\n",
    "        #return int_label_mapping, label_int_mapping\n",
    "        \n",
    "    def _class_weights(self, y_train, stage_name):\n",
    "        class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        self.stages[stage_name]['classifier'].set_params(class_weight = class_weights)\n",
    "    \n",
    "    def fit_classifiers(self, classifiers):\n",
    "        \"\"\"\n",
    "        Fit a classifier to each stage\n",
    "        \"\"\"\n",
    "        if classifiers.keys() != self.stages.keys():\n",
    "             raise ValueError('Your assigned classifiers do not match the stages of the hierarchy, fit a classifier to each of: '+self.stages.keys())\n",
    "        else:\n",
    "            for stage, classifier in classifiers.items():\n",
    "                self.stages[stage]['classifier'] = classifier\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a multi-classifier from training data (X, y).\n",
    "        \"\"\"\n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        self.scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_train = dfFilter[Xcols]\n",
    "            y_train = dfFilter[[stage_info['target']]]\n",
    "                        \n",
    "            #warning - no samples to fit for stage\n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                y_train_col = pd.Series(np.ravel(y_train))\n",
    "                self._class_weights(y_train_col, stage_name)\n",
    "                self._label_mapping(y_train_col, stage_name)\n",
    "                y_encoded = y_train_col.map(stage_info['mapping']['label_int'])\n",
    "                y_dummy = pd.DataFrame(np_utils.to_categorical(y_encoded))\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_train))\n",
    "                stage_info['classifier'].fit(X_scaled, y_dummy)\n",
    "            else:\n",
    "                stage_info['classifier'] = stage_info['classifier'].fit(X_train, y_train)\n",
    "            #print('Stage '+stage_name+' succesfully fitted')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _predict_stages(self, X):\n",
    "        \n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_pred = pd.Series(stage_info['classifier'].predict(X_scaled)).map(stage_info['mapping']['int_label'])\n",
    "                y_hat_stage = pd.DataFrame(y_pred.values, index = X_test.index)\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(stage_info['classifier'].predict(X_test), index = X_test.index)\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat      \n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_hat = self._predict_stages(X)\n",
    "        # Return only final predicted class\n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T13:34:06.455545Z",
     "iopub.status.busy": "2021-02-08T13:34:06.455159Z",
     "iopub.status.idle": "2021-02-08T13:34:06.476058Z",
     "shell.execute_reply": "2021-02-08T13:34:06.473332Z",
     "shell.execute_reply.started": "2021-02-08T13:34:06.455503Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class HierarchicalClassification1:\n",
    "    \"\"\"\n",
    "    Hierarchical classification using the tree: unknown - known -> happy - unhappy -> mildly - medium - heavily\n",
    "    Input: 3 classifiers for each parent node\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier1, classifier2, classifier3):\n",
    "        self.clf1 = classifier1\n",
    "        self.clf2 = classifier2\n",
    "        self.clf3 = classifier3\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        X_train_1 = X_train\n",
    "        y_train_1 = y_train['binaryMatchClassification']\n",
    "\n",
    "        index_train_2 = y_train.loc[(y_train['binaryMatchClassification'] == 'KNOWN')].index\n",
    "        X_train_2 = X_train.loc[index_train_2]\n",
    "        y_train_2 = y_train['generalMatchClassification'].loc[index_train_2]\n",
    "\n",
    "        index_train_3 = y_train.loc[(y_train['generalMatchClassification'] == 'UNHAPPY')].index\n",
    "        X_train_3 = X_train.loc[index_train_3]\n",
    "        y_train_3 = y_train['detailedMatchClassification'].loc[index_train_3]\n",
    "        \n",
    "        self.clf1 = classifier1.fit(X_train_1, y_train_1)\n",
    "        self.clf2 = classifier2.fit(X_train_2, y_train_2)\n",
    "        self.clf3 = classifier3.fit(X_train_3, y_train_3)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        predictions = pd.DataFrame()\n",
    "        \n",
    "        predictions['predLayer1'] = self.clf1.predict(X_test)\n",
    "        predictions['predLayer2'] = self.clf2.predict(X_test)\n",
    "        predictions['predLayer3'] = self.clf3.predict(X_test)\n",
    "        \n",
    "        predictions = self.labelPredictions(predictions)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def labelPredictions(self, predictions):\n",
    "    \n",
    "        happyLabelIndex = predictions.loc[predictions['predLayer2'] == 'HAPPY'].index\n",
    "        unknownLabelIndex = predictions.loc[predictions['predLayer1'] == 'UNKNOWN'].index\n",
    "\n",
    "        predictions['binaryPrediction'] = predictions['predLayer1']\n",
    "\n",
    "        predictions['generalPrediction'] = predictions['predLayer2']\n",
    "        predictions.loc[unknownLabelIndex, 'generalPrediction'] = 'UNKNOWN'\n",
    "\n",
    "        predictions['detailedPrediction'] = predictions['predLayer3']\n",
    "        predictions.loc[happyLabelIndex, 'detailedPrediction'] = 'HAPPY'\n",
    "        predictions.loc[unknownLabelIndex, 'detailedPrediction'] = 'UNKNOWN'\n",
    "\n",
    "        return predictions[['binaryPrediction','generalPrediction','detailedPrediction']]\n",
    "        \n",
    "    def predict_proba(self, X_test, threshold = 0.5):\n",
    "        \n",
    "        predictions = pd.DataFrame()\n",
    "        \n",
    "        predictions_1 = self.clf1.predict_proba(X_test)\n",
    "        predictions_2 = self.clf2.predict_proba(X_test)\n",
    "        predictions_3 = self.clf3.predict_proba(X_test)\n",
    "        \n",
    "        #concat columns with clear headings\n",
    "        \n",
    "        predictions = labelPredictionsProba(predictions, threshold)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def labelPredictionsProba(self, predictions, threshold):\n",
    "        \n",
    "#         X_test_1 = X_test\n",
    "#         class_1 = self.clf1.classes_\n",
    "#         knownIndex = np.where(class_1 == 'KNOWN')[0][0]\n",
    "#         predictions['probKnown'] = self.clf1.predict_proba(X_test_1)[:,knownIndex]\n",
    "        \n",
    "#         index_test_2 = predictions.loc[(predictions['probKnown'] >= threshold)].index\n",
    "#         X_test_2 = X_test.loc[index_test_2]\n",
    "#         class_2 = self.clf2.classes_\n",
    "#         unhappyIndex = np.where(class_2 == 'UNHAPPY')[0][0]\n",
    "#         predictions.loc[index_test_2, 'probUnhappy'] = self.clf2.predict_proba(X_test_2)[:,unhappyIndex]\n",
    "\n",
    "#         index_test_3 = predictions.loc[(predictions['probUnhappy'] >= threshold)].index\n",
    "#         X_test_3 = X_test.loc[index_test_3]\n",
    "#         predictions.loc[index_test_3, 'predLayer3'] = self.clf3.predict(X_test_3)\n",
    "    \n",
    "#         predictions.loc[predictions['probKnown'] >= threshold, 'binaryPrediction'] = 'KNOWN'\n",
    "#         predictions.loc[predictions['probKnown'] <= (1-threshold), 'binaryPrediction'] = 'UNKNOWN'\n",
    "        \n",
    "#         predictions.loc[predictions['probUnhappy'] >= threshold, 'generalPrediction'] = 'UNHAPPY'\n",
    "#         predictions.loc[predictions['probUnhappy'] <= (1-threshold), 'generalPrediction'] = 'HAPPY'\n",
    "#         predictions.loc[predictions['binaryPrediction'] == 'UNKNOWN', 'generalPrediction'] = 'UNKNOWN'\n",
    "        \n",
    "#         predictions['detailedPrediction'] = predictions['predLayer3']\n",
    "#         predictions.loc[predictions['probUnhappy'] <= (1-threshold), 'detailedPrediction'] = 'HAPPY'\n",
    "#         predictions.loc[predictions['probKnown'] <= (1-threshold), 'detailedPrediction'] = 'UNKNOWN'\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T13:28:47.153024Z",
     "iopub.status.busy": "2021-02-08T13:28:47.152658Z",
     "iopub.status.idle": "2021-02-08T13:28:47.183804Z",
     "shell.execute_reply": "2021-02-08T13:28:47.177640Z",
     "shell.execute_reply.started": "2021-02-08T13:28:47.152989Z"
    }
   },
   "outputs": [],
   "source": [
    "def classifyLabelsHC(classifier, X, y, n, split = 'TimeSeries', smote = False, scale = None, NN = False):\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    storage = {'binary'  :{'acc':{},'pre':{},'rec':{},'f1':{}},\n",
    "               'general' :{'acc':{},'pre':{},'rec':{},'f1':{}},\n",
    "               'detailed':{'acc':{},'pre':{},'rec':{},'f1':{}}}\n",
    "        \n",
    "    if split == 'Random':\n",
    "        cv = StratifiedKFold(n_splits = n, random_state = 0, shuffle = True)   \n",
    "    else:\n",
    "        cv = TimeSeriesSplit(n_splits = n)\n",
    "    \n",
    "    count = 1\n",
    "\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        \n",
    "        if scale != None:\n",
    "            X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "            X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "        else:   \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            \n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        classifier.fit(X_train,y_train)\n",
    "        predictions = classifier.predict(X_test)\n",
    "        \n",
    "        #Calculate performance metrics for each level\n",
    "        for level in ['binary','general','detailed']:\n",
    "            \n",
    "            labels = np.unique(y[level+'MatchClassification'])\n",
    "            \n",
    "            y_pred_ = predictions[level+'Prediction']\n",
    "            y_test_ = y_test[level+'MatchClassification']\n",
    "\n",
    "            accuracy = metrics.accuracy_score(y_test_, y_pred_)\n",
    "            scores = metrics.precision_recall_fscore_support(y_test_, y_pred_, average = None, labels = labels, beta = 1)\n",
    "            \n",
    "            storage[level]['acc'][count] = accuracy\n",
    "            storage[level]['pre'][count] = scores[0]\n",
    "            storage[level]['rec'][count] = scores[1]\n",
    "            storage[level]['f1'][count] = scores[2]\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    #Calculate averages of each metric\n",
    "    for level in ['binary','general','detailed']:\n",
    "        \n",
    "        labels = np.unique(y[level+'MatchClassification'])\n",
    "        \n",
    "        results[level+'Accuracy'] = sum(storage[level]['acc'].values()) / n\n",
    "\n",
    "        for ix,lab in enumerate(labels):\n",
    "            results[(level+'Precision_'+lab)] = (sum(storage[level]['pre'].values()) / n)[ix]\n",
    "            results[(level+'Recall_'+lab)] = (sum(storage[level]['rec'].values()) / n)[ix]\n",
    "            results[(level+'F1_'+lab)] = (sum(storage[level]['f1'].values()) / n)[ix]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:54:12.601502Z",
     "iopub.status.busy": "2021-02-08T09:54:12.601228Z",
     "iopub.status.idle": "2021-02-08T09:54:12.610391Z",
     "shell.execute_reply": "2021-02-08T09:54:12.609269Z",
     "shell.execute_reply.started": "2021-02-08T09:54:12.601472Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def neuralNetworkSetup(y,train_index):\n",
    "    \n",
    "    labels = np.unique(y)\n",
    "    int_label_mapping = dict(enumerate(labels))\n",
    "    label_int_mapping = {y:x for x,y in int_label_mapping.items()}\n",
    "    \n",
    "    y_encoded = y.map(label_int_mapping)\n",
    "    y_dummy = pd.DataFrame(np_utils.to_categorical(y_encoded))\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced',labels,y.iloc[train_index])\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    clf.set_params(class_weight = class_weights)\n",
    "    y_train = y_dummy.iloc[train_index]\n",
    "    \n",
    "    return y_train\n",
    "    \n",
    "    #y_pred = pd.Series(y_pred).map(int_label_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
