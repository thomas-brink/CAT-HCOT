{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "voluntary-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authentic-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "import warnings\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import importlib\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bound-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-monroe",
   "metadata": {},
   "source": [
    "# Data Loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-haiti",
   "metadata": {},
   "source": [
    "## Option 1: via .csv files (preferred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-count",
   "metadata": {},
   "source": [
    "### Load files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "universal-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('/Users/thoma/Documents/seminar_data/data_2019.csv')\n",
    "df_2020 = pd.read_csv('/Users/thoma/Documents/seminar_data/data_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fewer-currency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # records:  4779466\n"
     ]
    }
   ],
   "source": [
    "#Concat files and create new index\n",
    "df_full = pd.concat([df_2019, df_2020])\n",
    "df_full = df_full.reset_index(drop = True)\n",
    "\n",
    "print('Total # records: ',df_full.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-playback",
   "metadata": {},
   "source": [
    "### Rename existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuffed-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "rename_columns = {'datetTimeFirstDeliveryMoment': 'dateTimeFirstDeliveryMoment',\n",
    "                  'generalMatchClassification'  : 'detailedMatchClassification',\n",
    "                  'detailedMatchClassification' : 'generalMatchClassification',\n",
    "                  'quanityReturned'             : 'quantityReturned'}\n",
    "\n",
    "df_full = df_full.rename(columns = rename_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-display",
   "metadata": {},
   "source": [
    "### Change data type of relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "labeled-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform dates to date-type\n",
    "df_full['orderDate']                   = pd.to_datetime(df_full['orderDate'])\n",
    "df_full['cancellationDate']            = pd.to_datetime(df_full['cancellationDate'])\n",
    "df_full['promisedDeliveryDate']        = pd.to_datetime(df_full['promisedDeliveryDate'])\n",
    "df_full['shipmentDate']                = pd.to_datetime(df_full['shipmentDate'])\n",
    "df_full['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df_full['dateTimeFirstDeliveryMoment'])\n",
    "df_full['startDateCase']               = pd.to_datetime(df_full['startDateCase'])\n",
    "df_full['returnDateTime']              = pd.to_datetime(df_full['returnDateTime'])\n",
    "df_full['registrationDateSeller']      = pd.to_datetime(df_full['registrationDateSeller'])\n",
    "\n",
    "#Change type of columns\n",
    "dtype = {'calculationDefinitive': bool,\n",
    "         'noCancellation'       : bool,\n",
    "         'noCase'               : bool,\n",
    "         'hasOneCase'           : bool,\n",
    "         'hasMoreCases'         : bool,\n",
    "         'noReturn'             : bool}\n",
    "\n",
    "df_full = df_full.astype(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-crest",
   "metadata": {},
   "source": [
    "### Remove noise and irrelevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "smoking-potter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6516 complete records removed from the data\n",
      "Cleaned # records:  4772950 \n",
      "\n",
      "# Records where cancellation values are emptied: 53780\n",
      "# Records where return values are emptied: \t 8208\n",
      "# Records where case values are emptied: \t 0\n",
      "# Records where quantity values are equalized: \t 14722\n",
      "# Records where delivery values are emptied: \t 4103\n"
     ]
    }
   ],
   "source": [
    "#Remove nonsensical rows\n",
    "noise = df_full.loc[(df_full['startDateCase']        < df_full['orderDate']) | \n",
    "                   (df_full['cancellationDate']      < df_full['orderDate']) |\n",
    "                   (df_full['promisedDeliveryDate']  < df_full['orderDate']) |\n",
    "                   (df_full['shipmentDate']          < df_full['orderDate']) |\n",
    "                   (df_full['returnDateTime']        < df_full['orderDate']) |\n",
    "                   (df_full['cancellationDate']      > df_full['returnDateTime']) |\n",
    "                   (df_full['shipmentDate']          > df_full['returnDateTime']) |\n",
    "                   (df_full['orderDate']             < df_full['registrationDateSeller']) |\n",
    "                   (df_full['orderDate']             > df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) |\n",
    "                   (df_full['cancellationDate']      > df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) |\n",
    "                   (df_full['shipmentDate']          > df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) |\n",
    "                   ((df_full['returnDateTime']       < df_full['dateTimeFirstDeliveryMoment'].dt.normalize()) & \n",
    "                                                       (df_full['dateTimeFirstDeliveryMoment'].notnull()) &\n",
    "                                                       (df_full['returnDateTime'].notnull())) |\n",
    "                   ((df_full['cancellationDate']     > df_full['shipmentDate']) &\n",
    "                                                       ((df_full['cancellationReasonCode'] == 'CUST_FE') |\n",
    "                                                       (df_full['cancellationReasonCode'] == 'CUST_CS'))) |\n",
    "                   (df_full['registrationDateSeller'].isnull()) |\n",
    "                   (df_full['promisedDeliveryDate'].isnull())].index\n",
    "\n",
    "#Drop noise data\n",
    "df = df_full.drop(index = noise)\n",
    "print(len(noise), 'complete records removed from the data')\n",
    "print('Cleaned # records: ',df.shape[0],'\\n')\n",
    "\n",
    "#Sort rows on orderDate and create new index\n",
    "df = df.sort_values(by = 'orderDate')\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "#Remove inconsistent values -> we fill in all data as known by bol during their lookback periods\n",
    "cancellationNoise = df.loc[(df['noCancellation'] == True) & (df['cancellationDate'].notnull())].index\n",
    "returnNoise       = df.loc[(df['noReturn'] == True) & (df['returnDateTime'].notnull())].index\n",
    "caseNoise         = df.loc[(df['noCase'] == True) & (df['startDateCase'].notnull())].index\n",
    "quantityNoise     = df.loc[df['quantityReturned'] > df['quantityOrdered']].index\n",
    "deliveryNoise     = df.loc[(df['dateTimeFirstDeliveryMoment'].notnull()) & (df['onTimeDelivery'].isnull())].index\n",
    "\n",
    "df.loc[cancellationNoise, ['cancellationDate','cancellationReasonCode']] = None\n",
    "df.loc[returnNoise,       ['returnDateTime','quantityReturned','returnCode']] = None\n",
    "df.loc[caseNoise,         ['startDateCase','cntDistinctCaseIds','hasOneCase','hasMoreCases']] = None\n",
    "df.loc[quantityNoise,     ['quantityReturned']] = df.loc[quantityNoise, ['quantityOrdered']]\n",
    "df.loc[deliveryNoise,     ['dateTimeFirstDeliveryMoment']] = None\n",
    "\n",
    "print('# Records where cancellation values are emptied:',len(cancellationNoise))\n",
    "print('# Records where return values are emptied: \\t',len(returnNoise))\n",
    "print('# Records where case values are emptied: \\t',len(caseNoise))\n",
    "print('# Records where quantity values are equalized: \\t',len(quantityNoise))\n",
    "print('# Records where delivery values are emptied: \\t',len(deliveryNoise))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-trinity",
   "metadata": {},
   "source": [
    "### Create variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-sender",
   "metadata": {},
   "source": [
    "#### Time-related "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "gorgeous-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new variables related to periods (days difference)\n",
    "df['caseDays']             = (df['startDateCase'] - df['orderDate']).dt.days\n",
    "df['returnDays']           = (df['returnDateTime'] - df['orderDate']).dt.days\n",
    "df['cancellationDays']     = (df['cancellationDate'] - df['orderDate']).dt.days\n",
    "df['actualDeliveryDays']   = (df['dateTimeFirstDeliveryMoment'].dt.normalize() - df['orderDate']).dt.days\n",
    "df['shipmentDays']         = (df['shipmentDate'] - df['orderDate']).dt.days\n",
    "df['partnerSellingDays']   = (df['orderDate'] - df['registrationDateSeller']).dt.days\n",
    "df['promisedDeliveryDays'] = (df['promisedDeliveryDate'] - df['orderDate']).dt.days\n",
    "\n",
    "#Time related variables\n",
    "df['orderYear']    = df['orderDate'].dt.year\n",
    "df['orderMonth']   = df['orderDate'].dt.month\n",
    "df['orderWeekday'] = df['orderDate'].dt.weekday\n",
    "df['orderCorona']  = df['orderDate'].apply(lambda x: True if x > datetime.strptime('2020-03-20','%Y-%m-%d') else False)\n",
    "# Weekend?\n",
    "\n",
    "#Create dummy variables for weekdays, months and years\n",
    "df['orderMonday']    = df['orderWeekday'].apply(lambda x: True if x == 0 else False)\n",
    "df['orderTuesday']   = df['orderWeekday'].apply(lambda x: True if x == 1 else False)\n",
    "df['orderWednesday'] = df['orderWeekday'].apply(lambda x: True if x == 2 else False)\n",
    "df['orderThursday']  = df['orderWeekday'].apply(lambda x: True if x == 3 else False)\n",
    "df['orderFriday']    = df['orderWeekday'].apply(lambda x: True if x == 4 else False)\n",
    "df['orderSaturday']  = df['orderWeekday'].apply(lambda x: True if x == 5 else False)\n",
    "df['orderSunday']    = df['orderWeekday'].apply(lambda x: True if x == 6 else False)\n",
    "\n",
    "df['orderJanuary']   = df['orderMonth'].apply(lambda x: True if x == 1 else False)\n",
    "df['orderFebruary']  = df['orderMonth'].apply(lambda x: True if x == 2 else False)\n",
    "df['orderMarch']     = df['orderMonth'].apply(lambda x: True if x == 3 else False)\n",
    "df['orderApril']     = df['orderMonth'].apply(lambda x: True if x == 4 else False)\n",
    "df['orderMay']       = df['orderMonth'].apply(lambda x: True if x == 5 else False)\n",
    "df['orderJune']      = df['orderMonth'].apply(lambda x: True if x == 6 else False)\n",
    "df['orderJuly']      = df['orderMonth'].apply(lambda x: True if x == 7 else False)\n",
    "df['orderAugust']    = df['orderMonth'].apply(lambda x: True if x == 8 else False)\n",
    "df['orderSeptember'] = df['orderMonth'].apply(lambda x: True if x == 9 else False)\n",
    "df['orderOctober']   = df['orderMonth'].apply(lambda x: True if x == 10 else False)\n",
    "df['orderNovember']  = df['orderMonth'].apply(lambda x: True if x == 11 else False)\n",
    "df['orderDecember']  = df['orderMonth'].apply(lambda x: True if x == 12 else False)\n",
    "\n",
    "df['orderYear2019'] = df['orderYear'].apply(lambda x: True if x == 2019 else False)\n",
    "df['orderYear2020'] = df['orderYear'].apply(lambda x: True if x == 2020 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-agency",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlimited-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['productTitleLength'] = len(df['productTitle'])\n",
    "\n",
    "df['fulfilmentByBol'] = df['fulfilmentType'].apply(lambda x: True if x == 'FBB' else False)\n",
    "\n",
    "df['countryCodeNL']   = df['countryCode'].apply(lambda x: True if x == 'NL' else False)\n",
    "df['countryOriginNL'] = df['countryOriginSeller'].apply(lambda x: True if x == 'NL' else False)\n",
    "df['countryOriginBE'] = df['countryOriginSeller'].apply(lambda x: True if x == 'BE' else False)\n",
    "df['countryOriginDE'] = df['countryOriginSeller'].apply(lambda x: True if x == 'DE' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-ottawa",
   "metadata": {},
   "source": [
    "#### Determinant classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "complex-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df[['noCancellation','noReturn','noCase','onTimeDelivery']].values\n",
    "\n",
    "determinantClassification = np.empty(df_values.shape[0], dtype='object')\n",
    "\n",
    "for ix,df_ in enumerate(df_values):\n",
    "    if ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 1) & (df_[3] == True)): \n",
    "        determinantClassification[ix] = 'All good'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 1) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 1) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Late delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 0) & (df_[3] == True)):\n",
    "        determinantClassification[ix] = 'Case'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 0) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Case + Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 1) & (df_[2] == 0) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Case + Late delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 1) & (df_[3] == True)):\n",
    "        determinantClassification[ix] = 'Return'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 1) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Return + Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 1) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Return + Late delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 0) & (df_[3] == True)):\n",
    "        determinantClassification[ix] = 'Return + Case'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 0) & (np.isnan(df_[3]) == True)):\n",
    "        determinantClassification[ix] = 'Return + Case + Unknown delivery'\n",
    "    elif ((df_[0] == 1) & (df_[1] == 0) & (df_[2] == 0) & (df_[3] == False)):\n",
    "        determinantClassification[ix] = 'Return + Case + Late delivery'\n",
    "    elif (df_[0] == 0):\n",
    "        determinantClassification[ix] = 'Cancellation'\n",
    "        \n",
    "df['determinantClassification'] = determinantClassification\n",
    "df['determinantClassification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "little-livestock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "All good                            2685606\n",
       "Unknown delivery                    1517648\n",
       "Late delivery                        146725\n",
       "Return                               145556\n",
       "Return + Unknown delivery             82968\n",
       "Case + Unknown delivery               67732\n",
       "Case                                  42643\n",
       "Return + Case                         24204\n",
       "Cancellation                          23693\n",
       "Return + Case + Unknown delivery      17263\n",
       "Return + Late delivery                 8426\n",
       "Case + Late delivery                   8352\n",
       "Return + Case + Late delivery          2134\n",
       "Name: determinantClassification, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['determinantClassification'] = df.apply(determinantClassification, axis = 1)\n",
    "df['determinantClassification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-details",
   "metadata": {},
   "source": [
    "#### Binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "molecular-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['binaryMatchClassification'] = df['generalMatchClassification'].apply(lambda x: 'UNKNOWN' if x == 'UNKNOWN' else 'KNOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-alcohol",
   "metadata": {},
   "source": [
    "#### Transporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "verified-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transporterCluster(transporterCode):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered transporter variable: 28 -> 5 categories\n",
    "    \"\"\"\n",
    "    if transporterCode in ['AH-NL','TNT','TNT-EXPRESS','TNT-EXTRA']:\n",
    "        return 'POSTNL'\n",
    "    elif transporterCode in ['DHL','DHL_DE','DHLFORYOU']:\n",
    "        return 'DHL'\n",
    "    elif transporterCode in ['DPD-NL','DPD-BE']:\n",
    "        return 'DPD'\n",
    "    elif transporterCode in ['BRIEFPOST','BPOST_BRIEF','DHL-GLOBAL-MAIL','TNT_BRIEF']:\n",
    "        return 'BRIEF'\n",
    "    else:\n",
    "        return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "civilian-planet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSTNL    2110753\n",
       "BRIEF     1488153\n",
       "DHL        436975\n",
       "OTHER      407323\n",
       "DPD        329746\n",
       "Name: transporterCodeGeneral, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transporterCodeGeneral'] = df['transporterCode'].apply(transporterCluster)\n",
    "df['transporterCodeGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-means",
   "metadata": {},
   "source": [
    "#### Product group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "civilian-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def productGroupCluster(productGroup):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered product group variable based on categories bol.com\n",
    "    60 -> 14 groups.\n",
    "    \"\"\"\n",
    "    if productGroup in ['Dutch Books PG','Ebooks and Audiobooks','International Books PG']:\n",
    "        return 'Books'\n",
    "    elif productGroup in ['Games Accessories','Games Consoles','Games Software Physical',\n",
    "                          'Movies','Music']:\n",
    "        return 'Music, Film & Games'\n",
    "    elif productGroup in ['Camera','Desktop Monitor and Beamer','Ereaders and Accessories',\n",
    "                          'Laptop Computers','PC Accessories','Personal Audio',\n",
    "                          'Sound and Vision Accessories','Storage and Network',\n",
    "                          'Telephone and Tablet Accessories','Telephones and Tablets','Television']:\n",
    "        return 'Computer & Electronics'\n",
    "    elif productGroup in ['General Toys','Recreational and Outdoor Toys']:\n",
    "        return 'Toys & Hobby'\n",
    "    elif productGroup in ['Baby and Kids Fashion','Baby PG']:\n",
    "        return 'Baby & Kids'\n",
    "    elif productGroup in ['Daily Care PG','Health PG','Perfumery PG','Personal Care']:\n",
    "        return 'Health & Care'\n",
    "    elif productGroup in ['Footwear','Jewelry and Watches','Mens and Womens Fashion','Wearables']:\n",
    "        return 'Fashion, Shoes & Accessories'\n",
    "    elif productGroup in ['Bodyfashion and Beachwear','Camping and Outdoor','Cycling',\n",
    "                          'Sporting Equipment','Sportswear','Travel Bags and Accessories']:\n",
    "        return 'Sports, Outdoor & Travel'\n",
    "    elif productGroup in ['Educational Dutch','Educational International','Printing and Ink']:\n",
    "        return 'Office & School'\n",
    "    elif productGroup in ['Supermarket PG'] :\n",
    "        return 'Food & Beverage'\n",
    "    elif productGroup in ['Furniture','Heating and Air','Home Decoration','Home Entertainment',\n",
    "                          'Household','Household Appliances','Kitchen','Kitchen Machines',\n",
    "                          'Lighting','Major Domestic Appliances PG','Plumbing and Safety']:\n",
    "        return 'Home, Cooking & Household'\n",
    "    elif productGroup in ['Garden','Pet PG','Textiles','Tools and Paint']:\n",
    "        return 'Pets, Garden & Jobs'\n",
    "    elif productGroup in ['Car and Motorcycle'] :\n",
    "        return 'Car & Motor'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deadly-dynamics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer & Electronics          1387679\n",
       "Home, Cooking & Household        797874\n",
       "Sports, Outdoor & Travel         522098\n",
       "Toys & Hobby                     500977\n",
       "Pets, Garden & Jobs              339813\n",
       "Health & Care                    299049\n",
       "Food & Beverage                  258769\n",
       "Books                            184581\n",
       "Music, Film & Games              163842\n",
       "Baby & Kids                      113707\n",
       "Fashion, Shoes & Accessories     110067\n",
       "Office & School                   52270\n",
       "Car & Motor                       29753\n",
       "Other                             12471\n",
       "Name: productGroupGeneral, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['productGroupGeneral'] = df['productGroup'].apply(productGroupCluster)\n",
    "df['productGroupGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spatial-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummies of new product grouping\n",
    "for group in df['productGroupGeneral'].unique():\n",
    "    \n",
    "    columnName = 'group' + group.split(' ')[0].replace(',','')\n",
    "    df[columnName] = df['productGroupGeneral'].apply(lambda x: True if x == group else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-aggregate",
   "metadata": {},
   "source": [
    "#### Cleaned total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "unlimited-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orderDate', 'productId', 'sellerId', 'totalPrice', 'quantityOrdered',\n",
      "       'countryCode', 'cancellationDate', 'cancellationReasonCode',\n",
      "       'promisedDeliveryDate', 'shipmentDate', 'transporterCode',\n",
      "       'transporterName', 'transporterNameOther',\n",
      "       'dateTimeFirstDeliveryMoment', 'fulfilmentType', 'startDateCase',\n",
      "       'cntDistinctCaseIds', 'returnDateTime', 'quantityReturned',\n",
      "       'returnCode', 'productTitle', 'brickName', 'chunkName', 'productGroup',\n",
      "       'productSubGroup', 'productSubSubGroup', 'registrationDateSeller',\n",
      "       'countryOriginSeller', 'currentCountryAvailabilitySeller',\n",
      "       'calculationDefinitive', 'noCancellation', 'onTimeDelivery', 'noCase',\n",
      "       'hasOneCase', 'hasMoreCases', 'noReturn', 'detailedMatchClassification',\n",
      "       'generalMatchClassification', 'caseDays', 'returnDays',\n",
      "       'cancellationDays', 'actualDeliveryDays', 'shipmentDays',\n",
      "       'partnerSellingDays', 'promisedDeliveryDays', 'orderYear', 'orderMonth',\n",
      "       'orderWeekday', 'orderCorona', 'orderMonday', 'orderTuesday',\n",
      "       'orderWednesday', 'orderThursday', 'orderFriday', 'orderSaturday',\n",
      "       'orderSunday', 'orderJanuary', 'orderFebruary', 'orderMarch',\n",
      "       'orderApril', 'orderMay', 'orderJune', 'orderJuly', 'orderAugust',\n",
      "       'orderSeptember', 'orderOctober', 'orderNovember', 'orderDecember',\n",
      "       'orderYear2019', 'orderYear2020', 'productTitleLength',\n",
      "       'fulfilmentByBol', 'countryCodeNL', 'countryOriginNL',\n",
      "       'countryOriginBE', 'countryOriginDE', 'determinantClassification',\n",
      "       'binaryMatchClassification', 'transporterCodeGeneral',\n",
      "       'productGroupGeneral', 'groupHealth', 'groupHome', 'groupSports',\n",
      "       'groupComputer', 'groupPets', 'groupToys', 'groupBooks', 'groupBaby',\n",
      "       'groupMusic', 'groupFood', 'groupOffice', 'groupFashion', 'groupOther',\n",
      "       'groupCar'],\n",
      "      dtype='object')\n",
      "Total:  94  columns\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print('Total: ',len(df.columns),' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fitting-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "DATE = ['orderDate']\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength','promisedDeliveryDays','partnerSellingMonths']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "YEAR = ['orderYear2019','orderYear2020']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "\n",
    "#Classifications\n",
    "CLASSIFICATION = ['generalMatchClassification','detailedMatchClassification','binaryMatchClassification','determinantClassification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "toxic-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderDate</th>\n",
       "      <th>productId</th>\n",
       "      <th>sellerId</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>quantityOrdered</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>cancellationDate</th>\n",
       "      <th>cancellationReasonCode</th>\n",
       "      <th>promisedDeliveryDate</th>\n",
       "      <th>shipmentDate</th>\n",
       "      <th>transporterCode</th>\n",
       "      <th>transporterName</th>\n",
       "      <th>transporterNameOther</th>\n",
       "      <th>dateTimeFirstDeliveryMoment</th>\n",
       "      <th>fulfilmentType</th>\n",
       "      <th>startDateCase</th>\n",
       "      <th>cntDistinctCaseIds</th>\n",
       "      <th>returnDateTime</th>\n",
       "      <th>quantityReturned</th>\n",
       "      <th>returnCode</th>\n",
       "      <th>productTitle</th>\n",
       "      <th>brickName</th>\n",
       "      <th>chunkName</th>\n",
       "      <th>productGroup</th>\n",
       "      <th>productSubGroup</th>\n",
       "      <th>productSubSubGroup</th>\n",
       "      <th>registrationDateSeller</th>\n",
       "      <th>countryOriginSeller</th>\n",
       "      <th>currentCountryAvailabilitySeller</th>\n",
       "      <th>calculationDefinitive</th>\n",
       "      <th>noCancellation</th>\n",
       "      <th>onTimeDelivery</th>\n",
       "      <th>noCase</th>\n",
       "      <th>hasOneCase</th>\n",
       "      <th>hasMoreCases</th>\n",
       "      <th>noReturn</th>\n",
       "      <th>detailedMatchClassification</th>\n",
       "      <th>generalMatchClassification</th>\n",
       "      <th>caseDays</th>\n",
       "      <th>returnDays</th>\n",
       "      <th>cancellationDays</th>\n",
       "      <th>actualDeliveryDays</th>\n",
       "      <th>shipmentDays</th>\n",
       "      <th>partnerSellingDays</th>\n",
       "      <th>promisedDeliveryDays</th>\n",
       "      <th>orderYear</th>\n",
       "      <th>orderMonth</th>\n",
       "      <th>orderWeekday</th>\n",
       "      <th>orderCorona</th>\n",
       "      <th>orderMonday</th>\n",
       "      <th>orderTuesday</th>\n",
       "      <th>orderWednesday</th>\n",
       "      <th>orderThursday</th>\n",
       "      <th>orderFriday</th>\n",
       "      <th>orderSaturday</th>\n",
       "      <th>orderSunday</th>\n",
       "      <th>orderJanuary</th>\n",
       "      <th>orderFebruary</th>\n",
       "      <th>orderMarch</th>\n",
       "      <th>orderApril</th>\n",
       "      <th>orderMay</th>\n",
       "      <th>orderJune</th>\n",
       "      <th>orderJuly</th>\n",
       "      <th>orderAugust</th>\n",
       "      <th>orderSeptember</th>\n",
       "      <th>orderOctober</th>\n",
       "      <th>orderNovember</th>\n",
       "      <th>orderDecember</th>\n",
       "      <th>orderYear2019</th>\n",
       "      <th>orderYear2020</th>\n",
       "      <th>productTitleLength</th>\n",
       "      <th>fulfilmentByBol</th>\n",
       "      <th>countryCodeNL</th>\n",
       "      <th>countryOriginNL</th>\n",
       "      <th>countryOriginBE</th>\n",
       "      <th>countryOriginDE</th>\n",
       "      <th>determinantClassification</th>\n",
       "      <th>binaryMatchClassification</th>\n",
       "      <th>transporterCodeGeneral</th>\n",
       "      <th>productGroupGeneral</th>\n",
       "      <th>groupHealth</th>\n",
       "      <th>groupHome</th>\n",
       "      <th>groupSports</th>\n",
       "      <th>groupComputer</th>\n",
       "      <th>groupPets</th>\n",
       "      <th>groupToys</th>\n",
       "      <th>groupBooks</th>\n",
       "      <th>groupBaby</th>\n",
       "      <th>groupMusic</th>\n",
       "      <th>groupFood</th>\n",
       "      <th>groupOffice</th>\n",
       "      <th>groupFashion</th>\n",
       "      <th>groupOther</th>\n",
       "      <th>groupCar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000103390344</td>\n",
       "      <td>1244284</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT_BRIEF</td>\n",
       "      <td>PostNL Briefpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FBR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Velvet Scrunchie Pale Pink</td>\n",
       "      <td>Haar – Accessoires</td>\n",
       "      <td>Haaraccessoire</td>\n",
       "      <td>Daily Care PG</td>\n",
       "      <td>Haar</td>\n",
       "      <td>Haar Accessoires</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>743</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4772950</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BRIEF</td>\n",
       "      <td>Health &amp; Care</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000065456100</td>\n",
       "      <td>1167286</td>\n",
       "      <td>158.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>DPD-NL</td>\n",
       "      <td>DPD Nederland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FBR</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inventum MN306C - Combi-magnetron</td>\n",
       "      <td>Magnetrons</td>\n",
       "      <td>Vrijstaande magnetron</td>\n",
       "      <td>Major Domestic Appliances PG</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>KNOWN HEAVILY UNHAPPY</td>\n",
       "      <td>UNHAPPY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>991</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4772950</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>DPD</td>\n",
       "      <td>Home, Cooking &amp; Household</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000024539481</td>\n",
       "      <td>888610</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>BPOST_BE</td>\n",
       "      <td>Bpost Belgie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 08:17:00</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Perfect Push Up V2</td>\n",
       "      <td>Fitness Accessoires</td>\n",
       "      <td>Opdruksteun</td>\n",
       "      <td>Sporting Equipment</td>\n",
       "      <td>Fitness Klein</td>\n",
       "      <td>Fitnessmaterialen</td>\n",
       "      <td>2013-12-21</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>KNOWN HAPPY</td>\n",
       "      <td>KNOWN HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1837</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4772950</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Sports, Outdoor &amp; Travel</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000056338594</td>\n",
       "      <td>1308208</td>\n",
       "      <td>32.20</td>\n",
       "      <td>2</td>\n",
       "      <td>NL</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>SELLER_UNDELIV</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGB led strip - 5m - Set RGB - kleuren - Inclu...</td>\n",
       "      <td>Verlichting – Vast</td>\n",
       "      <td>Led-strip</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>Slimme Verlichting</td>\n",
       "      <td>Slimme Led-Strips</td>\n",
       "      <td>2017-09-15</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>KNOWN HEAVILY UNHAPPY</td>\n",
       "      <td>UNHAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>473</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4772950</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Cancellation</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Home, Cooking &amp; Household</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000085152942</td>\n",
       "      <td>1274000</td>\n",
       "      <td>24.50</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 17:06:38</td>\n",
       "      <td>FBB</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deltaco GT-174D 4-poort stekkerdoos met 2 x US...</td>\n",
       "      <td>Verdeelborden/-kasten</td>\n",
       "      <td>Stekkerdoos</td>\n",
       "      <td>Plumbing and Safety</td>\n",
       "      <td>Elektra</td>\n",
       "      <td>Verlengmateriaal</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>NL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>KNOWN MEDIUM UNHAPPY</td>\n",
       "      <td>UNHAPPY</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>580</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4772950</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Return + Case</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Home, Cooking &amp; Household</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orderDate         productId  sellerId  totalPrice  quantityOrdered  \\\n",
       "0 2019-01-01  9200000103390344   1244284        4.95                1   \n",
       "1 2019-01-01  9200000065456100   1167286      158.00                1   \n",
       "2 2019-01-01  9200000024539481    888610       30.00                1   \n",
       "3 2019-01-01  9200000056338594   1308208       32.20                2   \n",
       "4 2019-01-01  9200000085152942   1274000       24.50                1   \n",
       "\n",
       "  countryCode cancellationDate cancellationReasonCode promisedDeliveryDate  \\\n",
       "0          NL              NaT                    NaN           2019-01-04   \n",
       "1          NL              NaT                    NaN           2019-01-07   \n",
       "2          BE              NaT                    NaN           2019-01-03   \n",
       "3          NL       2019-01-02         SELLER_UNDELIV           2019-01-03   \n",
       "4          NL              NaT                    NaN           2019-01-03   \n",
       "\n",
       "  shipmentDate transporterCode   transporterName transporterNameOther  \\\n",
       "0   2019-01-02       TNT_BRIEF  PostNL Briefpost                  NaN   \n",
       "1   2019-01-02          DPD-NL     DPD Nederland                  NaN   \n",
       "2   2019-01-02        BPOST_BE      Bpost Belgie                  NaN   \n",
       "3          NaT             NaN               NaN                  NaN   \n",
       "4   2019-01-02             TNT            PostNL                  NaN   \n",
       "\n",
       "  dateTimeFirstDeliveryMoment fulfilmentType startDateCase  \\\n",
       "0                         NaT            FBR           NaT   \n",
       "1                         NaT            FBR    2019-01-03   \n",
       "2         2019-01-03 08:17:00            FBB           NaT   \n",
       "3                         NaT            FBB           NaT   \n",
       "4         2019-01-03 17:06:38            FBB    2019-01-18   \n",
       "\n",
       "   cntDistinctCaseIds returnDateTime  quantityReturned returnCode  \\\n",
       "0                 NaN            NaT               NaN        NaN   \n",
       "1                 2.0            NaT               NaN        NaN   \n",
       "2                 NaN            NaT               NaN        NaN   \n",
       "3                 NaN            NaT               NaN        NaN   \n",
       "4                 1.0     2019-01-04               1.0        NaN   \n",
       "\n",
       "                                        productTitle              brickName  \\\n",
       "0                         Velvet Scrunchie Pale Pink     Haar – Accessoires   \n",
       "1                  Inventum MN306C - Combi-magnetron             Magnetrons   \n",
       "2                                 Perfect Push Up V2    Fitness Accessoires   \n",
       "3  RGB led strip - 5m - Set RGB - kleuren - Inclu...     Verlichting – Vast   \n",
       "4  Deltaco GT-174D 4-poort stekkerdoos met 2 x US...  Verdeelborden/-kasten   \n",
       "\n",
       "               chunkName                  productGroup     productSubGroup  \\\n",
       "0         Haaraccessoire                 Daily Care PG                Haar   \n",
       "1  Vrijstaande magnetron  Major Domestic Appliances PG             Cooking   \n",
       "2            Opdruksteun            Sporting Equipment       Fitness Klein   \n",
       "3              Led-strip                      Lighting  Slimme Verlichting   \n",
       "4            Stekkerdoos           Plumbing and Safety             Elektra   \n",
       "\n",
       "  productSubSubGroup registrationDateSeller countryOriginSeller  \\\n",
       "0   Haar Accessoires             2016-12-19                  NL   \n",
       "1            Cooking             2016-04-15                  NL   \n",
       "2  Fitnessmaterialen             2013-12-21                  NL   \n",
       "3  Slimme Led-Strips             2017-09-15                  NL   \n",
       "4   Verlengmateriaal             2017-05-31                  NL   \n",
       "\n",
       "  currentCountryAvailabilitySeller  calculationDefinitive  noCancellation  \\\n",
       "0                               NL                   True            True   \n",
       "1                               NL                   True            True   \n",
       "2                               NL                   True            True   \n",
       "3                               NL                   True           False   \n",
       "4                              ALL                   True            True   \n",
       "\n",
       "  onTimeDelivery  noCase  hasOneCase  hasMoreCases  noReturn  \\\n",
       "0            NaN    True         0.0           0.0      True   \n",
       "1            NaN   False         0.0           1.0      True   \n",
       "2           True    True         0.0           0.0      True   \n",
       "3            NaN    True         0.0           0.0      True   \n",
       "4           True   False         1.0           0.0     False   \n",
       "\n",
       "  detailedMatchClassification generalMatchClassification  caseDays  \\\n",
       "0                     UNKNOWN                    UNKNOWN       NaN   \n",
       "1       KNOWN HEAVILY UNHAPPY                    UNHAPPY       2.0   \n",
       "2                 KNOWN HAPPY                KNOWN HAPPY       NaN   \n",
       "3       KNOWN HEAVILY UNHAPPY                    UNHAPPY       NaN   \n",
       "4        KNOWN MEDIUM UNHAPPY                    UNHAPPY      17.0   \n",
       "\n",
       "   returnDays  cancellationDays  actualDeliveryDays  shipmentDays  \\\n",
       "0         NaN               NaN                 NaN           1.0   \n",
       "1         NaN               NaN                 NaN           1.0   \n",
       "2         NaN               NaN                 2.0           1.0   \n",
       "3         NaN               1.0                 NaN           NaN   \n",
       "4         3.0               NaN                 2.0           1.0   \n",
       "\n",
       "   partnerSellingDays  promisedDeliveryDays  orderYear  orderMonth  \\\n",
       "0                 743                     3       2019           1   \n",
       "1                 991                     6       2019           1   \n",
       "2                1837                     2       2019           1   \n",
       "3                 473                     2       2019           1   \n",
       "4                 580                     2       2019           1   \n",
       "\n",
       "   orderWeekday  orderCorona  orderMonday  orderTuesday  orderWednesday  \\\n",
       "0             1        False        False          True           False   \n",
       "1             1        False        False          True           False   \n",
       "2             1        False        False          True           False   \n",
       "3             1        False        False          True           False   \n",
       "4             1        False        False          True           False   \n",
       "\n",
       "   orderThursday  orderFriday  orderSaturday  orderSunday  orderJanuary  \\\n",
       "0          False        False          False        False          True   \n",
       "1          False        False          False        False          True   \n",
       "2          False        False          False        False          True   \n",
       "3          False        False          False        False          True   \n",
       "4          False        False          False        False          True   \n",
       "\n",
       "   orderFebruary  orderMarch  orderApril  orderMay  orderJune  orderJuly  \\\n",
       "0          False       False       False     False      False      False   \n",
       "1          False       False       False     False      False      False   \n",
       "2          False       False       False     False      False      False   \n",
       "3          False       False       False     False      False      False   \n",
       "4          False       False       False     False      False      False   \n",
       "\n",
       "   orderAugust  orderSeptember  orderOctober  orderNovember  orderDecember  \\\n",
       "0        False           False         False          False          False   \n",
       "1        False           False         False          False          False   \n",
       "2        False           False         False          False          False   \n",
       "3        False           False         False          False          False   \n",
       "4        False           False         False          False          False   \n",
       "\n",
       "   orderYear2019  orderYear2020  productTitleLength  fulfilmentByBol  \\\n",
       "0           True          False             4772950            False   \n",
       "1           True          False             4772950            False   \n",
       "2           True          False             4772950             True   \n",
       "3           True          False             4772950             True   \n",
       "4           True          False             4772950             True   \n",
       "\n",
       "   countryCodeNL  countryOriginNL  countryOriginBE  countryOriginDE  \\\n",
       "0           True             True            False            False   \n",
       "1           True             True            False            False   \n",
       "2          False             True            False            False   \n",
       "3           True             True            False            False   \n",
       "4           True             True            False            False   \n",
       "\n",
       "  determinantClassification binaryMatchClassification transporterCodeGeneral  \\\n",
       "0                      None                   UNKNOWN                  BRIEF   \n",
       "1                      None                     KNOWN                    DPD   \n",
       "2                  All good                     KNOWN                  OTHER   \n",
       "3              Cancellation                     KNOWN                  OTHER   \n",
       "4             Return + Case                     KNOWN                 POSTNL   \n",
       "\n",
       "         productGroupGeneral  groupHealth  groupHome  groupSports  \\\n",
       "0              Health & Care         True      False        False   \n",
       "1  Home, Cooking & Household        False       True        False   \n",
       "2   Sports, Outdoor & Travel        False      False         True   \n",
       "3  Home, Cooking & Household        False       True        False   \n",
       "4  Home, Cooking & Household        False       True        False   \n",
       "\n",
       "   groupComputer  groupPets  groupToys  groupBooks  groupBaby  groupMusic  \\\n",
       "0          False      False      False       False      False       False   \n",
       "1          False      False      False       False      False       False   \n",
       "2          False      False      False       False      False       False   \n",
       "3          False      False      False       False      False       False   \n",
       "4          False      False      False       False      False       False   \n",
       "\n",
       "   groupFood  groupOffice  groupFashion  groupOther  groupCar  \n",
       "0      False        False         False       False     False  \n",
       "1      False        False         False       False     False  \n",
       "2      False        False         False       False     False  \n",
       "3      False        False         False       False     False  \n",
       "4      False        False         False       False     False  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-czech",
   "metadata": {},
   "source": [
    "## Option 2: via direct sql connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structured-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (    \n",
    "    r'Driver={SQL Server};'\n",
    "    r'Server=LAPTOP-LD74USH0\\SQLEXPRESS;'\n",
    "    r'Integrated Security=SSPI;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "necessary-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql2df(query, params=[], parse_dates=None, dsn='SQLEXPRESS'):\n",
    "        with py.connect(connection_string, readonly=True) as conn:\n",
    "            return pd.read_sql(query, conn, params=params, parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frequent-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First work with random top 100.000 (to reduce computation time) - 45secs\n",
    "\n",
    "df = sql2df('''\n",
    "SELECT TOP 500000 * FROM Seminar.dbo.cleaned_bol_data_full\n",
    "ORDER BY newid();\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "abandoned-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.5 minutes \n",
    "\n",
    "df = sql2df('''\n",
    "SELECT * FROM Seminar.dbo.cleaned_bol_data_full;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "danish-syracuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orderDate             datetime64[ns]\n",
       "productId                     object\n",
       "sellerId                      object\n",
       "totalPrice                   float64\n",
       "quantityOrdered                int64\n",
       "                           ...      \n",
       "orderSeptember                  bool\n",
       "orderOctober                    bool\n",
       "orderNovember                   bool\n",
       "orderDecember                   bool\n",
       "productTitleLength             int64\n",
       "Length: 78, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change type of columns\n",
    "dtype = {'calculationDefinitive': bool,\n",
    "         'noCancellation': bool,\n",
    "         'noCase': bool,\n",
    "         'hasOneCase': bool,\n",
    "         'hasMoreCases': bool,\n",
    "         'noReturn': bool,\n",
    "         'orderWeekend': bool,\n",
    "         'orderCorona': bool,\n",
    "         'countryCodeNL': bool,\n",
    "         'fulfilmentByBol': bool,\n",
    "         'countryOriginNL': bool,\n",
    "         'countryOriginBE': bool,\n",
    "         'countryOriginDE': bool,\n",
    "         'orderMonday': bool,\n",
    "         'orderTuesday': bool,\n",
    "         'orderWednesday': bool,\n",
    "         'orderThursday': bool,\n",
    "         'orderFriday': bool,\n",
    "         'orderSaturday': bool,\n",
    "         'orderSunday': bool,\n",
    "         'orderJanuary': bool,\n",
    "         'orderFebruary': bool,\n",
    "         'orderMarch': bool,\n",
    "         'orderApril': bool,\n",
    "         'orderMay': bool,\n",
    "         'orderJune': bool,\n",
    "         'orderJuly': bool,\n",
    "         'orderAugust': bool,\n",
    "         'orderSeptember': bool,\n",
    "         'orderOctober': bool,\n",
    "         'orderNovember': bool,\n",
    "         'orderDecember': bool}\n",
    "\n",
    "df = df.astype(dtype)\n",
    "\n",
    "#Transform dates to date-type\n",
    "df['orderDate'] = pd.to_datetime(df['orderDate'], errors='coerce')\n",
    "df['cancellationDate'] = pd.to_datetime(df['cancellationDate'], errors='coerce')\n",
    "df['promisedDeliveryDate'] = pd.to_datetime(df['promisedDeliveryDate'], errors='coerce')\n",
    "df['shipmentDate'] = pd.to_datetime(df['shipmentDate'], errors='coerce')\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'], errors='coerce')\n",
    "df['startDateCase'] = pd.to_datetime(df['startDateCase'], errors='coerce')\n",
    "df['returnDateTime'] = pd.to_datetime(df['returnDateTime'], errors='coerce')\n",
    "df['registrationDateSeller'] = pd.to_datetime(df['registrationDateSeller'], errors='coerce')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-occasions",
   "metadata": {},
   "source": [
    "#### Add variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approved-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification variable\n",
    "df['binaryMatchClassification'] = df['generalMatchClassification'].apply(lambda x: 'UNKNOWN' if x == 'UNKNOWN' else 'KNOWN')\n",
    "\n",
    "# Dummy for year = 2020\n",
    "df['orderYear2020'] = df['orderYear'].apply(lambda x: True if x == 2020 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-religious",
   "metadata": {},
   "source": [
    "#### Transporter Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "known-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transporterCluster(transporterCode):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered transporter variable: 28 -> 5 categories\n",
    "    \"\"\"\n",
    "    if transporterCode in ['AH-NL','TNT','TNT-EXPRESS','TNT-EXTRA']:\n",
    "        return 'POSTNL'\n",
    "    elif transporterCode in ['DHL','DHL_DE','DHLFORYOU']:\n",
    "        return 'DHL'\n",
    "    elif transporterCode in ['DPD-NL','DPD-BE']:\n",
    "        return 'DPD'\n",
    "    elif transporterCode in ['BRIEFPOST','BPOST_BE','BPOST_BRIEF','DHL-GLOBAL-MAIL','TNT_BRIEF']:\n",
    "        return 'BRIEF'\n",
    "    else:\n",
    "        return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "practical-dress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSTNL    221508\n",
       "BRIEF     165035\n",
       "DHL        45527\n",
       "DPD        34475\n",
       "OTHER      33455\n",
       "Name: transporterCodeGeneral, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transporterCodeGeneral'] = df['transporterCode'].apply(transporterCluster)\n",
    "df['transporterCodeGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-campbell",
   "metadata": {},
   "source": [
    "#### Product Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "physical-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "def productGroupCluster(productGroup):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered product group variable based on categories bol.com\n",
    "    60 -> 14 groups.\n",
    "    \"\"\"\n",
    "    if productGroup in ['Dutch Books PG','Ebooks and Audiobooks','International Books PG']:\n",
    "        return 'Books'\n",
    "    elif productGroup in ['Games Accessories','Games Consoles','Games Software Physical',\n",
    "                          'Movies','Music']:\n",
    "        return 'Music, Film & Games'\n",
    "    elif productGroup in ['Camera','Desktop Monitor and Beamer','Ereaders and Accessories',\n",
    "                          'Laptop Computers','PC Accessories','Personal Audio',\n",
    "                          'Sound and Vision Accessories','Storage and Network',\n",
    "                          'Telephone and Tablet Accessories','Telephones and Tablets','Television']:\n",
    "        return 'Computer & Electronics'\n",
    "    elif productGroup in ['General Toys','Recreational and Outdoor Toys']:\n",
    "        return 'Toys & Hobby'\n",
    "    elif productGroup in ['Baby and Kids Fashion','Baby PG']:\n",
    "        return 'Baby & Kids'\n",
    "    elif productGroup in ['Daily Care PG','Health PG','Perfumery PG','Personal Care']:\n",
    "        return 'Health & Care'\n",
    "    elif productGroup in ['Footwear','Jewelry and Watches','Mens and Womens Fashion','Wearables']:\n",
    "        return 'Fashion, Shoes & Accessories'\n",
    "    elif productGroup in ['Bodyfashion and Beachwear','Camping and Outdoor','Cycling',\n",
    "                          'Sporting Equipment','Sportswear','Travel Bags and Accessories']:\n",
    "        return 'Sports, Outdoor & Travel'\n",
    "    elif productGroup in ['Educational Dutch','Educational International','Printing and Ink']:\n",
    "        return 'Office & School'\n",
    "    elif productGroup in ['Supermarket PG'] :\n",
    "        return 'Food & Beverage'\n",
    "    elif productGroup in ['Furniture','Heating and Air','Home Decoration','Home Entertainment',\n",
    "                          'Household','Household Appliances','Kitchen','Kitchen Machines',\n",
    "                          'Lighting','Major Domestic Appliances PG','Plumbing and Safety']:\n",
    "        return 'Home, Cooking & Household'\n",
    "    elif productGroup in ['Garden','Pet PG','Textiles','Tools and Paint']:\n",
    "        return 'Pets, Garden & Jobs'\n",
    "    elif productGroup in ['Car and Motorcycle'] :\n",
    "        return 'Car & Motor'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "trained-baseline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer & Electronics          145687\n",
       "Home, Cooking & Household        83348\n",
       "Sports, Outdoor & Travel         54598\n",
       "Toys & Hobby                     52834\n",
       "Pets, Garden & Jobs              35484\n",
       "Health & Care                    31315\n",
       "Food & Beverage                  26802\n",
       "Books                            19435\n",
       "Music, Film & Games              17343\n",
       "Baby & Kids                      11784\n",
       "Fashion, Shoes & Accessories     11453\n",
       "Office & School                   5450\n",
       "Car & Motor                       3149\n",
       "Other                             1318\n",
       "Name: productGroupGeneral, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['productGroupGeneral'] = df['productGroup'].apply(productGroupCluster)\n",
    "df['productGroupGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "significant-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummies of new product grouping\n",
    "for group in df['productGroupGeneral'].unique():\n",
    "    \n",
    "    columnName = 'group' + group.split(' ')[0].replace(',','')\n",
    "    df[columnName] = df['productGroupGeneral'].apply(lambda x: True if x == group else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regulation-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orderDate', 'productId', 'sellerId', 'totalPrice', 'quantityOrdered',\n",
      "       'countryCode', 'cancellationDate', 'cancellationReasonCode',\n",
      "       'promisedDeliveryDate', 'shipmentDate', 'transporterCode',\n",
      "       'transporterName', 'transporterNameOther',\n",
      "       'dateTimeFirstDeliveryMoment', 'fulfilmentType', 'startDateCase',\n",
      "       'cntDistinctCaseIds', 'returnDateTime', 'quantityReturned',\n",
      "       'returnCode', 'productTitle', 'brickName', 'chunkName', 'productGroup',\n",
      "       'productSubGroup', 'productSubSubGroup', 'registrationDateSeller',\n",
      "       'countryOriginSeller', 'currentCountryAvailabilitySeller',\n",
      "       'calculationDefinitive', 'noCancellation', 'onTimeDelivery', 'noCase',\n",
      "       'hasOneCase', 'hasMoreCases', 'noReturn', 'detailedMatchClassification',\n",
      "       'generalMatchClassification', 'determinantClassification', 'orderYear',\n",
      "       'orderMonth', 'orderYearMonth', 'orderWeekday', 'orderWeekend',\n",
      "       'orderCorona', 'transporterFeature', 'partnerSellingMonths',\n",
      "       'cancellationDays', 'shipmentDays', 'promisedDeliveryDays',\n",
      "       'actualDeliveryDays', 'caseDays', 'returnDays', 'countryCodeNL',\n",
      "       'fulfilmentByBol', 'countryOriginNL', 'countryOriginBE',\n",
      "       'countryOriginDE', 'orderMonday', 'orderTuesday', 'orderWednesday',\n",
      "       'orderThursday', 'orderFriday', 'orderSaturday', 'orderSunday',\n",
      "       'orderJanuary', 'orderFebruary', 'orderMarch', 'orderApril', 'orderMay',\n",
      "       'orderJune', 'orderJuly', 'orderAugust', 'orderSeptember',\n",
      "       'orderOctober', 'orderNovember', 'orderDecember', 'productTitleLength',\n",
      "       'binaryMatchClassification', 'orderYear2020', 'transporterCodeGeneral',\n",
      "       'productGroupGeneral', 'groupHome', 'groupHealth', 'groupSports',\n",
      "       'groupFood', 'groupToys', 'groupComputer', 'groupMusic', 'groupFashion',\n",
      "       'groupBooks', 'groupPets', 'groupBaby', 'groupCar', 'groupOffice',\n",
      "       'groupOther'],\n",
      "      dtype='object')\n",
      "Total:  96  columns\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print('Total: ',len(df.columns),' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "domestic-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "\n",
    "#Classifications\n",
    "CLASS = ['generalMatchClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-superior",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "external-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addKnownColumns(df,X):\n",
    "    \"\"\"\n",
    "    Function to create columns which indicate whether determinants are known after X days.\n",
    "    Input: X = number of days after order date at which the prediction is made\n",
    "           df = dataFrame\n",
    "    \"\"\"\n",
    "#     df_ = df[['actualDeliveryDays','onTimeDelivery','shipmentDays','transporterCodeGeneral']]\n",
    "    \n",
    "    df['caseKnownX']           = df['caseDays'].apply(lambda x: True if x <= X else False)\n",
    "    df['returnKnownX']         = df['returnDays'].apply(lambda x: True if x <= X else False)\n",
    "    df['cancellationKnownX']   = df['cancellationDays'].apply(lambda x: True if x <= X else False)\n",
    "    \n",
    "#     df_['actualDeliveryKnown'] = df['actualDeliveryDays'].apply(lambda x: True if x <= X else False)\n",
    "#     df_['shipmentDaysKnown']   = df['shipmentDays'].apply(lambda x: True if x <= X else False)\n",
    "    \n",
    "    df['onTimeDeliveryKnownX'] = df.apply(lambda row: True if ((row.actualDeliveryDays <= X) and (row.onTimeDelivery == True)) else False, axis = 1)\n",
    "    df['lateDeliveryKnownX']   = df.apply(lambda row: True if ((row.actualDeliveryDays <= X) and (row.onTimeDelivery == False)) else False, axis = 1)\n",
    "    \n",
    "    for transporter in df['transporterCodeGeneral'].unique():\n",
    "        dummyColumn = 'transporter' + transporter +'/X'\n",
    "        df[dummyColumn] = df.apply(lambda row: True if ((row.shipmentDays <= X) and (row.transporterCodeGeneral == transporter)) else False, axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "homeless-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addProductColumns(df,X):\n",
    "    \n",
    "    if ['productOrderCount0','productTotalCount0','productTotalReturned0','productReturnFraction0'] not in list(df.columns):\n",
    "    \n",
    "        df = addProductColumns0(df)\n",
    "    \n",
    "    if X > 0:\n",
    "        \n",
    "        df = addProductColumnsX(df,X)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df['productOrderCountX'] = df['productOrderCount0']\n",
    "        df['productTotalCountX'] = df['productTotalCount0']\n",
    "        df['productTotalReturnedX'] = df['productTotalReturned0']\n",
    "        df['productReturnFractionX'] = df['productReturnFraction0']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecological-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSellerColumns(df,X):\n",
    "    \n",
    "    if 'sellerDailyOrders0' not in list(df.columns):\n",
    "    \n",
    "        df = addSellerColumns0(df)\n",
    "    \n",
    "    if X > 0:\n",
    "        \n",
    "        df = addSellerColumnsX(df,X)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        df['sellerDailyOrdersX'] = df['sellerDailyOrders0']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "analyzed-porter",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addProductColumns0(df): \n",
    "    \"\"\"\n",
    "    Function to add 4 columns: productOrderCount, productTotalCount, productTotalReturned and productReturnFraction.\n",
    "    Input: dataFrame with columns: 'productId','orderDate','quantityOrdered','quantityReturned','returnDateTime'.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by = ['productId','orderDate'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df_ = df[['productId','orderDate','quantityOrdered','quantityReturned','returnDateTime']]\n",
    "    \n",
    "    #ProductTotalCount\n",
    "    pivot = df_.groupby(['productId','orderDate']).quantityOrdered.sum().groupby('productId').cumsum()\n",
    "    productTotalCount = df_.merge(pivot, \n",
    "                                left_on=['productId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').quantityOrdered_y\n",
    "    \n",
    "    #ProductOrderCount\n",
    "    pivot = df_.groupby(['productId','orderDate']).quantityOrdered.count().groupby('productId').cumsum()\n",
    "    productOrderCount = df_.merge(pivot, \n",
    "                                left_on=['productId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').quantityOrdered_y\n",
    "    \n",
    "    #ProductTotalReturned\n",
    "    productTotalReturned = np.zeros(df_.shape[0])\n",
    "    \n",
    "    previousID = None\n",
    "    \n",
    "    returnDic = {}\n",
    "    \n",
    "    for row in df_.itertuples(): #iterate through dataFrame: row[0] = index, row[1] = productId, row[2] = orderDate\n",
    "                                                           # row[3] = quantityOrdered, row[4] = quantityReturned\n",
    "        if row[0] == 0:                                    # row[5] = returnDateTime\n",
    "            \n",
    "            #update return dictionary if this product is returned\n",
    "            if row[4] != None:\n",
    "                if row[5] in returnDic:\n",
    "                    returnDic[row[5]] += row[4]\n",
    "                else:\n",
    "                    returnDic[row[5]] = row[4]\n",
    "\n",
    "            previousID = row[1]\n",
    "            \n",
    "        elif (previousID == row[1]):\n",
    "            \n",
    "            #update return dictionary if this product is returned\n",
    "            if row[4] != None:\n",
    "                if row[5] in returnDic:\n",
    "                    returnDic[row[5]] += row[4]\n",
    "                else:\n",
    "                    returnDic[row[5]] = row[4]\n",
    "            \n",
    "            #add returned products to new dictionary if known\n",
    "            known = {k: v for k, v in returnDic.items() if k <= row[2]}\n",
    "            productTotalReturned[row[0]] = sum(known.values())\n",
    "            \n",
    "            #update the dictionary by removing the returns which are now known\n",
    "            returnDic = {k: v for k, v in returnDic.items() if k > row[2]}\n",
    "                        \n",
    "            previousID = row[1]\n",
    "            \n",
    "        else:\n",
    "            returnDic = {} #new productId, hence empty the return dictionary\n",
    "            \n",
    "            #update return dictionary if this product is returned\n",
    "            if row[4] != None:\n",
    "                if row[5] in returnDic:\n",
    "                    returnDic[row[5]] += row[4]\n",
    "                else:\n",
    "                    returnDic[row[5]] = row[4]\n",
    "                    \n",
    "            previousID = row[1]\n",
    "    \n",
    "    df_['productTotalReturned'] = productTotalReturned\n",
    "    pivot = df_.groupby(by = ['productId','orderDate']).productTotalReturned.sum().groupby('productId').cumsum()\n",
    "    productTotalReturned = df_.merge(pivot, \n",
    "                                left_on=['productId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').productTotalReturned_y\n",
    "     \n",
    "    #Add new columns to dataFrame    \n",
    "    df['productOrderCount0'] = productOrderCount\n",
    "    df['productTotalCount0'] = productTotalCount\n",
    "    df['productTotalReturned0'] = productTotalReturned\n",
    "    df['productReturnFraction0'] = productTotalReturned / productTotalCount\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "celtic-quarterly",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addProductColumnsX(df,X):\n",
    "    \"\"\"\n",
    "    Function to add 4 columns: productOrderCountX, productTotalCountX, productTotalReturnedX and productReturnFractionX.\n",
    "    Input: dataFrame with columns: 'productId','orderDate','productOrderCount','productTotalCount','productTotalReturned'\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by = ['productId','orderDate'], ascending = [True, False]) #reverse ordering on Orderdate!\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df_ = df[['productId','orderDate','productOrderCount0','productTotalCount0','productTotalReturned0']]\n",
    "    #            row[1]       row[2]        row[3]               row[4]                 row[5]    \n",
    "    \n",
    "    df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
    "    #      row[6]\n",
    "\n",
    "    knownProductInfo = np.zeros((df_.shape[0],3))\n",
    "    \n",
    "    previousID = None\n",
    "    previousMaxDate = None\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    for row in df_.itertuples(): #iterate  \n",
    "                                                                  \n",
    "        if row[0] == 0:                                          \n",
    "            \n",
    "            knownProductInfo[[row[0]]] = (row[3],row[4],row[5]) \n",
    "            \n",
    "            dic[row[2]] = (row[3],row[4],row[5])\n",
    "\n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "            \n",
    "        elif (previousID == row[1]):\n",
    "            \n",
    "            if row[6] >= previousMaxDate:\n",
    "                dic[row[2]] = (row[3],row[4],row[5])\n",
    "                knownProductInfo[[row[0]]] = dic[max(dic)]\n",
    "            else:\n",
    "                dic[row[2]] = (row[3],row[4],row[5])\n",
    "                dic = {k: v for k, v in dic.items() if k <= row[6]}\n",
    "                \n",
    "                knownProductInfo[[row[0]]] = dic[max(dic)]\n",
    "                previousMaxDate = max(dic)\n",
    "                 \n",
    "            previousID = row[1]\n",
    "            \n",
    "        else:\n",
    "            dic = {} #new productId -> empty the dictionary\n",
    "            \n",
    "            knownProductInfo[[row[0]]] = (row[3],row[4],row[5])\n",
    "            dic[row[2]] = (row[3],row[4],row[5])\n",
    "                    \n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "\n",
    "    df['productOrderCountX'] = knownProductInfo[:,0]\n",
    "    df['productTotalCountX'] = knownProductInfo[:,1]\n",
    "    df['productTotalReturnedX'] = knownProductInfo[:,2]\n",
    "    df['productReturnFractionX'] = knownProductInfo[:,2] / knownProductInfo[:,1]\n",
    "    \n",
    "    #Reverse to natural order\n",
    "    df = df.sort_values(by = ['productId','orderDate'], ascending = [True, True])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sitting-hollywood",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addSellerColumns0(df):\n",
    "    \"\"\"\n",
    "    Function to add 4 columns: \n",
    "    Input: dataFrame with columns: 'sellerId','orderDate','quantityOrdered','partnerSellingMonths'\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by = ['sellerId','orderDate'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df_ = df[['sellerId','orderDate','quantityOrdered','partnerSellingMonths']]\n",
    "    \n",
    "    firstOrder = df_.groupby('sellerId').orderDate.min()\n",
    "    df_['firstOrder'] = df_.merge(firstOrder,\n",
    "                                  left_on = 'sellerId',\n",
    "                                  right_index = True,\n",
    "                                  how = 'left').orderDate_y\n",
    "    df_['daysFirstOrder'] = (df_['orderDate'] - df_['firstOrder']).dt.days + 1\n",
    "    \n",
    "    pivot = df_.groupby(['sellerId','orderDate']).quantityOrdered.count().groupby('sellerId').cumsum()\n",
    "    sellerTotalCount = df_.merge(pivot, \n",
    "                                left_on=['sellerId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').quantityOrdered_y\n",
    "    \n",
    "    df['sellerDailyOrders0'] = np.log(sellerTotalCount / df_['daysFirstOrder'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "virgin-words",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addSellerColumnsX(df,X):\n",
    "    \"\"\"\n",
    "    Function to add 4 columns: \n",
    "    Input: dataFrame with columns: 'sellerId','orderDate','quantityOrdered','partnerSellingMonths'\n",
    "    \"\"\"\n",
    "        \n",
    "    df = df.sort_values(by = ['sellerId','orderDate'], ascending = [True, False]) #reverse ordering orderdate!\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    df_ = df[['sellerId','orderDate','sellerDailyOrders0']]\n",
    "    #            row[1]       row[2]        row[3]        \n",
    "\n",
    "    df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
    "    #      row[4]\n",
    "\n",
    "    knownSellerInfo = np.zeros(df_.shape[0])\n",
    "\n",
    "    previousID = None\n",
    "    previousMaxDate = None\n",
    "\n",
    "    dic = {}\n",
    "\n",
    "    for row in df_.itertuples(): #iterate  \n",
    "\n",
    "        if row[0] == 0:                                          \n",
    "\n",
    "            knownSellerInfo[[row[0]]] = row[3]\n",
    "\n",
    "            dic[row[2]] = row[3]\n",
    "\n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "\n",
    "        elif (previousID == row[1]):\n",
    "\n",
    "            if row[4] >= previousMaxDate:\n",
    "                dic[row[2]] = row[3]\n",
    "                knownSellerInfo[[row[0]]] = dic[max(dic)]\n",
    "            else:\n",
    "                dic[row[2]] = row[3]\n",
    "                dic = {k: v for k, v in dic.items() if k <= row[4]}\n",
    "\n",
    "                knownSellerInfo[[row[0]]] = dic[max(dic)]\n",
    "                previousMaxDate = max(dic)\n",
    "\n",
    "            previousID = row[1]\n",
    "\n",
    "        else:\n",
    "            dic = {} #new productId -> empty the dictionary\n",
    "\n",
    "            knownSellerInfo[[row[0]]] = row[3]\n",
    "            dic[row[2]] = row[3]\n",
    "\n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "\n",
    "    df['sellerDailyOrdersX'] = knownSellerInfo\n",
    "\n",
    "    #Reverse to natural order\n",
    "    df = df.sort_values(by = ['sellerId','orderDate'], ascending = [True, True])\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incident-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLabels(classifier, X, y, n, split = 'TimeSeries', smote = False, scale = None, days = 0):\n",
    "    \"\"\"\n",
    "    Function to classify match labels using a pre-specified classifier with X and y variables. \n",
    "    \n",
    "    Input:\n",
    "    - classifier: can be any supported classifier. E.g. DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth=10). Necessary!\n",
    "    - X: dataframe input on explanatory features. Necessary!\n",
    "    - y: dataframe input on labels. Necessary!\n",
    "    - n: number of folds to be evaluated.\n",
    "    - split: object that can take value 'Random' to make K-fold random train/test split. Default is to apply time series split.\n",
    "    - smote: boolean, if true Synthetic Minority Oversampling will be applied. Default = False.\n",
    "    - scale: object that can take values 'MinMax' or 'Standard' to scale X correspondingly. Any other input will not scale X. Default = None.\n",
    "    - days: integer number of days after orderDate that should be considered. Default = 0.\n",
    "    \n",
    "    Output: \n",
    "    - accuracy: list of accuracies for the n evaluated classifiers.\n",
    "    - class_report: report of performance measures for the n evaluated classifiers.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = {}\n",
    "    class_report = {}\n",
    "    count = 1\n",
    "    \n",
    "    if split == 'Random':\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits = n, random_state = 0, shuffle = True)\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            if scale == 'MinMax':\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            elif scale == 'Standard':\n",
    "                scaler = preprocessing.StandardScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            else:\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            if smote == True:\n",
    "                smote = SMOTE('not majority')\n",
    "                X_train, y_train = smote.fit_sample(X_train,y_train)\n",
    "            else:\n",
    "                X_train, y_train = X_train, y_train\n",
    "            \n",
    "            clf = classifier\n",
    "            clf = clf.fit(X_train,y_train)\n",
    "            prediction = clf.predict(X_test)\n",
    "            accuracy[count] = metrics.accuracy_score(y_test, prediction)\n",
    "            class_report[count] = metrics.classification_report(y_test, prediction)\n",
    "    \n",
    "            print(count)\n",
    "            count +=1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits = n)\n",
    "        \n",
    "        for train_index, test_index in tscv.split(X):\n",
    "        \n",
    "            if scale == 'MinMax':\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            elif scale == 'Standard':\n",
    "                scaler = preprocessing.StandardScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            else:\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            if smote == True:\n",
    "                smote = SMOTE('not majority')\n",
    "                X_train, y_train = smote.fit_sample(X_train,y_train)\n",
    "            else:\n",
    "                X_train, y_train = X_train, y_train\n",
    "            \n",
    "            clf = classifier\n",
    "            clf = clf.fit(X_train,y_train)\n",
    "            prediction = clf.predict(X_test)\n",
    "            accuracy[count] = metrics.accuracy_score(y_test, prediction)\n",
    "            class_report[count] = metrics.classification_report(y_test, prediction)\n",
    "    \n",
    "            print(count)\n",
    "            count +=1\n",
    "\n",
    "    return(accuracy, class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "allied-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['productId', 'sellerId', 'countryCode', 'cancellationReasonCode', 'transporterCode', 'transporterName', 'transporterNameOther', 'fulfilmentType', 'returnCode', 'productTitle', 'brickName', 'chunkName', 'productGroup', 'productSubGroup', 'productSubSubGroup', 'countryOriginSeller', 'currentCountryAvailabilitySeller', 'onTimeDelivery', 'detailedMatchClassification', 'generalMatchClassification', 'determinantClassification', 'orderMonth', 'orderYearMonth', 'transporterFeature', 'binaryMatchClassification', 'transporterCodeGeneral', 'productGroupGeneral']\n"
     ]
    }
   ],
   "source": [
    "#Categorical variables\n",
    "s = (df.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-handy",
   "metadata": {},
   "source": [
    "# Function-based Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-apache",
   "metadata": {},
   "source": [
    "## Define X and y variables for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pacific-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['orderDate']\n",
    "X_col_base = ['totalPrice','quantityOrdered','promisedDeliveryDays','orderCorona','partnerSellingMonths',\n",
    "        'countryCodeNL', 'fulfilmentByBol', 'countryOriginNL', 'countryOriginBE', 'countryOriginDE', 'orderWeekend',\n",
    "        'orderMonday','orderTuesday', 'orderWednesday', 'orderThursday', 'orderFriday', 'orderSaturday', 'orderSunday',\n",
    "        'orderJanuary', 'orderFebruary', 'orderMarch', 'orderApril', 'orderMay', 'orderJune', 'orderJuly',\n",
    "        'orderAugust', 'orderSeptember', 'orderOctober', 'orderNovember', 'orderDecember', 'productTitleLength',\n",
    "        'orderYear2020', 'groupComputer', 'groupFood', 'groupBooks', 'groupHealth', 'groupToys', 'groupSports', \n",
    "        'groupHome', 'groupOffice', 'groupPets', 'groupMusic', 'groupFashion', 'groupBaby', 'groupOther', 'groupCar']\n",
    "#y_col = ['binaryMatchClassification']\n",
    "y_col = ['generalMatchClassification']\n",
    "#'productOrderCount', 'productReturnFraction', "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-window",
   "metadata": {},
   "source": [
    "## Function to return X and y for a pre-specified number of days after orderDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "protecting-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataX(df,days):\n",
    "    \"\"\"\n",
    "    Function to return features and output labels for a pre-specified number of days after orderDate. \n",
    "    \n",
    "    Input:\n",
    "    - df: dataframe containing all features available at the time of ordering.\n",
    "    - days: integer number of days after orderDate that should be considered.\n",
    "    \n",
    "    Output: \n",
    "    - X: dataframe output of features that can be used the number of days after orderDate. E.g. information on cases and deliveries are added.\n",
    "    - y: dataframe output of output labels that can be used the number of days after orderDate.\n",
    "    \"\"\"    \n",
    "    \n",
    "    df = addKnownColumns(df,days)\n",
    "    df = addProductColumns(df,days)\n",
    "    df = addSellerColumns(df,days)\n",
    "    \n",
    "    if days == 0:\n",
    "        X_col = X_col_base + ['productOrderCountX', 'productTotalCountX',\n",
    "                 'productTotalReturnedX', 'productReturnFractionX', 'sellerDailyOrdersX']\n",
    "    else:\n",
    "        X_col = X_col_base + ['caseKnownX', 'returnKnownX', 'cancellationKnownX', 'onTimeDeliveryKnownX',\n",
    "                 'lateDeliveryKnownX', 'transporterPOSTNL/X', 'transporterDHL/X', 'transporterDPD/X', \n",
    "                 'transporterBRIEF/X', 'transporterOTHER/X', 'productOrderCountX', 'productTotalCountX',\n",
    "                 'productTotalReturnedX', 'productReturnFractionX', 'sellerDailyOrdersX']\n",
    "\n",
    "    df_test = df[index+X_col+y_col].dropna()\n",
    "    df_test = df_test.sort_values(by = 'orderDate')\n",
    "    df_test = df_test.reset_index(drop = True)\n",
    "\n",
    "    X = df_test[X_col]\n",
    "    y = df_test[y_col]\n",
    "    \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "partial-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=25,activation='relu'))\n",
    "    model.add(Dense(units=3,activation='softmax')) #units should equal number of labels\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#estimator = KerasClassifier(build_fn = neuralNetwork, epochs = 20, class_weight = class_weights, verbose = 1)\n",
    "#history = estimator.fit(X_train, y_train)\n",
    "#pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "affecting-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLabelsQuick(classifier, X, y, n, split = 'TimeSeries', smote = False, scale = None, days = 0):\n",
    "    \n",
    "    accuracy = {}\n",
    "    class_report = {}\n",
    "    \n",
    "    if split == 'Random':\n",
    "        split_type = StratifiedKFold(n_splits = n, random_state = 0, shuffle = True)\n",
    "        \n",
    "    else:\n",
    "        split_type = TimeSeriesSplit(n_splits = n)\n",
    "    \n",
    "    #Create pipeline -> everything in the pipeline is executed after eachother\n",
    "    pipe = Pipeline([('scaler', preprocessing.MinMaxScaler()), ('classifier', classifier)])\n",
    "    \n",
    "    #Cross validation function which outputs the accuracy and average (unweighted) precision and recall of labels\n",
    "    y_pred = cross_validate(pipe, X, y, cv = split_type, scoring = ('precision_macro', 'recall_macro', 'accuracy'), return_train_score = True)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-polyester",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-elephant",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "foster-marriage",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-815bebd517d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 5. In order to create classification report you need the encoded_y or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#    if you want the label names use le.inverse_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_y_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'encoded_y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Training Neural Network:\n",
    "\n",
    "# 1. Use MinMaxScaler\n",
    "# 2. Multilabel output should be converted into dummies\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "encoded_y = le.transform(y)\n",
    "dummy_y = pd.DataFrame(np_utils.to_categorical(encoded_y))\n",
    "# 3. Class-weights have to be computed beforehand (only the training weights actually)\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                   np.unique(encoded_y),\n",
    "                                                   encoded_y)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "# 4. Use the folowwing estimator\n",
    "estimator = KerasClassifier(build_fn = neuralNetwork, #model defined below\n",
    "                            epochs = 20, \n",
    "                            class_weight = class_weights,\n",
    "                            verbose = 0)\n",
    "# 5. In order to create classification report you need the encoded_y or\n",
    "#    if you want the label names use le.inverse_transform\n",
    "metrics.classification_report(encoded_y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-garlic",
   "metadata": {},
   "source": [
    "### Function: classifyLabels(classifier, X, y, n, split = 'TimeSeries', smote = False, scale = None, days = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "familiar-craps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "A = 5\n",
    "\n",
    "resultsAcc = {}\n",
    "resultsClass = {}\n",
    "\n",
    "for DAYS in range(A):\n",
    "    \n",
    "    X, y = dataX(df,DAYS)\n",
    "    print('Lets Go')\n",
    "    \n",
    "    accuracy, class_report = classifyLabels(DecisionTreeClassifier(random_state=0,\n",
    "                                                                   class_weight='balanced'), X, y, n = 3)\n",
    "        \n",
    "    resultsAcc[DAYS] = accuracy\n",
    "    resultsClass[DAYS] = class_report\n",
    "    \n",
    "    print(DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ambient-strength",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1: 0.604816, 2: 0.6168, 3: 0.640976},\n",
       " 1: {1: 0.736872, 2: 0.72452, 3: 0.738128},\n",
       " 2: {1: 0.767872, 2: 0.755368, 3: 0.778936},\n",
       " 3: {1: 0.78952, 2: 0.778312, 3: 0.79404},\n",
       " 4: {1: 0.80728, 2: 0.786088, 3: 0.795896}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "statewide-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_accuracies_binary = resultsAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "handed-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_report_binary = resultsClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "hispanic-oracle",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.84      0.91      0.87     16759\n",
      "     UNKNOWN       0.77      0.65      0.71      8241\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.81      0.78      0.79     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.86      0.94      0.90     18233\n",
      "     UNKNOWN       0.78      0.59      0.67      6767\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.82      0.76      0.78     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.82      0.95      0.88     16847\n",
      "     UNKNOWN       0.85      0.57      0.68      8153\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.76      0.78     25000\n",
      "weighted avg       0.83      0.83      0.82     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.92      0.94      0.93     16759\n",
      "     UNKNOWN       0.87      0.83      0.85      8241\n",
      "\n",
      "    accuracy                           0.90     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.90      0.90      0.90     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.93      0.95      0.94     18233\n",
      "     UNKNOWN       0.86      0.81      0.84      6767\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.90      0.88      0.89     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.91      0.96      0.94     16847\n",
      "     UNKNOWN       0.91      0.81      0.86      8153\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.91      0.89      0.90     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.93      0.94      0.94     16759\n",
      "     UNKNOWN       0.87      0.86      0.87      8241\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.90      0.90      0.90     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.96      0.95     18233\n",
      "     UNKNOWN       0.89      0.84      0.87      6767\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.92      0.90      0.91     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.97      0.95     16847\n",
      "     UNKNOWN       0.92      0.86      0.89      8153\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.91      0.92     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.93      0.95      0.94     16759\n",
      "     UNKNOWN       0.90      0.86      0.88      8241\n",
      "\n",
      "    accuracy                           0.92     25000\n",
      "   macro avg       0.91      0.91      0.91     25000\n",
      "weighted avg       0.92      0.92      0.92     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     18233\n",
      "     UNKNOWN       0.90      0.87      0.89      6767\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.93      0.92      0.92     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16847\n",
      "     UNKNOWN       0.93      0.89      0.91      8153\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.93     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.96      0.95     16759\n",
      "     UNKNOWN       0.91      0.88      0.90      8241\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.92      0.92     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     18233\n",
      "     UNKNOWN       0.92      0.87      0.89      6767\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.93      0.92      0.93     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16847\n",
      "     UNKNOWN       0.94      0.89      0.91      8153\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.94      0.93      0.94     25000\n",
      "weighted avg       0.94      0.95      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.96      0.95     16759\n",
      "     UNKNOWN       0.92      0.88      0.90      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.93      0.92      0.93     25000\n",
      "weighted avg       0.94      0.94      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     18233\n",
      "     UNKNOWN       0.93      0.87      0.90      6767\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.94      0.92      0.93     25000\n",
      "weighted avg       0.94      0.95      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.98      0.96     16847\n",
      "     UNKNOWN       0.95      0.90      0.92      8153\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.94      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.96      0.96     16759\n",
      "     UNKNOWN       0.92      0.89      0.91      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.93     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.94      0.88      0.91      6767\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.93      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.98      0.97     16847\n",
      "     UNKNOWN       0.95      0.90      0.93      8153\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.94      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16759\n",
      "     UNKNOWN       0.93      0.90      0.91      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.94     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.94      0.88      0.91      6767\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.93      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     16847\n",
      "     UNKNOWN       0.96      0.91      0.93      8153\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.96      0.94      0.95     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16759\n",
      "     UNKNOWN       0.94      0.89      0.91      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.94     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.95      0.89      0.91      6767\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.95      0.93      0.94     25000\n",
      "weighted avg       0.96      0.96      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     16847\n",
      "     UNKNOWN       0.96      0.91      0.93      8153\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.96      0.94      0.95     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16759\n",
      "     UNKNOWN       0.94      0.90      0.92      8241\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.94      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.95      0.89      0.92      6767\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.95      0.94      0.94     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     16847\n",
      "     UNKNOWN       0.96      0.91      0.93      8153\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.96      0.94      0.95     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(A):\n",
    "    for item in resultsClass[i].values():\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "former-peninsula",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-222-87b2216d9be3>:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['productTotalReturned'] = productTotalReturned\n",
      "<ipython-input-223-2e46c60816db>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
      "<ipython-input-224-c875244aaa5a>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['daysFirstOrder'] = (df_['orderDate'] - df_['firstOrder']).dt.days + 1\n",
      "<ipython-input-225-754f78ba8450>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.8126, 2: 0.83996, 3: 0.8458}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.88      0.87      0.88     13647\n",
      "     UNHAPPY       0.49      0.56      0.53      3112\n",
      "     UNKNOWN       0.83      0.81      0.82      8241\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.74      0.75      0.74     25000\n",
      "weighted avg       0.82      0.81      0.82     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.86      0.92      0.89     15320\n",
      "     UNHAPPY       0.87      0.43      0.57      2913\n",
      "     UNKNOWN       0.78      0.84      0.81      6767\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.73      0.76     25000\n",
      "weighted avg       0.84      0.84      0.83     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.87      0.90      0.89     14006\n",
      "     UNHAPPY       0.85      0.41      0.55      2841\n",
      "     UNKNOWN       0.80      0.90      0.85      8153\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.84      0.74      0.76     25000\n",
      "weighted avg       0.85      0.85      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Bernoulli 1 day\n",
    "(X, y) = dataX(df,5)\n",
    "(accuracy,class_report) = classifyLabels(BernoulliNB(), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "balanced-generation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.588248, 2: 0.689048, 3: 0.675984}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.61      0.68     68195\n",
      "     UNHAPPY       0.15      0.29      0.20     15437\n",
      "     UNKNOWN       0.66      0.66      0.66     41368\n",
      "\n",
      "    accuracy                           0.59    125000\n",
      "   macro avg       0.53      0.52      0.51    125000\n",
      "weighted avg       0.66      0.59      0.62    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.69      0.94      0.80     75861\n",
      "     UNHAPPY       0.00      0.00      0.00     14564\n",
      "     UNKNOWN       0.67      0.44      0.53     34575\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.45      0.46      0.44    125000\n",
      "weighted avg       0.61      0.69      0.63    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.66      0.94      0.78     70405\n",
      "     UNHAPPY       0.00      0.00      0.00     14378\n",
      "     UNKNOWN       0.72      0.46      0.56     40217\n",
      "\n",
      "    accuracy                           0.68    125000\n",
      "   macro avg       0.46      0.47      0.45    125000\n",
      "weighted avg       0.61      0.68      0.62    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Bernoulli\n",
    "(accuracy,class_report) = classifyLabels(BernoulliNB(), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "separated-blond",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.648288, 2: 0.646056, 3: 0.644936}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.68      0.84      0.75     68195\n",
      "     UNHAPPY       0.18      0.08      0.11     15437\n",
      "     UNKNOWN       0.67      0.55      0.61     41368\n",
      "\n",
      "    accuracy                           0.65    125000\n",
      "   macro avg       0.51      0.49      0.49    125000\n",
      "weighted avg       0.62      0.65      0.62    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.71      0.83      0.76     75861\n",
      "     UNHAPPY       0.18      0.10      0.13     14564\n",
      "     UNKNOWN       0.59      0.48      0.53     34575\n",
      "\n",
      "    accuracy                           0.65    125000\n",
      "   macro avg       0.49      0.47      0.47    125000\n",
      "weighted avg       0.61      0.65      0.62    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.72      0.78      0.75     70405\n",
      "     UNHAPPY       0.16      0.10      0.12     14378\n",
      "     UNKNOWN       0.62      0.60      0.61     40217\n",
      "\n",
      "    accuracy                           0.64    125000\n",
      "   macro avg       0.50      0.49      0.49    125000\n",
      "weighted avg       0.62      0.64      0.63    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussian\n",
    "(accuracy,class_report) = classifyLabels(GaussianNB(), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "incomplete-apollo",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.776368, 2: 0.757728, 3: 0.762664}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.84      0.83      0.83     83632\n",
      "     UNKNOWN       0.66      0.68      0.67     41368\n",
      "\n",
      "    accuracy                           0.78    125000\n",
      "   macro avg       0.75      0.75      0.75    125000\n",
      "weighted avg       0.78      0.78      0.78    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.83      0.83      0.83     90425\n",
      "     UNKNOWN       0.56      0.56      0.56     34575\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.70      0.70      0.70    125000\n",
      "weighted avg       0.76      0.76      0.76    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.81      0.84      0.83     84783\n",
      "     UNKNOWN       0.64      0.59      0.62     40217\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.73      0.72      0.72    125000\n",
      "weighted avg       0.76      0.76      0.76    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-NN\n",
    "(accuracy,class_report) = classifyLabels(neighbors.KNeighborsClassifier(n_neighbors = 3), X, y, n = 3, scale = 'MinMax')\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "trained-electric",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.678176, 2: 0.685968, 3: 0.7108}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.75      0.76     68195\n",
      "     UNHAPPY       0.20      0.03      0.05     15437\n",
      "     UNKNOWN       0.59      0.80      0.68     41368\n",
      "\n",
      "    accuracy                           0.68    125000\n",
      "   macro avg       0.52      0.53      0.50    125000\n",
      "weighted avg       0.64      0.68      0.65    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.83      0.79     75861\n",
      "     UNHAPPY       0.21      0.05      0.08     14564\n",
      "     UNKNOWN       0.58      0.64      0.61     34575\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.52      0.51      0.49    125000\n",
      "weighted avg       0.64      0.69      0.66    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.81      0.79     70405\n",
      "     UNHAPPY       0.21      0.03      0.05     14378\n",
      "     UNKNOWN       0.64      0.79      0.71     40217\n",
      "\n",
      "    accuracy                           0.71    125000\n",
      "   macro avg       0.54      0.54      0.52    125000\n",
      "weighted avg       0.66      0.71      0.68    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "(accuracy,class_report) = classifyLabels(LogisticRegression(random_state=0,\n",
    "                                                            class_weight='balanced',\n",
    "                                                            fit_intercept=False,\n",
    "                                                            solver='liblinear'), X, y, n = 3, scale = 'MinMax')\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (very slow!)\n",
    "(accuracy,class_report) = classifyLabels(svm.SVC(random_state=0,\n",
    "                                                 class_weight='balanced'), X, y, n = 3, scale = 'MinMax')\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "behavioral-customs",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:635: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.9 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "{1: 0.603464, 2: 0.587064, 3: 0.603976}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.67      0.70     68195\n",
      "     UNHAPPY       0.14      0.18      0.16     15437\n",
      "     UNKNOWN       0.63      0.64      0.64     41368\n",
      "\n",
      "    accuracy                           0.60    125000\n",
      "   macro avg       0.50      0.50      0.50    125000\n",
      "weighted avg       0.63      0.60      0.61    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.66      0.70     75861\n",
      "     UNHAPPY       0.13      0.16      0.14     14564\n",
      "     UNKNOWN       0.52      0.61      0.56     34575\n",
      "\n",
      "    accuracy                           0.59    125000\n",
      "   macro avg       0.47      0.48      0.47    125000\n",
      "weighted avg       0.62      0.59      0.60    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.72      0.69      0.71     70405\n",
      "     UNHAPPY       0.13      0.18      0.15     14378\n",
      "     UNKNOWN       0.64      0.60      0.62     40217\n",
      "\n",
      "    accuracy                           0.60    125000\n",
      "   macro avg       0.50      0.49      0.49    125000\n",
      "weighted avg       0.63      0.60      0.62    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "(accuracy,class_report) = classifyLabels(DecisionTreeClassifier(random_state=0,\n",
    "                                                                class_weight='balanced'), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "furnished-river",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.73088, 2: 0.740224, 3: 0.751032}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.87      0.81     68195\n",
      "     UNHAPPY       0.15      0.02      0.03     15437\n",
      "     UNKNOWN       0.71      0.77      0.74     41368\n",
      "\n",
      "    accuracy                           0.73    125000\n",
      "   macro avg       0.54      0.55      0.52    125000\n",
      "weighted avg       0.66      0.73      0.69    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.76      0.90      0.83     75861\n",
      "     UNHAPPY       0.25      0.01      0.01     14564\n",
      "     UNKNOWN       0.69      0.70      0.69     34575\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.57      0.54      0.51    125000\n",
      "weighted avg       0.68      0.74      0.69    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.93      0.83     70405\n",
      "     UNHAPPY       0.30      0.01      0.02     14378\n",
      "     UNKNOWN       0.77      0.71      0.74     40217\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.61      0.55      0.53    125000\n",
      "weighted avg       0.70      0.75      0.70    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "(accuracy,class_report) = classifyLabels(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
    "                                                            n_estimators=50,\n",
    "                                                            random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cleared-serum",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.747288, 2: 0.75016, 3: 0.74272}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.92      0.82     68195\n",
      "     UNHAPPY       0.23      0.00      0.00     15437\n",
      "     UNKNOWN       0.75      0.75      0.75     41368\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.58      0.55      0.52    125000\n",
      "weighted avg       0.68      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.76      0.93      0.83     75861\n",
      "     UNHAPPY       0.45      0.00      0.00     14564\n",
      "     UNKNOWN       0.72      0.68      0.70     34575\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.65      0.54      0.51    125000\n",
      "weighted avg       0.71      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.73      0.94      0.82     70405\n",
      "     UNHAPPY       0.32      0.00      0.00     14378\n",
      "     UNKNOWN       0.78      0.66      0.72     40217\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.61      0.54      0.51    125000\n",
      "weighted avg       0.70      0.74      0.69    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "(accuracy,class_report) = classifyLabels(GradientBoostingClassifier(random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "moving-stake",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.75276, 2: 0.751056, 3: 0.757056}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.92      0.83     68195\n",
      "     UNHAPPY       0.25      0.00      0.01     15437\n",
      "     UNKNOWN       0.75      0.76      0.76     41368\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.59      0.56      0.53    125000\n",
      "weighted avg       0.69      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.92      0.83     75861\n",
      "     UNHAPPY       0.22      0.00      0.00     14564\n",
      "     UNKNOWN       0.71      0.71      0.71     34575\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.56      0.54      0.52    125000\n",
      "weighted avg       0.69      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.94      0.83     70405\n",
      "     UNHAPPY       0.26      0.00      0.00     14378\n",
      "     UNKNOWN       0.79      0.71      0.75     40217\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.60      0.55      0.53    125000\n",
      "weighted avg       0.70      0.76      0.71    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hist Gradient Boosting\n",
    "(accuracy,class_report) = classifyLabels(HistGradientBoostingClassifier(random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "differential-technology",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.704248, 2: 0.691872, 3: 0.691832}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.84      0.79     68195\n",
      "     UNHAPPY       0.15      0.05      0.07     15437\n",
      "     UNKNOWN       0.70      0.72      0.71     41368\n",
      "\n",
      "    accuracy                           0.70    125000\n",
      "   macro avg       0.53      0.54      0.52    125000\n",
      "weighted avg       0.66      0.70      0.67    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.76      0.82      0.79     75861\n",
      "     UNHAPPY       0.16      0.06      0.09     14564\n",
      "     UNKNOWN       0.62      0.68      0.65     34575\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.51      0.52      0.51    125000\n",
      "weighted avg       0.65      0.69      0.67    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.82      0.78     70405\n",
      "     UNHAPPY       0.14      0.07      0.10     14378\n",
      "     UNKNOWN       0.70      0.68      0.69     40217\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.53      0.53      0.52    125000\n",
      "weighted avg       0.66      0.69      0.67    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "(accuracy,class_report) = classifyLabels(BaggingClassifier(n_estimators=10,\n",
    "                                                           random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "continuous-saturn",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.741472, 2: 0.743208, 3: 0.752912}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.90      0.82     68195\n",
      "     UNHAPPY       0.18      0.03      0.05     15437\n",
      "     UNKNOWN       0.75      0.74      0.75     41368\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.56      0.56      0.54    125000\n",
      "weighted avg       0.68      0.74      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.91      0.83     75861\n",
      "     UNHAPPY       0.17      0.03      0.05     14564\n",
      "     UNKNOWN       0.72      0.69      0.70     34575\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.55      0.54      0.53    125000\n",
      "weighted avg       0.68      0.74      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.93      0.83     70405\n",
      "     UNHAPPY       0.18      0.03      0.05     14378\n",
      "     UNKNOWN       0.79      0.71      0.75     40217\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.57      0.55      0.54    125000\n",
      "weighted avg       0.70      0.75      0.71    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "(accuracy,class_report) = classifyLabels(RandomForestClassifier(n_estimators=10,\n",
    "                                                                random_state=0,\n",
    "                                                                class_weight='balanced'), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
