{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "from dynamic_input_data import *\n",
    "import importlib\n",
    "importlib.reload(dynamic_input_data)\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseData():\n",
    "    \n",
    "    # Read in cleaned and prepared data file (.csv) that is created in the data_cleaning_preparation code\n",
    "    df = pd.read_csv('path...', low_memory = True)\n",
    "    \n",
    "    df['orderDate']                   = pd.to_datetime(df['orderDate'])\n",
    "    df['cancellationDate']            = pd.to_datetime(df['cancellationDate'])\n",
    "    df['promisedDeliveryDate']        = pd.to_datetime(df['promisedDeliveryDate'])\n",
    "    df['shipmentDate']                = pd.to_datetime(df['shipmentDate'])\n",
    "    df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'])\n",
    "    df['startDateCase']               = pd.to_datetime(df['startDateCase'])\n",
    "    df['returnDateTime']              = pd.to_datetime(df['returnDateTime'])\n",
    "    df['registrationDateSeller']      = pd.to_datetime(df['registrationDateSeller'])\n",
    "\n",
    "    # Fixed Columns:\n",
    "    DATE = ['orderDate']\n",
    "    BASIC = ['totalPrice','quantityOrdered','fulfilmentByPlatform','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "            'countryOriginDE','productTitleLength','promisedDeliveryDays','partnerSellingDays', 'orderCorona']\n",
    "    WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "    MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "             'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "    YEAR = ['orderYear2020']\n",
    "    GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "             'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "    # Dynamic Columns:\n",
    "    TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "    KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "    PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "    SELLERX = ['sellerDailyOrdersX']\n",
    "    HISTORICX = []\n",
    "    historic_variable = ['transporterCode','sellerId','productGroup']\n",
    "    for x in range(len(historic_variable)):\n",
    "        HISTORICX = HISTORICX + [historic_variable[x]+'HistoricHappyX',historic_variable[x]+'HistoricUnhappyX',historic_variable[x]+'HistoricUnknownX']\n",
    "\n",
    "    # Determinants:\n",
    "    DETERMINANT = ['noReturn', 'noCase', 'noCancellation', 'onTimeDelivery']\n",
    "\n",
    "    # Classifications\n",
    "    CLASSIFICATION = ['generalMatchClassification','detailedMatchClassification','binaryMatchClassification','determinantClassification']\n",
    "\n",
    "    X_col = BASIC + WEEK + MONTH + YEAR + GROUP + TRANSPORTERX + KNOWNX + PRODUCTX + SELLERX + HISTORICX\n",
    "    Y_col = ['detailedMatchClassification']\n",
    "    \n",
    "    return df, X_col, Y_col, DATE, historic_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise data\n",
    "df, X_col, Y_col, DATE, historic_variable = initialiseData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Validation (Flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill dataframe df_ with a subsample of training + validation data containing 1.1M observations\n",
    "random.seed(100)\n",
    "df_ = df.iloc[:int(0.8*len(df))].sample(n=1100000, replace=False, random_state=1).sort_values(by = 'orderDate').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_get_hyperspace(combination):\n",
    "    \n",
    "    param_hyperopt = {}\n",
    "\n",
    "    if combination == 'DT':\n",
    "        hyper = {'DT_criterion'   : hp.choice('DT_criterion',['gini','entropy']),\n",
    "                 'DT_max_depth'   : scope.int(hp.quniform('DT_max_depth', 5, 15, 1))}\n",
    "    elif combination == 'RF':\n",
    "        hyper = {'RF_max_depth'    : scope.int(hp.quniform('RF_max_depth', 5, 15, 1)),\n",
    "                 'RF_n_estimators' : scope.int(hp.quniform('RF_n_estimators', 10, 50, 5))}\n",
    "    elif combination == 'NN':\n",
    "        hyper = {'NN_dropout'  : hp.uniform('NN_dropout', 0, 0.5),\n",
    "                 'NN_nodes'    : scope.int(hp.quniform('NN_nodes', 5, 50, 5)),\n",
    "                 'NN_layers'   : scope.int(hp.quniform('NN_layers', 1, 2, 1))}\n",
    "    elif combination == 'LR':\n",
    "        hyper = {'LR_penalty' : hp.choice('LR_penalty', ['l1','l2'])}\n",
    "\n",
    "    param_hyperopt = {**param_hyperopt, **hyper}\n",
    "        \n",
    "    return param_hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_objective_function(params):\n",
    "    \n",
    "    if combination == 'RF':\n",
    "        clf = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = params['RF_max_depth'], n_estimators = params['RF_n_estimators'])\n",
    "    elif combination == 'LR':\n",
    "        print(params)\n",
    "        clf = LogisticRegression(penalty = params['LR_penalty'], class_weight = 'balanced', solver = 'liblinear')\n",
    "    \n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_val)\n",
    "    \n",
    "    precision, recall, f1, support = metrics.precision_recall_fscore_support(y_val, pred, average = 'weighted', beta = 1)\n",
    "    accuracy = metrics.accuracy_score(y_val, pred)\n",
    "    #cross validation score to be implemented?\n",
    "    \n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_hyperopt(param_space, X_train, y_train, X_val, y_val, num_eval):\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    best_param = fmin(flat_objective_function, \n",
    "                      param_space, \n",
    "                      algo = tpe.suggest, \n",
    "                      max_evals = num_eval, \n",
    "                      trials = trials,\n",
    "                      rstate = np.random.RandomState(1))\n",
    "    \n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    index_min_loss = loss.index(min(loss))\n",
    "    accuracy_scores = [x['result']['accuracy'] for x in trials.trials]\n",
    "    \n",
    "    f1 = min(loss)*-1\n",
    "    accuracy = accuracy_scores[index_min_loss]\n",
    "    \n",
    "    return best_param, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start day as date of ordering (begin = 0) and end day as the 10-th day after the order date (end = 10)\n",
    "begin, end = 0, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise output\n",
    "output = {}\n",
    "\n",
    "# All combinations between RF and LR in the flat case\n",
    "combinations = ['RF','LR']\n",
    "\n",
    "# For all days\n",
    "for DAY in range(begin,end+1):\n",
    "    \n",
    "    # Create X and Y \n",
    "    X_preBurn, y_preBurn = dataX(df_, DATE, X_col, Y_col, historic_variable, DAY)\n",
    "    index = range(0, X_preBurn.shape[0])\n",
    "    \n",
    "    # Burn in first 10% of observations\n",
    "    X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "    y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "    # Make 80-20 train-validation split\n",
    "    X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "    X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "\n",
    "    y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "    y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "    \n",
    "    output[DAY] = {}\n",
    "\n",
    "    for combination in combinations:\n",
    "        \n",
    "        if combination == 'RF':\n",
    "            n_trials = 20\n",
    "        elif combination == 'LR':\n",
    "            n_trials = 2 # No more than 2 trials needed to try all hyperparameter combinations (we only tune on either L1- or L2-penalty)\n",
    "\n",
    "        # Optimise\n",
    "        best_param, f1, accuracy = flat_hyperopt(flat_get_hyperspace(combination), X_train, y_train, X_val, y_val, n_trials)\n",
    "\n",
    "        # Save output for day and combination\n",
    "        output[DAY][str(combination)] = (DAY, best_param, f1, accuracy)\n",
    "        print(output)\n",
    "        \n",
    "        # Write a path and file name (with .json format) to write the output to\n",
    "        with open('path...', 'w') as f:\n",
    "            json.dump(output, f, cls = NumpyEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Validation (HCOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill dataframe df_ with a subsample of training + validation data containing 1.1M observations\n",
    "random.seed(100)\n",
    "df_ = df.iloc[:int(0.8*len(df))].sample(n=1100000, replace=False, random_state=1).sort_values(by = 'orderDate').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hierarchical structure\n",
    "Tree = ClassHierarchy('ORDERS')\n",
    "Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "## All combinations for RF and LR\n",
    "combinations = [('LR','LR','LR'),('LR','LR','RF'),('LR','RF','LR'),('LR','RF','RF'),\n",
    "                ('RF','LR','LR'),('RF','LR','RF'),('RF','RF','LR'),('RF','RF','RF')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise\n",
    "output = {}\n",
    "START = 0\n",
    "END = 10\n",
    "\n",
    "for DAY in range(START,END+1):\n",
    "    \n",
    "    # Create X and Y \n",
    "    X_preBurn, y_preBurn = dataX(df_, DATE, X_col, Y_col, historic_variable, DAY)\n",
    "    index = range(0, X_preBurn.shape[0])\n",
    "    \n",
    "    # Burn in first 10% of observations\n",
    "    X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "    y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "    # Make 80-20 train-validation split\n",
    "    X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "    X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "\n",
    "    y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "    y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "\n",
    "    output[DAY] = {}\n",
    "\n",
    "    for combination in combinations:\n",
    "\n",
    "        # Optimise\n",
    "        best_param, f1, accuracy = hyperopt(get_hyperspace(combination), X_train, y_train, X_val, y_val, 20)\n",
    "\n",
    "        # Save output per combination per day\n",
    "        output[DAY][str(combination)] = (DAY, best_param, f1, accuracy)\n",
    "\n",
    "        # Write a path and file name (with .json format) to write the output to\n",
    "        with open('path...', 'w') as f:\n",
    "            json.dump(output, f, cls = NumpyEncoder)\n",
    "    \n",
    "    print(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperspace(combination):\n",
    "    \n",
    "    param_hyperopt = {}\n",
    "    \n",
    "    for node, clf in enumerate(combination):\n",
    "        \n",
    "        if clf == 'DT':\n",
    "            hyper = {'DT_criterion_'+str(node)   : hp.choice('DT_criterion_'+str(node) ,['gini','entropy']),\n",
    "                     'DT_max_depth_'+str(node)   : scope.int(hp.quniform('DT_max_depth_'+str(node), 5, 15, 1))}\n",
    "        elif clf == 'RF':\n",
    "            hyper = {'RF_max_depth_'   +str(node) : scope.int(hp.quniform('RF_max_depth_'+str(node), 5, 15, 1)),\n",
    "                     'RF_n_estimators_'+str(node) : scope.int(hp.quniform('RF_n_estimators_'+str(node), 10, 50, 5))}\n",
    "        elif clf == 'NN':\n",
    "            hyper = {'NN_dropout_'+str(node)  : hp.uniform('NN_dropout_'+str(node), 0, 0.5),\n",
    "                     'NN_nodes_'  +str(node)  : scope.int(hp.quniform('NN_nodes_'+str(node), 5, 50, 5)),\n",
    "                     'NN_layers_' +str(node)  : scope.int(hp.quniform('NN_layers_'+str(node), 1, 2, 1))}\n",
    "        elif clf == 'LR':\n",
    "            hyper = {'LR_penalty_' + str(node) : hp.choice('LR_penalty_' + str(node), ['l1','l2'])}\n",
    "            \n",
    "        param_hyperopt = {**param_hyperopt, **hyper}\n",
    "        \n",
    "    return param_hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_hypers(params):\n",
    "\n",
    "    clf = {}\n",
    "    \n",
    "    for ix, node in enumerate(['ORDERS','KNOWN','UNHAPPY']):\n",
    "\n",
    "        node_hypers = [x for x in list(params.keys()) if x[-1] == str(ix)]\n",
    "\n",
    "        if combination[ix] == 'DT':\n",
    "            clf[node] = DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = params[node_hypers[1]], criterion = params[node_hypers[0]])\n",
    "        elif combination[ix] == 'RF':\n",
    "            clf[node] = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = params[node_hypers[0]], n_estimators = params[node_hypers[1]])\n",
    "        elif combination[ix] == 'NN':\n",
    "            if ix == 2:\n",
    "                output = 3\n",
    "            else:\n",
    "                output = 1\n",
    "            clf[node] = KerasClassifier(functions.neuralNetwork, output = output, nodes = params[node_hypers[1]], layers = params[node_hypers[2]], droprate = params[node_hypers[0]], epochs = 15, verbose = 0)\n",
    "        elif combination[ix] == 'LR':\n",
    "            clf[node] = LogisticRegression(penalty = params[node_hypers[0]], class_weight = 'balanced', solver = 'liblinear')\n",
    "            \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    \n",
    "    HC = HierarchicalClassifier(Tree)\n",
    "    HC.fit_classifiers(clf_hypers(params))\n",
    "    \n",
    "    HC = HC.fit(X_train,y_train)\n",
    "    pred = HC.predict(X_val)\n",
    "    \n",
    "    score = f1_score_ancestors(Tree, y_val['detailedMatchClassification'], pred, beta=1)\n",
    "    accuracy = metrics.accuracy_score(y_val, pred)\n",
    "    # cross-validation score to be implemented\n",
    "    \n",
    "    return {'loss': -score, 'status': STATUS_OK, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X_train, y_train, X_val, y_val, num_eval):\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    best_param = fmin(objective_function, \n",
    "                      param_space, \n",
    "                      algo = tpe.suggest, \n",
    "                      max_evals = num_eval, \n",
    "                      trials = trials,\n",
    "                      rstate = np.random.RandomState(1))\n",
    "    \n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    index_min_loss = loss.index(min(loss))\n",
    "    accuracy_scores = [x['result']['accuracy'] for x in trials.trials]\n",
    "    \n",
    "    f1 = min(loss)*-1\n",
    "    accuracy = accuracy_scores[index_min_loss]\n",
    "    \n",
    "    return best_param, f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### CAT-HCOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicHierarchicalClassifier(START, END, threshold = None, threshold_type = None):  \n",
    "  \n",
    "    # Create hierarchy\n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "    \n",
    "    # Optimal hypers obtained via validation\n",
    "    hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "                           '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "                           '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "                           '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "    \n",
    "    # Certainty parameter alpha\n",
    "    CERTAINTY = 0.7\n",
    "    OPTION = 2\n",
    "    \n",
    "    statistics, previous_pred_block, feature_importances = None, None, None\n",
    "\n",
    "    for DAYS in range(START, END+1):\n",
    "        \n",
    "        # Create X and Y\n",
    "        X, y = dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "        # Make 80-20 train-test split and burn in first 10% of train set\n",
    "        X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "        y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "        X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "        y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "        X_test = X.iloc[int(0.8*len(X)):]\n",
    "        y_test = y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "        N_test = len(y_test)\n",
    "    \n",
    "        # Fit classifiers at parent nodes in hierarchy\n",
    "        HC = HierarchicalClassifier(Tree)\n",
    "        HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "                            'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "                            'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "\n",
    "        HC = HC.fit(X_train,y_train)\n",
    "\n",
    "        y_train_hat = HC.get_probabilities(X_train, y_train)\n",
    "        probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "\n",
    "        # Find thresholds\n",
    "        THRESHOLDS = {}\n",
    "        for node in range(1,8):\n",
    "            name, threshold = opt_threshold(probs, node, DAYS, CERTAINTY, option = 2)\n",
    "            THRESHOLDS[name] = threshold\n",
    "\n",
    "        if DAYS == START: # create dataframe to save predictions\n",
    "            y_hat = pd.DataFrame([Tree.root] * len(X_test),\n",
    "                                    columns=[DAYS],\n",
    "                                    index=X_test.index)\n",
    "            index_no_leaf = X_test.index\n",
    "        else:\n",
    "            y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "        if DAYS < END:\n",
    "            pred = HC.predict_proba2(X_test.loc[index_no_leaf], THRESHOLDS = THRESHOLDS)\n",
    "\n",
    "            check_no_leaf = ~pred.isin(Tree._get_leaf_nodes())\n",
    "            index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "            check_leaf    = pred.isin(Tree._get_leaf_nodes())      # from current non_leaf predictions which are now leaf\n",
    "            index_leaf    = check_leaf[check_leaf].index\n",
    "            y_hat_stage   = pd.DataFrame(pred, index = index_leaf)\n",
    "        else:\n",
    "            pred        = HC.predict(X_test.loc[index_no_leaf]) # last day you want a label for each order\n",
    "            y_hat_stage = pd.DataFrame(pred, index = index_no_leaf)\n",
    "            index_leaf  = index_no_leaf\n",
    "\n",
    "        y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "        y_hat.stage_col = y_hat.stage_col.fillna(y_hat[DAYS]) #  fill previously predicted labels\n",
    "        y_hat = y_hat.drop(DAYS, axis=1)\n",
    "        y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "\n",
    "        current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "        # Save performance metrics\n",
    "        statistics, feature_importances, previous_pred_block = get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, \n",
    "                                                                               previous_pred_block, THRESHOLDS, OPTION, CERTAINTY, y_test, Tree, HC, feature_importances, statistics)\n",
    "\n",
    "        # Write a path and file name (with .json format) to write the output to\n",
    "        file_name = 'statistics_optimal_'+str(OPTION)+'_'+str(CERTAINTY)+'.json'\n",
    "        path_name = 'path...' + file_name\n",
    "        with open(path_name, 'w') as f:\n",
    "            json.dump(statistics, f, cls = NumpyEncoder)\n",
    "\n",
    "        print('DAYS: ',DAYS)\n",
    "     \n",
    "    final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "    return final_pred, statistics, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CAT-HCOT \n",
    "pred, statistics, feature_importances = dynamicHierarchicalClassifier(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Base Case 1 (Static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staticHierarchicalClassifier(START, END):\n",
    "    \n",
    "    # Create hierarchy\n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "    \n",
    "    # Optimal hypers obtained via validation\n",
    "    hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "                           '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "                           '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "                           '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "    \n",
    "    statistics = {'accuracy':{},\n",
    "                  'precision':{},\n",
    "                  'recall':{},\n",
    "                  'f1':{}}\n",
    "    for leaf in Tree._get_leaf_nodes(): \n",
    "        statistics['precision_'+leaf] = {}\n",
    "        statistics['recall_'+leaf]    = {}\n",
    "        statistics['f1_'+leaf]        = {}\n",
    "    \n",
    "    for DAYS in range(START, END+1):\n",
    "\n",
    "        # Create X and Y\n",
    "        X, y = dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "        # Make 80-20 train-test split and burn in first 10% of train set\n",
    "        X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "        y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "        X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "        y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "        X_test = X.iloc[int(0.8*len(X)):]\n",
    "        y_test = y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "        # Fit classifiers at parent nodes in hierarchy\n",
    "        HC = HierarchicalClassifier(Tree)\n",
    "        HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "                            'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "                            'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "\n",
    "        HC = HC.fit(X_train,y_train)\n",
    "        pred = HC.predict(X_test)\n",
    "        \n",
    "        y_test = y_test['detailedMatchClassification']\n",
    "        \n",
    "        # Compute performance metrics\n",
    "        statistics['accuracy'][DAYS] = metrics.accuracy_score(y_test, pred)\n",
    "        statistics['precision'][DAYS] = precision_score_ancestors(Tree, y_test, pred)\n",
    "        statistics['recall'][DAYS] = recall_score_ancestors(Tree, y_test, pred)\n",
    "        statistics['f1'][DAYS] = f1_score_ancestors(Tree, y_test, pred, beta = 1)\n",
    "        \n",
    "        for leaf in Tree._get_leaf_nodes():\n",
    "            leaf_ix = pred.loc[pred == leaf].index\n",
    "            statistics['precision_'+leaf][DAYS] = precision_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "            statistics['recall_'+leaf][DAYS]    = recall_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "            statistics['f1_'+leaf][DAYS]        = f1_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix], beta = 1)\n",
    "            \n",
    "        print('DAY ',DAYS)\n",
    "            \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run static HCOT baseline\n",
    "stats = staticHierarchicalClassifier(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Base Case 2 (Flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicFlatClassifier(START, END):  \n",
    "\n",
    "    # Optimal hyperparameters obtained via flat validation\n",
    "    hypers = pd.DataFrame({'LR_penalty'     : ['l1','l1','l1','l1','l1','l1','l2','l1','l1','l1','l1'],\n",
    "                           'RF_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           'RF_n_estimators': [45,45,40,45,40,45,40,45,45,45,45]})\n",
    "    \n",
    "    # Create hierarchy\n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "    # Set certainty parameter alpha\n",
    "    certainties = [0.7]\n",
    "    \n",
    "    statistics = {'accuracy'  :{},\n",
    "                  'classified':{},\n",
    "                  'thresholds':{},\n",
    "                  'precision' :{},\n",
    "                  'recall'    :{},\n",
    "                  'f1'        :{}}\n",
    "    for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']: \n",
    "        statistics['precision_'+leaf] = {}\n",
    "        statistics['recall_'+leaf]    = {}\n",
    "        statistics['f1_'+leaf]        = {}\n",
    "    for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']: \n",
    "        statistics['2precision_'+leaf] = {}\n",
    "        statistics['2recall_'+leaf]    = {}\n",
    "        statistics['2f1_'+leaf]        = {}\n",
    "    \n",
    "    for CERTAINTY in certainties:  \n",
    "        for DAYS in range(START, END+1):\n",
    "\n",
    "            # Create X and Y\n",
    "            X, y = dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "            # Make 80-20 train-test split and burn in first 10% of train set\n",
    "            X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "            y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "            X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "            y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "            X_test = X.iloc[int(0.8*len(X)):]\n",
    "            y_test = y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "            # Fit classifiers\n",
    "            if DAYS < 5:\n",
    "                clf = LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, 'LR_penalty'])\n",
    "            else:\n",
    "                clf = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, 'RF_max_depth'], n_estimators = hypers.loc[DAYS, 'RF_n_estimators'])\n",
    "                \n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_train_hat = clf.predict_proba(X_train) \n",
    "            y_classes = clf.classes_\n",
    "            y_train_hat = pd.DataFrame(y_train_hat, index = X_train.index, columns = y_classes)\n",
    "            probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "            \n",
    "            # Compute thresholds\n",
    "            THRESHOLDS = {}\n",
    "            for node in range(1,6):\n",
    "                name, threshold = flat_thresholds(probs, node, DAYS, CERTAINTY, steps = 100)\n",
    "                THRESHOLDS[name] = threshold\n",
    "\n",
    "            if DAYS == START: # create dataframe to save predictions\n",
    "                y_hat = pd.DataFrame(['ORDERS'] * len(X_test),\n",
    "                                        columns=[DAYS],\n",
    "                                        index=X_test.index)\n",
    "                index_no_leaf = X_test.index\n",
    "            else:\n",
    "                y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "            if DAYS < END:\n",
    "                X_test_ = X_test.loc[index_no_leaf]\n",
    "                y_proba = clf.predict_proba(X_test_)\n",
    "                y_classes = clf.classes_\n",
    "            \n",
    "                max_prob = np.amax(y_proba, axis=1)              # max probability of classes\n",
    "                max_class = np.argmax(y_proba, axis=1)           # class number with max probability\n",
    "                max_class_thresholds = np.vectorize(lambda x: THRESHOLDS[y_classes[x]])(max_class)  # get node-specific threshold\n",
    "\n",
    "                accept_index = np.where(max_prob >= max_class_thresholds)[0]\n",
    "                accept_class = np.take(max_class, accept_index)  # filtered list of orders which are above threshold\n",
    "\n",
    "                if len(accept_class) > 0: # check if samples reach threshold\n",
    "                    accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                              # convert class number into label\n",
    "                    y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test_.index.values, accept_index))  # set labels to correct position\n",
    "                else:\n",
    "                    y_hat_stage = pd.DataFrame(columns = [0], index = X_test_.index)\n",
    "                    \n",
    "                index_leaf = y_hat_stage.index\n",
    "\n",
    "            else:\n",
    "                pred        = clf.predict(X_test.loc[index_no_leaf]) # last day you want a label for each order\n",
    "                y_hat_stage = pd.DataFrame(pred, index = index_no_leaf)\n",
    "                index_leaf  = index_no_leaf\n",
    "\n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[DAYS]) # fill previously predicted labels\n",
    "            y_hat = y_hat.drop(DAYS, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "\n",
    "            current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "            check_no_leaf = (current_pred == 'ORDERS')    # from current non_leaf predictions which are now leaf\n",
    "            index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "            \n",
    "            # Compute performance metrics\n",
    "            statistics['accuracy'][DAYS]   = metrics.accuracy_score(y_test.loc[index_leaf], current_pred.loc[index_leaf])\n",
    "            statistics['classified'][DAYS] = (current_pred != 'ORDERS').sum() / len(y_test)\n",
    "            statistics['thresholds'][DAYS] = THRESHOLDS\n",
    "            \n",
    "            precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test.loc[index_leaf], current_pred.loc[index_leaf], average = 'weighted', beta = 1)\n",
    "            \n",
    "            statistics['precision'][DAYS] = precision\n",
    "            statistics['recall'][DAYS]    = recall\n",
    "            statistics['f1'][DAYS]        = f1\n",
    "            \n",
    "            precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test.loc[index_leaf], current_pred.loc[index_leaf], average = None, labels = ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'])\n",
    "            \n",
    "            for ix,leaf in enumerate(['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']):\n",
    "                statistics['precision_'+leaf][DAYS] = precision[ix]\n",
    "                statistics['recall_'+leaf][DAYS]    = recall[ix]\n",
    "                statistics['f1_'+leaf][DAYS]        = f1[ix]\n",
    "                \n",
    "            for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']:\n",
    "                leaf_ix = current_pred.loc[current_pred == leaf].index\n",
    "                statistics['2precision_'+leaf][DAYS] = precision_score_ancestors(Tree, y_test['detailedMatchClassification'].loc[leaf_ix], current_pred.loc[leaf_ix])\n",
    "                statistics['2recall_'+leaf][DAYS]    = recall_score_ancestors(Tree, y_test['detailedMatchClassification'].loc[leaf_ix], current_pred.loc[leaf_ix])\n",
    "                statistics['2f1_'+leaf][DAYS]        = f1_score_ancestors(Tree, y_test['detailedMatchClassification'].loc[leaf_ix], current_pred.loc[leaf_ix], beta = 1)\n",
    "            \n",
    "            # Write a path and file name (with .json format) to write the output to\n",
    "            file_name = 'flat_statistics_'+str(CERTAINTY)+'.json'\n",
    "            path_name = 'path...' + file_name\n",
    "            with open(path_name, 'w') as f:\n",
    "                json.dump(statistics, f, cls = NumpyEncoder)\n",
    "\n",
    "            print('DAYS: ',DAYS)\n",
    "     \n",
    "        final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        accuracy = metrics.accuracy_score(y_test, final_pred)\n",
    "        precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test, final_pred, average = None, labels = ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], beta = 1)\n",
    "        print(accuracy)\n",
    "        print(precision)\n",
    "        print(recall)\n",
    "        print(precision_score_ancestors(Tree, y_test['detailedMatchClassification'], final_pred))\n",
    "        print(recall_score_ancestors(Tree, y_test['detailedMatchClassification'], final_pred))\n",
    "        for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']:\n",
    "            leaf_ix = final_pred.loc[final_pred == leaf].index\n",
    "            print(leaf,precision_score_ancestors(Tree, y_test['detailedMatchClassification'].loc[leaf_ix], final_pred.loc[leaf_ix]),\n",
    "                  recall_score_ancestors(Tree, y_test['detailedMatchClassification'].loc[leaf_ix], final_pred.loc[leaf_ix]))\n",
    "        \n",
    "    return final_pred, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run flat CAT-HCOT baseline\n",
    "pred, stats = dynamicFlatClassifier(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, previous_pred_block, THRESHOLDS, OPTION, CERTAINTY, y_test, Tree, HC, feature_importances, statistics):\n",
    "    \n",
    "    # Initialize Dictionary at Day 0\n",
    "    \n",
    "    if DAYS == 0:\n",
    "        statistics = {'%classified'     :{}, 'N_classified'         :{},  'N_predicted' : {},\n",
    "                      'leaf_accuracy'   :{}, 'total_leaf_accuracy'  :{},\n",
    "                      'leaf_precision'  :{}, 'total_leaf_precision' :{},\n",
    "                      'leaf_recall'     :{}, 'total_leaf_recall'    :{},\n",
    "                      'label_precision' :{}, \n",
    "                      'label_recall'    :{}, \n",
    "                      'block_precision' :{},\n",
    "                      'block_recall'    :{},\n",
    "                      'block_Nchange'   :{}, 'block_Pchange'        :{},\n",
    "                      '%blocking'       :{}, '%Tblocking'           :{},\n",
    "                      'tree_error'      :{},\n",
    "                      'thresholds'      :{},\n",
    "                      'option'          :{},\n",
    "                      'certainty'       :{}}\n",
    "\n",
    "        for leaf in Tree._get_leaf_nodes()+Tree._get_internal_nodes(): \n",
    "            statistics['precision_'+leaf] = {}\n",
    "            statistics['recall_'+leaf]    = {}\n",
    "            statistics['f1_'+leaf]        = {}\n",
    "            \n",
    "        feature_importances = pd.DataFrame(index = X_col)\n",
    "        decision_trees = {}\n",
    "    \n",
    "    # Get Daily information\n",
    "    \n",
    "    check_block = pred.isin(Tree._get_internal_nodes())\n",
    "    index_block = check_block[check_block].index        \n",
    "        \n",
    "    total_check_leaf = current_pred.isin(Tree._get_leaf_nodes())   # of all predictions which are now leaf\n",
    "    total_index_leaf = total_check_leaf[total_check_leaf].index\n",
    "        \n",
    "    if DAYS > 0:\n",
    "        block = pd.concat([previous_pred_block, pred.loc[previous_pred_block.index]], axis=1, keys = [0,1])\n",
    "        block['Nchange'] = block.apply(lambda row: 0 if row[1] in Tree._get_descendants(row[0])+[row[0]] else 1, axis = 1)\n",
    "        block['Pchange'] = block.apply(lambda row: 1 if row[1] in Tree._get_descendants(row[0]) else 0, axis = 1)\n",
    "    previous_pred_block = pred.loc[index_block]\n",
    "    previous_index_block = index_block #was commented?\n",
    "\n",
    "    y_test = y_test['detailedMatchClassification']\n",
    "    test_pred = pd.concat([y_test.loc[index_leaf], current_pred[index_leaf]], axis=1, keys = [0,1])\n",
    "    test_pred['TE'] = test_pred.apply(lambda row: Tree._tree_distance(row[0], row[1]), axis = 1)\n",
    "    \n",
    "    # Update Dictionary\n",
    "    \n",
    "    statistics['option'][DAYS]          = OPTION\n",
    "    statistics['certainty'][DAYS]       = CERTAINTY\n",
    "    statistics['thresholds'][DAYS]      = THRESHOLDS\n",
    "    statistics['%classified'][DAYS]     = current_pred.isin(Tree._get_leaf_nodes()).sum() / len(y_test)\n",
    "    statistics['N_classified'][DAYS]    = int(len(index_leaf))\n",
    "    statistics['N_predicted'][DAYS]     = int(len(pred))\n",
    "\n",
    "    statistics['leaf_accuracy'][DAYS]   = metrics.accuracy_score(y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "    statistics['leaf_precision'][DAYS]  = precision_score_ancestors(Tree, y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "    statistics['leaf_recall'][DAYS]     = recall_score_ancestors(Tree, y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "\n",
    "    for leaf in Tree._get_leaf_nodes()+Tree._get_internal_nodes():\n",
    "        leaf_ix = pred.loc[pred == leaf].index\n",
    "        statistics['precision_'+leaf][DAYS] = precision_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "        statistics['recall_'+leaf][DAYS]    = recall_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "        statistics['f1_'+leaf][DAYS]        = f1_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix], beta = 1)\n",
    "        \n",
    "    for clf in list(HC.stages.keys()):\n",
    "        if isinstance(HC.stages[clf]['classifier'],RandomForestClassifier):\n",
    "            feature_importances[clf+'_'+str(DAYS)] = HC.stages[clf]['classifier'].feature_importances_ \n",
    "        elif isinstance(HC.stages[clf]['classifier'],LogisticRegression):\n",
    "            feature_importances[clf+'_'+str(DAYS)] = HC.stages[clf]['classifier'].coef_[0] \n",
    "\n",
    "    statistics['total_leaf_accuracy'][DAYS]  = metrics.accuracy_score(y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "    statistics['total_leaf_precision'][DAYS] = precision_score_ancestors(Tree, y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "    statistics['total_leaf_recall'][DAYS]    = recall_score_ancestors(Tree, y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "\n",
    "    statistics['label_precision'][DAYS]  = precision_score_ancestors(Tree, y_test.loc[index_leaf.union(index_block)], pred.loc[index_leaf.union(index_block)]) \n",
    "    statistics['label_recall'][DAYS]     = recall_score_ancestors(Tree, y_test.loc[index_leaf.union(index_block)], pred.loc[index_leaf.union(index_block)])  \n",
    "\n",
    "    statistics['block_precision'][DAYS] = precision_score_ancestors(Tree, y_test.loc[index_block], pred.loc[index_block]) if DAYS < END else None\n",
    "    statistics['block_recall'][DAYS]    = recall_score_ancestors(Tree, y_test.loc[index_block], pred.loc[index_block]) if DAYS < END else None\n",
    "    statistics['block_Nchange'][DAYS]   = block['Nchange'].sum() / block['Nchange'].count() if DAYS > 0 else None\n",
    "    statistics['block_Pchange'][DAYS]   = block['Pchange'].sum() / block['Pchange'].count() if DAYS > 0 else None\n",
    "    statistics['%blocking'][DAYS]       = HC.blocking  if len(total_index_leaf) != len(y_test) else {'ORDERS':None,'KNOWN':None,'UNHAPPY':None}\n",
    "    statistics['%Tblocking'][DAYS]      = HC.Tblocking if len(total_index_leaf) != len(y_test) else {'ORDERS':None,'KNOWN':None,'UNHAPPY':None}\n",
    "\n",
    "    statistics['tree_error'][DAYS]      = np.mean(test_pred['TE'])\n",
    "        \n",
    "    return statistics, feature_importances, previous_pred_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scores(y_true, y_pred, average = 'macro'):\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = average)\n",
    "    return accuracy, scores[0], scores[1], scores[2]\n",
    "\n",
    "def local_scores(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = None, labels = labels, beta = 1)\n",
    "    return scores[0], scores[1], scores[2]\n",
    "\n",
    "def class_report(y_true, y_pred):\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "\n",
    "def _aggregate_class_sets(set_function, y_true, y_pred):\n",
    "    intersection_sum = 0\n",
    "    true_sum = 0\n",
    "    predicted_sum = 0\n",
    "    for true, pred in zip(list(y_true), list(y_pred)):\n",
    "        true_set = set([true] + set_function(true))\n",
    "        pred_set = set([pred] + set_function(pred))\n",
    "        intersection_sum += len(true_set.intersection(pred_set))\n",
    "        true_sum += len(true_set)\n",
    "        predicted_sum += len(pred_set)\n",
    "    return (true_sum, predicted_sum, intersection_sum)\n",
    "\n",
    "def precision_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    if predicted_sum == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return intersection_sum / predicted_sum\n",
    "\n",
    "def recall_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    if true_sum == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return intersection_sum / true_sum\n",
    "\n",
    "def f1_score_ancestors(class_hierarchy, y_true, y_pred, beta):\n",
    "    precision = precision_score_ancestors(class_hierarchy, y_true, y_pred)\n",
    "    recall = recall_score_ancestors(class_hierarchy, y_true, y_pred)\n",
    "    if (precision == None) or (recall == None):\n",
    "        return None\n",
    "    elif (precision == 0) or (recall == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassHierarchy:\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.nodes = {}\n",
    "        \n",
    "    def add_node(self, children, parent):\n",
    "        for child in children:\n",
    "            self.nodes[child] = parent\n",
    "            \n",
    "    def _get_leaf_nodes(self):\n",
    "        leaf_nodes = []\n",
    "        for child in self.nodes.keys():\n",
    "            if self._get_children(child) == []:\n",
    "                leaf_nodes.append(child)\n",
    "        return leaf_nodes\n",
    "    \n",
    "    def _get_internal_nodes(self):\n",
    "        internal_nodes = []\n",
    "        leaves = self._get_leaf_nodes()\n",
    "        for child in self.nodes.keys():\n",
    "            if (child != self.root) and (child not in leaves):\n",
    "                internal_nodes.append(child)\n",
    "        return internal_nodes\n",
    "\n",
    "    def _get_children(self, parent):\n",
    "        return sorted([child for child, childs_parent in\n",
    "                       self.nodes.items() if childs_parent == parent])\n",
    "    \n",
    "    def _get_parent(self, child):\n",
    "        return self.nodes[child] if (child in self.nodes and child != self.root) else self.root\n",
    "    \n",
    "    def _get_ancestors(self, child):\n",
    "        # Not including root, not including the child\n",
    "        ancestors = []\n",
    "        while True:\n",
    "            child = self._get_parent(child)\n",
    "            if child == self.root:\n",
    "                break\n",
    "            ancestors.append(child)\n",
    "        return ancestors\n",
    "    \n",
    "    def _get_descendants(self, parent):\n",
    "        # Return a list of the descendants of this node, not including the parent\n",
    "        descendants = []\n",
    "        self._depth_first(parent, descendants)\n",
    "        descendants.remove(parent)\n",
    "        return descendants\n",
    "    \n",
    "    def _depth_first(self, parent, classes):\n",
    "        classes.append(parent)\n",
    "        for node in self._get_children(parent):\n",
    "            self._depth_first(node, classes)\n",
    "            \n",
    "    def _tree_distance(self, y_test, pred):\n",
    "        \n",
    "        y_test_path = [y_test] + self._get_ancestors(y_test) + [self.root] if y_test != self.root else [y_test] + self._get_ancestors(y_test)\n",
    "        pred_path   = [pred] + self._get_ancestors(pred) + [self.root] if pred != self.root else [pred] + self._get_ancestors(pred)\n",
    "        \n",
    "        y_test_edges = []\n",
    "        for ix, node in enumerate(y_test_path):\n",
    "            length = len(y_test_path)\n",
    "            if ix < length - 1:\n",
    "                y_test_edges.append((node, y_test_path[ix+1]))\n",
    "                \n",
    "        pred_edges = []\n",
    "        for ix, node in enumerate(pred_path):\n",
    "            length = len(pred_path)\n",
    "            if ix < length - 1:\n",
    "                pred_edges.append((node, pred_path[ix+1]))        \n",
    "        \n",
    "        tree_distance = len([edge for edge in y_test_edges + pred_edges if edge not in pred_edges or edge not in y_test_edges])\n",
    "        \n",
    "        return tree_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalClassifier:\n",
    "\n",
    "    def __init__(self, class_hierarchy):\n",
    "        self.stages = {}\n",
    "        self.class_hierarchy = class_hierarchy\n",
    "        self._create_stages(self.stages, self.class_hierarchy.root, 0)\n",
    "\n",
    "    def _create_stages(self, stages, parent, depth):\n",
    "        # Get the children of this parent\n",
    "        children = self.class_hierarchy._get_children(parent)\n",
    "        \n",
    "        if len(children) > 0:\n",
    "            stage = {}\n",
    "            stage['depth'] = depth\n",
    "            stage['labels'] = children\n",
    "            stage['classes'] = stage['labels'] + [parent]\n",
    "            stage['target'] = 'target_stage_' + parent\n",
    "            stages[parent] = stage\n",
    "\n",
    "            for node in children:\n",
    "                self._create_stages(stages, node, depth + 1)\n",
    "                \n",
    "    def _recode_label(self, classes, label):\n",
    "\n",
    "        while label != self.class_hierarchy.root and label not in classes:\n",
    "            label = self.class_hierarchy._get_parent(label)\n",
    "        return label\n",
    "                \n",
    "    def _prep_data(self, X, y):\n",
    "        \n",
    "        Xcols = range(0, X.shape[1])\n",
    "        Ycol = X.shape[1]\n",
    "        \n",
    "        df = pd.concat([X, y], axis=1, ignore_index=True)\n",
    "        # Create a target column for each stage with the recoded labels\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            df[stage_info['target']] = pd.DataFrame.apply(df[[Ycol]],\n",
    "                                    lambda row: self._recode_label(stage_info['classes'], row[Ycol]),\n",
    "                                    axis=1)\n",
    "        return df, Xcols\n",
    "    \n",
    "    def _label_mapping(self, y_train, stage_name):\n",
    "        labels = np.unique(y_train)\n",
    "        int_label_mapping = dict(enumerate(labels))\n",
    "        label_int_mapping = {y:x for x,y in int_label_mapping.items()}\n",
    "        self.stages[stage_name]['mapping'] = {'int_label':int_label_mapping,\n",
    "                                              'label_int':label_int_mapping}\n",
    "        \n",
    "    def _class_weights(self, y_train, stage_name):\n",
    "        class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        self.stages[stage_name]['classifier'].set_params(class_weight = class_weights)\n",
    "    \n",
    "    def fit_classifiers(self, classifiers):\n",
    "        \"\"\"\n",
    "        Fit a classifier to each stage\n",
    "        \"\"\"\n",
    "        if classifiers.keys() != self.stages.keys():\n",
    "             raise ValueError('Your assigned classifiers do not match the stages of the hierarchy, fit a classifier to each of: '+self.stages.keys())\n",
    "        else:\n",
    "            for stage, classifier in classifiers.items():\n",
    "                self.stages[stage]['classifier'] = classifier\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a multi-classifier from training data (X, y).\n",
    "        \"\"\"\n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        self.scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_train = dfFilter[Xcols]\n",
    "            y_train = dfFilter[[stage_info['target']]]\n",
    "                        \n",
    "            # warning - no samples to fit for stage\n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                y_train_col = pd.Series(np.ravel(y_train))\n",
    "                \n",
    "                self._class_weights(y_train_col, stage_name)\n",
    "                self._label_mapping(y_train_col, stage_name)\n",
    "\n",
    "                y_encoded = y_train_col.map(stage_info['mapping']['label_int'])\n",
    "\n",
    "                if len(stage_info['labels']) > 2:\n",
    "                    y_dummy = pd.DataFrame(np_utils.to_categorical(y_encoded))\n",
    "                    y_train_NN = y_dummy\n",
    "                else:\n",
    "                    y_train_NN = np.asarray(y_encoded).reshape((-1,1))\n",
    "\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_train))\n",
    "                stage_info['classifier'].fit(X_scaled, y_train_NN)\n",
    "            else:\n",
    "                stage_info['classifier'] = stage_info['classifier'].fit(X_train, y_train)\n",
    "            # print('Stage '+stage_name+' succesfully fitted')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  # warning - no samples to fit for stage\n",
    "            \n",
    "            if X_test.empty:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                if len(stage_info['labels']) == 2:\n",
    "                    y_pred = pd.Series(stage_info['classifier'].predict(X_scaled).flatten()).map(stage_info['mapping']['int_label'])\n",
    "                else:\n",
    "                    y_pred = pd.Series(stage_info['classifier'].predict(X_scaled)).map(stage_info['mapping']['int_label'])\n",
    "                y_hat_stage = pd.DataFrame(y_pred.values, index = X_test.index)\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(stage_info['classifier'].predict(X_test), index = X_test.index)\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]     \n",
    "    \n",
    "    def predict_proba(self, X, threshold = 0.5):\n",
    "        \n",
    "        self.blocking = {}\n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  # warning - no samples to fit for stage\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            max_prob = np.amax(y_proba, axis=1)              # max probability of classes\n",
    "            max_class = np.argmax(y_proba, axis=1)           # class number with max probability\n",
    "            accept_index = np.where(max_prob >= threshold)[0]# indexes which are above threshold\n",
    "            accept_class = np.take(max_class, accept_index)  # filtered list of orders which are above threshold\n",
    "            \n",
    "            if len(accept_class) > 0: # check if samples reach threshold\n",
    "                accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             # convert class number into label\n",
    "                y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  # set labels to correct position\n",
    "                self.blocking[stage_name] = 1 - (len(accept_class) / len(max_class)) # blocking factor\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "                self.blocking[stage_name] = 1\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) # fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "    \n",
    "    def predict_proba2(self, X, THRESHOLDS):\n",
    "        \n",
    "        self.blocking = {}\n",
    "        self.Tblocking = {}\n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  # warning - no samples to fit for stage\n",
    "            \n",
    "            if X_test.empty:\n",
    "                self.blocking[stage_name] = None\n",
    "                self.Tblocking[stage_name] = None\n",
    "                continue\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            max_prob = np.amax(y_proba, axis=1)              # max probability of classes\n",
    "            max_class = np.argmax(y_proba, axis=1)           # class number with max probability\n",
    "            max_class_thresholds = np.vectorize(lambda x: THRESHOLDS[y_classes[x]])(max_class)  # get node specific threshold\n",
    "            \n",
    "            accept_index = np.where(max_prob >= max_class_thresholds)[0]\n",
    "\n",
    "            accept_class = np.take(max_class, accept_index)  # filtered list of orders which are above threshold\n",
    "            \n",
    "            if len(accept_class) > 0: # check if samples reach threshold\n",
    "                accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             # convert class number into label\n",
    "                y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  # set labels to correct position\n",
    "                \n",
    "                self.blocking[stage_name] = 1 - (len(accept_class) / len(max_class)) # blocking factor\n",
    "                self.Tblocking[stage_name] = len(max_class) - len(accept_class)\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "                self.blocking[stage_name] = 1\n",
    "                self.Tblocking[stage_name] = len(max_class)\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) # fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "    \n",
    "    def get_probabilities(self, X, y):\n",
    "        \n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        \n",
    "        stage_number = 0\n",
    "        \n",
    "        y_hat = pd.DataFrame(columns = [self.class_hierarchy.root], index = X.index)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "                \n",
    "            stage_number += 1             \n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_test = dfFilter[Xcols]\n",
    "            y_test = dfFilter[[stage_info['target']]]\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            y_hat_stage = pd.DataFrame(y_proba, index = X_test.index)\n",
    "\n",
    "            for col, label in enumerate(y_classes):\n",
    "                y_hat[label] = y_hat_stage[col]\n",
    "               \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(day):\n",
    "    HC = HierarchicalClassifier(ch)\n",
    "    HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '1_criterion'], max_depth = hypers.loc[day, '1_max_depth']),\n",
    "                        'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '2_criterion'], max_depth = hypers.loc[day, '2_max_depth']),\n",
    "                        'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[day, '3_max_depth'], n_estimators = hypers.loc[day, '3_n_estimators'])})\n",
    "    \n",
    "    X, y  = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, day)\n",
    "    index = range(0, X.shape[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "    HC.fit(X_train,y_train)\n",
    "    y_hat = HC.get_probabilities(X_train, y_train)\n",
    "\n",
    "    probs = pd.concat([y_train, y_hat], axis=1)\n",
    "    \n",
    "    return(probs)\n",
    "\n",
    "def opt_threshold(probs, node, day, certainty, option, steps = 100):\n",
    "    \n",
    "    if node == 1:\n",
    "        probabilities_for = 'UNKNOWN'\n",
    "        y_pos_filter_list = ['UNKNOWN']\n",
    "        y_neg_filter_list = ['HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[['UNKNOWN', 'KNOWN']]\n",
    "        majority_vote     = level[level['UNKNOWN'] > level['KNOWN']]['UNKNOWN']\n",
    "    elif node == 2:\n",
    "        probabilities_for = 'KNOWN'\n",
    "        y_pos_filter_list = ['HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['UNKNOWN']\n",
    "        level             = probs[['UNKNOWN', 'KNOWN']]\n",
    "        majority_vote     = level[level['KNOWN'] > level['UNKNOWN']]['KNOWN']\n",
    "    elif node == 3:\n",
    "        probabilities_for = 'HAPPY'\n",
    "        y_pos_filter_list = ['HAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY', 'HAPPY'])][['UNHAPPY', 'HAPPY']]\n",
    "        majority_vote     = level[level['HAPPY'] > level['UNHAPPY']]['HAPPY']\n",
    "    elif node == 4:\n",
    "        probabilities_for = 'UNHAPPY'\n",
    "        y_pos_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['HAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY', 'HAPPY'])][['UNHAPPY', 'HAPPY']]\n",
    "        majority_vote     = level[level['UNHAPPY'] > level['HAPPY']]['UNHAPPY']\n",
    "    elif node == 5:\n",
    "        probabilities_for = 'MILDLY UNHAPPY'\n",
    "        y_pos_filter_list = ['MILDLY UNHAPPY']\n",
    "        y_neg_filter_list = ['MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])][['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']]\n",
    "        majority_vote     = level[ (level['MILDLY UNHAPPY'] > level['MEDIUM UNHAPPY']) & (level['MILDLY UNHAPPY'] > level['HEAVILY UNHAPPY']) ]['MILDLY UNHAPPY']\n",
    "    elif node == 6:\n",
    "        probabilities_for = 'MEDIUM UNHAPPY'\n",
    "        y_pos_filter_list = ['MEDIUM UNHAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])][['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']]\n",
    "        majority_vote     = level[ (level['MEDIUM UNHAPPY'] > level['MILDLY UNHAPPY']) & (level['MEDIUM UNHAPPY'] > level['HEAVILY UNHAPPY']) ]['MEDIUM UNHAPPY']\n",
    "    elif node == 7:\n",
    "        probabilities_for = 'HEAVILY UNHAPPY'\n",
    "        y_pos_filter_list = ['HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])][['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']]\n",
    "        majority_vote     = level[ (level['HEAVILY UNHAPPY'] > level['MEDIUM UNHAPPY']) & (level['HEAVILY UNHAPPY'] > level['MILDLY UNHAPPY']) ]['HEAVILY UNHAPPY']\n",
    "    else:\n",
    "        raise Exception('''Error: undefined node has been passed. Node options (integer input):\n",
    "                           1: Unknown\n",
    "                           2: Known\n",
    "                           3: Happy\n",
    "                           4: Unhappy\n",
    "                           5: Mildly Unhappy\n",
    "                           6: Medium Unhappy\n",
    "                           7: Heavily Unhappy''')\n",
    "    \n",
    "    y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)][probabilities_for] \n",
    "    y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)][probabilities_for]\n",
    "    \n",
    "    if option == 1:\n",
    "        y_pos = y_pos[y_pos > min(majority_vote)]\n",
    "        y_neg = y_neg[y_neg > min(majority_vote)]\n",
    "    elif option == 2:\n",
    "        y_pos = y_pos[y_pos.index.isin(majority_vote.index)]\n",
    "        y_neg = y_neg[y_neg.index.isin(majority_vote.index)]\n",
    "    else:\n",
    "        raise Exception('''Error: undefined threshold option has been passed. Threshold options (integer input):\n",
    "                           1: Consider all probabilities >= min(majority vote)\n",
    "                           2: Only consider probabilities that are the majority vote''')\n",
    "    \n",
    "    # Potential thresholds\n",
    "    V = np.concatenate((y_pos, y_neg))\n",
    "    V = np.unique(V) # np.unique() also sorts\n",
    "    \n",
    "    if len(y_neg) > 0:\n",
    "        lowerbound = np.percentile(y_neg, (certainty*100))\n",
    "    else:\n",
    "        lowerbound = V.min()\n",
    "    \n",
    "    V = V[V >= lowerbound] # define allowed search space\n",
    "    \n",
    "    S = np.linspace(V.min(), V.max(), steps)\n",
    "    \n",
    "    thresholds = pd.DataFrame({'threshold'     : [0]*steps,\n",
    "                               'F_score'       : [0]*steps})\n",
    "    \n",
    "    for i in range(steps):        \n",
    "        threshold = S[i]       \n",
    "        beta      = 1\n",
    "        positives = len(y_pos[y_pos >= threshold])  \n",
    "        negatives = len(y_neg[y_neg >= threshold]) \n",
    "        recall    = positives / len(y_pos)\n",
    "        precision = positives / (positives + negatives)\n",
    "\n",
    "        thresholds.loc[i, 'threshold']       = threshold\n",
    "        thresholds.loc[i, 'F_score']         = ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall) if ((beta ** 2 * precision) + recall) != 0 else 0\n",
    "        \n",
    "    F_score         = thresholds['F_score'].max()\n",
    "    opt_index       = thresholds['F_score'].argmax()\n",
    "    threshold       = thresholds.loc[opt_index, 'threshold']\n",
    "    \n",
    "    return(probabilities_for, threshold)\n",
    "\n",
    "def flat_thresholds(probs, node, day, certainty, steps = 100):\n",
    "    \n",
    "    NODES = set(['UNKNOWN', 'HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])\n",
    "    \n",
    "    if node == 1:   NODE = 'UNKNOWN'\n",
    "    elif node == 2: NODE = 'HAPPY'\n",
    "    elif node == 3: NODE = 'MILDLY UNHAPPY'\n",
    "    elif node == 4: NODE = 'MEDIUM UNHAPPY'\n",
    "    elif node == 5: NODE = 'HEAVILY UNHAPPY'\n",
    "    else:\n",
    "        raise Exception('''Error: undefined node has been passed. Node options (integer input):\n",
    "                           1: Unknown\n",
    "                           2: Happy\n",
    "                           3: Mildly Unhappy\n",
    "                           4: Medium Unhappy\n",
    "                           5: Heavily Unhappy''')\n",
    "        \n",
    "    probabilities_for = NODE\n",
    "    y_pos_filter_list = [NODE]\n",
    "    y_neg_filter_list = list(NODES - {NODE})\n",
    "    majority_vote     = probs[probs[NODE] > probs[list(NODES - {NODE})].max(axis=1)][NODE]\n",
    "        \n",
    "    y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)][probabilities_for] \n",
    "    y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)][probabilities_for]\n",
    "    \n",
    "    y_pos = y_pos[y_pos.index.isin(majority_vote.index)]\n",
    "    y_neg = y_neg[y_neg.index.isin(majority_vote.index)]\n",
    " \n",
    "    if len(y_neg) > 0:\n",
    "        lowerbound = np.percentile(y_neg, (certainty*100))\n",
    "    else:\n",
    "        lowerbound = V.min()\n",
    "    \n",
    "    # Potential thresholds\n",
    "    V = np.concatenate((y_pos, y_neg))\n",
    "    V = np.unique(V) # np.unique() also sorts    \n",
    "    V = V[V >= lowerbound] # define allowed search space\n",
    "    S = np.linspace(V.min(), V.max(), steps)\n",
    "    \n",
    "    thresholds = pd.DataFrame({'threshold'     : [0]*steps,\n",
    "                               'F_score'       : [0]*steps})\n",
    "    \n",
    "    for i in range(steps):        \n",
    "        threshold = S[i] \n",
    "        beta      = 1\n",
    "        positives = len(y_pos[y_pos >= threshold])\n",
    "        negatives = len(y_neg[y_neg >= threshold])\n",
    "        recall    = positives / len(y_pos)\n",
    "        precision = positives / (positives + negatives)\n",
    "\n",
    "        thresholds.loc[i, 'threshold']       = threshold\n",
    "        thresholds.loc[i, 'F_score']         = ( (1 + (beta**2)) * precision * recall ) / ( (beta**2) * precision + recall ) if ( (beta**2) * precision + recall ) != 0 else 0\n",
    "        \n",
    "    \n",
    "    F_score         = thresholds['F_score'].max()\n",
    "    opt_index       = thresholds['F_score'].argmax()\n",
    "    threshold       = thresholds.loc[opt_index, 'threshold']                           \n",
    "\n",
    "    return(probabilities_for, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
