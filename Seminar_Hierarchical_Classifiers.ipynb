{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:10:26.996028Z",
     "iopub.status.busy": "2021-03-07T16:10:26.995677Z",
     "iopub.status.idle": "2021-03-07T16:10:46.523526Z",
     "shell.execute_reply": "2021-03-07T16:10:46.522739Z",
     "shell.execute_reply.started": "2021-03-07T16:10:26.995991Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectPercentile, mutual_info_classif, RFE, RFECV, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import product\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:05:01.715660Z",
     "iopub.status.busy": "2021-03-05T10:05:01.715235Z",
     "iopub.status.idle": "2021-03-05T10:05:01.742390Z",
     "shell.execute_reply": "2021-03-05T10:05:01.740917Z",
     "shell.execute_reply.started": "2021-03-05T10:05:01.715611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/Users/LV/Documents/GitHub/Seminar-QM-BA/functions.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:54:08.124566Z",
     "iopub.status.busy": "2021-03-07T16:54:08.124293Z",
     "iopub.status.idle": "2021-03-07T16:55:48.209463Z",
     "shell.execute_reply": "2021-03-07T16:55:48.205905Z",
     "shell.execute_reply.started": "2021-03-07T16:54:08.124540Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/LV/Desktop/data_bol_complete.csv', low_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:55:48.216265Z",
     "iopub.status.busy": "2021-03-07T16:55:48.215941Z",
     "iopub.status.idle": "2021-03-07T16:56:04.349627Z",
     "shell.execute_reply": "2021-03-07T16:56:04.348870Z",
     "shell.execute_reply.started": "2021-03-07T16:55:48.216232Z"
    }
   },
   "outputs": [],
   "source": [
    "df['orderDate']                   = pd.to_datetime(df['orderDate'])\n",
    "df['cancellationDate']            = pd.to_datetime(df['cancellationDate'])\n",
    "df['promisedDeliveryDate']        = pd.to_datetime(df['promisedDeliveryDate'])\n",
    "df['shipmentDate']                = pd.to_datetime(df['shipmentDate'])\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'])\n",
    "df['startDateCase']               = pd.to_datetime(df['startDateCase'])\n",
    "df['returnDateTime']              = pd.to_datetime(df['returnDateTime'])\n",
    "df['registrationDateSeller']      = pd.to_datetime(df['registrationDateSeller'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-27T21:57:04.995208Z",
     "iopub.status.busy": "2021-02-27T21:57:04.994964Z",
     "iopub.status.idle": "2021-02-27T21:57:05.278096Z",
     "shell.execute_reply": "2021-02-27T21:57:05.277419Z",
     "shell.execute_reply.started": "2021-02-27T21:57:04.995185Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate totals per Match Determinant\n",
    "totalCase = df['caseDays'].count()\n",
    "totalReturn = df['returnDays'].count()\n",
    "totalCancel = df['cancellationDays'].count()\n",
    "totalPromisedDelivery = df['promisedDeliveryDays'].count()\n",
    "totalDelivery = df['actualDeliveryDays'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-27T21:57:05.279671Z",
     "iopub.status.busy": "2021-02-27T21:57:05.279422Z",
     "iopub.status.idle": "2021-02-27T21:57:05.478294Z",
     "shell.execute_reply": "2021-02-27T21:57:05.477603Z",
     "shell.execute_reply.started": "2021-02-27T21:57:05.279649Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create table for plot\n",
    "periodTable = pd.concat([df['caseDays'].value_counts().sort_index(),\n",
    "                         df['returnDays'].value_counts().sort_index(),\n",
    "                         df['cancellationDays'].value_counts().sort_index(),\n",
    "                         df['promisedDeliveryDays'].value_counts().sort_index(),\n",
    "                         df['actualDeliveryDays'].value_counts().sort_index()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-27T21:57:05.479857Z",
     "iopub.status.busy": "2021-02-27T21:57:05.479613Z",
     "iopub.status.idle": "2021-02-27T21:57:05.560804Z",
     "shell.execute_reply": "2021-02-27T21:57:05.560079Z",
     "shell.execute_reply.started": "2021-02-27T21:57:05.479832Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create percantages per day and calculate running sum\n",
    "periodTable['caseDays%'] = (periodTable['caseDays'] / totalCase).cumsum()\n",
    "periodTable['returnDays%'] = (periodTable['returnDays'] / totalReturn).cumsum()\n",
    "periodTable['cancellationDays%'] = (periodTable['cancellationDays'] / totalCancel).cumsum()\n",
    "periodTable['promisedDeliveryDays%'] = (periodTable['promisedDeliveryDays'] / totalPromisedDelivery).cumsum()\n",
    "periodTable['actualDeliveryDays%'] = (periodTable['actualDeliveryDays'] / df.shape[0]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T14:57:18.556843Z",
     "iopub.status.busy": "2021-02-26T14:57:18.556597Z",
     "iopub.status.idle": "2021-02-26T14:57:18.567970Z",
     "shell.execute_reply": "2021-02-26T14:57:18.566843Z",
     "shell.execute_reply.started": "2021-02-26T14:57:18.556820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.7)(1, 28.2)(2, 50.0)(3, 57.6)(4, 61.5)(5, 62.9)(6, 63.5)(7, 63.8)(8, 64.0)(9, 64.0)(10, 64.1)(11, 64.2)(12, 64.2)(13, 64.2)(14, 64.2)(15, 64.2)(16, 64.2)(17, 64.2)(18, 64.2)(19, 64.2)(20, 64.2)(21, 64.2)(22, 64.2)(23, 64.2)(24, 64.2)(25, 64.2)(26, 64.2)(27, 64.2)(28, 64.2)(29, 64.2)"
     ]
    }
   ],
   "source": [
    "col = periodTable['actualDeliveryDays%']\n",
    "for i in range(30):\n",
    "    if i < 13:\n",
    "        print((i,round(col[i]*100,1)), end = '')\n",
    "    else:\n",
    "        print((i,64.2), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-26T14:52:00.101266Z",
     "iopub.status.busy": "2021-02-26T14:52:00.100945Z",
     "iopub.status.idle": "2021-02-26T14:52:00.155063Z",
     "shell.execute_reply": "2021-02-26T14:52:00.153570Z",
     "shell.execute_reply.started": "2021-02-26T14:52:00.101236Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseDays</th>\n",
       "      <th>returnDays</th>\n",
       "      <th>cancellationDays</th>\n",
       "      <th>promisedDeliveryDays</th>\n",
       "      <th>actualDeliveryDays</th>\n",
       "      <th>caseDays%</th>\n",
       "      <th>returnDays%</th>\n",
       "      <th>cancellationDays%</th>\n",
       "      <th>promisedDeliveryDays%</th>\n",
       "      <th>actualDeliveryDays%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10221.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>34537.0</td>\n",
       "      <td>35338.0</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.195796</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.007404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20425.0</td>\n",
       "      <td>34083.0</td>\n",
       "      <td>6940.0</td>\n",
       "      <td>1699249.0</td>\n",
       "      <td>1310846.0</td>\n",
       "      <td>0.186459</td>\n",
       "      <td>0.125180</td>\n",
       "      <td>0.488710</td>\n",
       "      <td>0.363252</td>\n",
       "      <td>0.282044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>22459.0</td>\n",
       "      <td>42638.0</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>1319161.0</td>\n",
       "      <td>1041357.0</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.277158</td>\n",
       "      <td>0.600051</td>\n",
       "      <td>0.639635</td>\n",
       "      <td>0.500223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>19048.0</td>\n",
       "      <td>35268.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>592789.0</td>\n",
       "      <td>363063.0</td>\n",
       "      <td>0.438999</td>\n",
       "      <td>0.402866</td>\n",
       "      <td>0.664289</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.576290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>16078.0</td>\n",
       "      <td>28205.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>433153.0</td>\n",
       "      <td>183553.0</td>\n",
       "      <td>0.536822</td>\n",
       "      <td>0.503399</td>\n",
       "      <td>0.730849</td>\n",
       "      <td>0.854584</td>\n",
       "      <td>0.614747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>12818.0</td>\n",
       "      <td>22366.0</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>297018.0</td>\n",
       "      <td>68269.0</td>\n",
       "      <td>0.614810</td>\n",
       "      <td>0.583119</td>\n",
       "      <td>0.807074</td>\n",
       "      <td>0.916814</td>\n",
       "      <td>0.629050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>9714.0</td>\n",
       "      <td>17796.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>34360.0</td>\n",
       "      <td>27708.0</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.646551</td>\n",
       "      <td>0.859410</td>\n",
       "      <td>0.924013</td>\n",
       "      <td>0.634856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7836.0</td>\n",
       "      <td>15306.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>170636.0</td>\n",
       "      <td>14698.0</td>\n",
       "      <td>0.721589</td>\n",
       "      <td>0.701107</td>\n",
       "      <td>0.902503</td>\n",
       "      <td>0.959763</td>\n",
       "      <td>0.637935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>5623.0</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>60228.0</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>0.755801</td>\n",
       "      <td>0.743024</td>\n",
       "      <td>0.941713</td>\n",
       "      <td>0.972382</td>\n",
       "      <td>0.639524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>4301.0</td>\n",
       "      <td>9360.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>34774.0</td>\n",
       "      <td>4443.0</td>\n",
       "      <td>0.781970</td>\n",
       "      <td>0.776386</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.979668</td>\n",
       "      <td>0.640455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>3731.0</td>\n",
       "      <td>7696.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>35359.0</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>0.804670</td>\n",
       "      <td>0.803817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987076</td>\n",
       "      <td>0.641124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>3316.0</td>\n",
       "      <td>6554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13120.0</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>0.824846</td>\n",
       "      <td>0.827178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989825</td>\n",
       "      <td>0.641596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>3067.0</td>\n",
       "      <td>5932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36578.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>0.843506</td>\n",
       "      <td>0.848322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.641888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>2839.0</td>\n",
       "      <td>5496.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860780</td>\n",
       "      <td>0.867912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>2693.0</td>\n",
       "      <td>5153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877164</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>2107.0</td>\n",
       "      <td>4269.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889984</td>\n",
       "      <td>0.901495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>2052.0</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902469</td>\n",
       "      <td>0.914876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>2166.0</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915648</td>\n",
       "      <td>0.927144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>1897.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.927189</td>\n",
       "      <td>0.937649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>1653.0</td>\n",
       "      <td>2564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937247</td>\n",
       "      <td>0.946788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>1537.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946598</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>1459.0</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955475</td>\n",
       "      <td>0.962364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>1158.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962521</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>1060.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968970</td>\n",
       "      <td>0.974597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>909.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974501</td>\n",
       "      <td>0.979320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>882.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979867</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>828.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984905</td>\n",
       "      <td>0.988159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>797.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989754</td>\n",
       "      <td>0.992287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995230</td>\n",
       "      <td>0.996386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>784.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      caseDays  returnDays  cancellationDays  promisedDeliveryDays  \\\n",
       "0.0    10221.0      1037.0            4639.0               34537.0   \n",
       "1.0    20425.0     34083.0            6940.0             1699249.0   \n",
       "2.0    22459.0     42638.0            2638.0             1319161.0   \n",
       "3.0    19048.0     35268.0            1522.0              592789.0   \n",
       "4.0    16078.0     28205.0            1577.0              433153.0   \n",
       "5.0    12818.0     22366.0            1806.0              297018.0   \n",
       "6.0     9714.0     17796.0            1240.0               34360.0   \n",
       "7.0     7836.0     15306.0            1021.0              170636.0   \n",
       "8.0     5623.0     11760.0             929.0               60228.0   \n",
       "9.0     4301.0      9360.0             508.0               34774.0   \n",
       "10.0    3731.0      7696.0             873.0               35359.0   \n",
       "11.0    3316.0      6554.0               NaN               13120.0   \n",
       "12.0    3067.0      5932.0               NaN               36578.0   \n",
       "13.0    2839.0      5496.0               NaN                8289.0   \n",
       "14.0    2693.0      5153.0               NaN                1979.0   \n",
       "15.0    2107.0      4269.0               NaN                 999.0   \n",
       "16.0    2052.0      3754.0               NaN                 416.0   \n",
       "17.0    2166.0      3442.0               NaN                 252.0   \n",
       "18.0    1897.0      2947.0               NaN                  10.0   \n",
       "19.0    1653.0      2564.0               NaN                   4.0   \n",
       "20.0    1537.0      2265.0               NaN                   5.0   \n",
       "21.0    1459.0      2105.0               NaN                   6.0   \n",
       "22.0    1158.0      1810.0               NaN                   4.0   \n",
       "23.0    1060.0      1622.0               NaN                   6.0   \n",
       "24.0     909.0      1325.0               NaN                   1.0   \n",
       "25.0     882.0      1277.0               NaN                   2.0   \n",
       "26.0     828.0      1203.0               NaN                   2.0   \n",
       "27.0     797.0      1158.0               NaN                   NaN   \n",
       "28.0     900.0      1150.0               NaN                   2.0   \n",
       "29.0     784.0      1014.0               NaN                  10.0   \n",
       "49.0       NaN         NaN               NaN                   1.0   \n",
       "\n",
       "      actualDeliveryDays  caseDays%  returnDays%  cancellationDays%  \\\n",
       "0.0              35338.0   0.062187     0.003696           0.195796   \n",
       "1.0            1310846.0   0.186459     0.125180           0.488710   \n",
       "2.0            1041357.0   0.323106     0.277158           0.600051   \n",
       "3.0             363063.0   0.438999     0.402866           0.664289   \n",
       "4.0             183553.0   0.536822     0.503399           0.730849   \n",
       "5.0              68269.0   0.614810     0.583119           0.807074   \n",
       "6.0              27708.0   0.673913     0.646551           0.859410   \n",
       "7.0              14698.0   0.721589     0.701107           0.902503   \n",
       "8.0               7583.0   0.755801     0.743024           0.941713   \n",
       "9.0               4443.0   0.781970     0.776386           0.963154   \n",
       "10.0              3196.0   0.804670     0.803817           1.000000   \n",
       "11.0              2251.0   0.824846     0.827178                NaN   \n",
       "12.0              1394.0   0.843506     0.848322                NaN   \n",
       "13.0                 NaN   0.860780     0.867912                NaN   \n",
       "14.0                 NaN   0.877164     0.886279                NaN   \n",
       "15.0                 NaN   0.889984     0.901495                NaN   \n",
       "16.0                 NaN   0.902469     0.914876                NaN   \n",
       "17.0                 NaN   0.915648     0.927144                NaN   \n",
       "18.0                 NaN   0.927189     0.937649                NaN   \n",
       "19.0                 NaN   0.937247     0.946788                NaN   \n",
       "20.0                 NaN   0.946598     0.954861                NaN   \n",
       "21.0                 NaN   0.955475     0.962364                NaN   \n",
       "22.0                 NaN   0.962521     0.968815                NaN   \n",
       "23.0                 NaN   0.968970     0.974597                NaN   \n",
       "24.0                 NaN   0.974501     0.979320                NaN   \n",
       "25.0                 NaN   0.979867     0.983871                NaN   \n",
       "26.0                 NaN   0.984905     0.988159                NaN   \n",
       "27.0                 NaN   0.989754     0.992287                NaN   \n",
       "28.0                 NaN   0.995230     0.996386                NaN   \n",
       "29.0                 NaN   1.000000     1.000000                NaN   \n",
       "49.0                 NaN        NaN          NaN                NaN   \n",
       "\n",
       "      promisedDeliveryDays%  actualDeliveryDays%  \n",
       "0.0                0.007236             0.007404  \n",
       "1.0                0.363252             0.282044  \n",
       "2.0                0.639635             0.500223  \n",
       "3.0                0.763833             0.576290  \n",
       "4.0                0.854584             0.614747  \n",
       "5.0                0.916814             0.629050  \n",
       "6.0                0.924013             0.634856  \n",
       "7.0                0.959763             0.637935  \n",
       "8.0                0.972382             0.639524  \n",
       "9.0                0.979668             0.640455  \n",
       "10.0               0.987076             0.641124  \n",
       "11.0               0.989825             0.641596  \n",
       "12.0               0.997488             0.641888  \n",
       "13.0               0.999225                  NaN  \n",
       "14.0               0.999640                  NaN  \n",
       "15.0               0.999849                  NaN  \n",
       "16.0               0.999936                  NaN  \n",
       "17.0               0.999989                  NaN  \n",
       "18.0               0.999991                  NaN  \n",
       "19.0               0.999992                  NaN  \n",
       "20.0               0.999993                  NaN  \n",
       "21.0               0.999994                  NaN  \n",
       "22.0               0.999995                  NaN  \n",
       "23.0               0.999996                  NaN  \n",
       "24.0               0.999996                  NaN  \n",
       "25.0               0.999997                  NaN  \n",
       "26.0               0.999997                  NaN  \n",
       "27.0                    NaN                  NaN  \n",
       "28.0               0.999998                  NaN  \n",
       "29.0               1.000000                  NaN  \n",
       "49.0               1.000000                  NaN  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periodTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:56:04.353045Z",
     "iopub.status.busy": "2021-03-07T16:56:04.352682Z",
     "iopub.status.idle": "2021-03-07T16:56:04.371445Z",
     "shell.execute_reply": "2021-03-07T16:56:04.369317Z",
     "shell.execute_reply.started": "2021-03-07T16:56:04.353017Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "DATE = ['orderDate']\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength','promisedDeliveryDays','partnerSellingDays', 'orderCorona']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "YEAR = ['orderYear2020']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "HISTORICX = []\n",
    "historic_variable = ['transporterCode','sellerId','productGroup']\n",
    "for x in range(len(historic_variable)):\n",
    "    HISTORICX = HISTORICX + [historic_variable[x]+'HistoricHappyX',historic_variable[x]+'HistoricUnhappyX',historic_variable[x]+'HistoricUnknownX']\n",
    "\n",
    "#Determinants:\n",
    "DETERMINANT = ['noReturn', 'noCase', 'noCancellation', 'onTimeDelivery']\n",
    "\n",
    "#Classifications\n",
    "CLASSIFICATION = ['generalMatchClassification','detailedMatchClassification','binaryMatchClassification','determinantClassification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:56:04.377478Z",
     "iopub.status.busy": "2021-03-07T16:56:04.376214Z",
     "iopub.status.idle": "2021-03-07T16:56:04.385408Z",
     "shell.execute_reply": "2021-03-07T16:56:04.383913Z",
     "shell.execute_reply.started": "2021-03-07T16:56:04.377415Z"
    }
   },
   "outputs": [],
   "source": [
    "X_col = BASIC + WEEK + MONTH + YEAR + GROUP + TRANSPORTERX + KNOWNX + PRODUCTX + SELLERX + HISTORICX\n",
    "Y_col = ['detailedMatchClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T17:13:57.920968Z",
     "iopub.status.busy": "2021-03-11T17:13:57.920495Z",
     "iopub.status.idle": "2021-03-11T17:14:07.638151Z",
     "shell.execute_reply": "2021-03-11T17:14:07.635148Z",
     "shell.execute_reply.started": "2021-03-11T17:13:57.920917Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = df.sample(n = 100000, replace = False, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Validation (Flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T11:19:00.573719Z",
     "iopub.status.busy": "2021-03-05T11:19:00.573462Z",
     "iopub.status.idle": "2021-03-05T11:19:12.749148Z",
     "shell.execute_reply": "2021-03-05T11:19:12.747709Z",
     "shell.execute_reply.started": "2021-03-05T11:19:00.573693Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_ contains a sample of training + validation data\n",
    "random.seed(100)\n",
    "df_ = df.iloc[:int(0.8*len(df))].sample(n=1100000, replace=False, random_state=1).sort_values(by = 'orderDate').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:37:11.789181Z",
     "iopub.status.busy": "2021-03-05T10:37:11.788658Z",
     "iopub.status.idle": "2021-03-05T10:37:11.801292Z",
     "shell.execute_reply": "2021-03-05T10:37:11.799859Z",
     "shell.execute_reply.started": "2021-03-05T10:37:11.789145Z"
    }
   },
   "outputs": [],
   "source": [
    "def flat_get_hyperspace(combination):\n",
    "    \n",
    "    param_hyperopt = {}\n",
    "\n",
    "    if combination == 'DT':\n",
    "        hyper = {'DT_criterion'   : hp.choice('DT_criterion',['gini','entropy']),\n",
    "                 'DT_max_depth'   : scope.int(hp.quniform('DT_max_depth', 5, 15, 1))}\n",
    "    elif combination == 'RF':\n",
    "        hyper = {'RF_max_depth'    : scope.int(hp.quniform('RF_max_depth', 5, 15, 1)),\n",
    "                 'RF_n_estimators' : scope.int(hp.quniform('RF_n_estimators', 10, 50, 5))}\n",
    "    elif combination == 'NN':\n",
    "        hyper = {'NN_dropout'  : hp.uniform('NN_dropout', 0, 0.5),\n",
    "                 'NN_nodes'    : scope.int(hp.quniform('NN_nodes', 5, 50, 5)),\n",
    "                 'NN_layers'   : scope.int(hp.quniform('NN_layers', 1, 2, 1))}\n",
    "    elif combination == 'LR':\n",
    "        hyper = {'LR_penalty' : hp.choice('LR_penalty', ['l1','l2'])}\n",
    "\n",
    "    param_hyperopt = {**param_hyperopt, **hyper}\n",
    "        \n",
    "    return param_hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:47:45.215220Z",
     "iopub.status.busy": "2021-03-05T10:47:45.214966Z",
     "iopub.status.idle": "2021-03-05T10:47:45.226691Z",
     "shell.execute_reply": "2021-03-05T10:47:45.225097Z",
     "shell.execute_reply.started": "2021-03-05T10:47:45.215194Z"
    }
   },
   "outputs": [],
   "source": [
    "def flat_objective_function(params):\n",
    "    \n",
    "    if combination == 'RF':\n",
    "        clf = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = params['RF_max_depth'], n_estimators = params['RF_n_estimators'])\n",
    "    elif combination == 'LR':\n",
    "        print(params)\n",
    "        clf = LogisticRegression(penalty = params['LR_penalty'], class_weight = 'balanced', solver = 'liblinear')\n",
    "    \n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_val)\n",
    "    \n",
    "    precision, recall, f1, support = metrics.precision_recall_fscore_support(y_val, pred, average = 'weighted', beta = 1)\n",
    "    accuracy = metrics.accuracy_score(y_val, pred)\n",
    "    #cross validation score to be implemented?\n",
    "    \n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:42:40.010972Z",
     "iopub.status.busy": "2021-03-05T10:42:40.009116Z",
     "iopub.status.idle": "2021-03-05T10:42:40.023177Z",
     "shell.execute_reply": "2021-03-05T10:42:40.021702Z",
     "shell.execute_reply.started": "2021-03-05T10:42:40.010909Z"
    }
   },
   "outputs": [],
   "source": [
    "def flat_hyperopt(param_space, X_train, y_train, X_val, y_val, num_eval):\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    best_param = fmin(flat_objective_function, \n",
    "                      param_space, \n",
    "                      algo = tpe.suggest, \n",
    "                      max_evals = num_eval, \n",
    "                      trials = trials,\n",
    "                      rstate = np.random.RandomState(1))\n",
    "    \n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    index_min_loss = loss.index(min(loss))\n",
    "    accuracy_scores = [x['result']['accuracy'] for x in trials.trials]\n",
    "    \n",
    "    f1 = min(loss)*-1\n",
    "    accuracy = accuracy_scores[index_min_loss]\n",
    "    \n",
    "    return best_param, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:42:40.219951Z",
     "iopub.status.busy": "2021-03-05T10:42:40.219642Z",
     "iopub.status.idle": "2021-03-05T10:42:40.228383Z",
     "shell.execute_reply": "2021-03-05T10:42:40.226726Z",
     "shell.execute_reply.started": "2021-03-05T10:42:40.219906Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lourens\n",
    "begin, end = 6, 8\n",
    "#Jim\n",
    "#begin, end = 9, 10\n",
    "#Thomas\n",
    "#begin, end = 3, 5\n",
    "#Mathilde\n",
    "#begin, end = 0, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T11:19:31.386010Z",
     "iopub.status.busy": "2021-03-05T11:19:31.385664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [20:33<00:00, 61.68s/trial, best loss: -0.8038906562402993]\n",
      "{0: {'RF': (0, {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}, 0.8038906562402993, 0.7911010101010101)}}\n",
      "{'LR_penalty': 'l1'}                                 \n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "\n",
    "combinations = ['RF','LR']\n",
    "\n",
    "for DAY in range(begin,end+1):\n",
    "    \n",
    "    X_preBurn, y_preBurn = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAY)\n",
    "    index = range(0, X_preBurn.shape[0])\n",
    "\n",
    "    X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "    y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "    #X_train_val = X.iloc[0:int(0.75*len(X))]\n",
    "    X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "    X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "\n",
    "    #y_train_val = y.iloc[0:int(0.75*len(y))]\n",
    "    y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "    y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "\n",
    "    #X_test_full = X.iloc[int(0.75*len(X)):]\n",
    "    #y_test_full = y.iloc[int(0.75*len(y)):]\n",
    "\n",
    "    output[DAY] = {}\n",
    "\n",
    "    for combination in combinations:\n",
    "        \n",
    "        if combination == 'RF':\n",
    "            n_trials = 20\n",
    "        elif combination == 'LR':\n",
    "            n_trials = 2\n",
    "\n",
    "        best_param, f1, accuracy = flat_hyperopt(flat_get_hyperspace(combination), X_train, y_train, X_val, y_val, n_trials)\n",
    "\n",
    "        output[DAY][str(combination)] = (DAY, best_param, f1, accuracy)\n",
    "        print(output)\n",
    "\n",
    "        with open('/Users/LV/Desktop/flat_validation.json', 'w') as f:\n",
    "            json.dump(output, f, cls = NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:10:46.525663Z",
     "iopub.status.busy": "2021-03-07T16:10:46.525384Z",
     "iopub.status.idle": "2021-03-07T16:10:46.535091Z",
     "shell.execute_reply": "2021-03-07T16:10:46.533742Z",
     "shell.execute_reply.started": "2021-03-07T16:10:46.525633Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/LV/Desktop/Statistics/Flat/flat_validation_0_2.json') as f:\n",
    "    val1 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Statistics/Flat/flat_validation_3_5.json') as f:\n",
    "    val2 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Statistics/Flat/flat_validation_6_8.json') as f:\n",
    "    val3 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Statistics/Flat/flat_validation_9_10.json') as f:\n",
    "    val4 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T16:33:50.903739Z",
     "iopub.status.busy": "2021-03-07T16:33:50.903450Z",
     "iopub.status.idle": "2021-03-07T16:33:50.935323Z",
     "shell.execute_reply": "2021-03-07T16:33:50.933667Z",
     "shell.execute_reply.started": "2021-03-07T16:33:50.903708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 40.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 40.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 40.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "      <td>{'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 1}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "      <td>{'LR_penalty': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  1  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  2  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 40.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  3  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  4  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 40.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  5  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  6  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 40.0}   \n",
       "LR                                {'LR_penalty': 1}   \n",
       "\n",
       "                                                  7  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  8  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                  9  \\\n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}   \n",
       "LR                                {'LR_penalty': 0}   \n",
       "\n",
       "                                                 10  \n",
       "RF  {'RF_max_depth': 14.0, 'RF_n_estimators': 45.0}  \n",
       "LR                                {'LR_penalty': 0}  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = {**val1, **val2, **val3, **val4}\n",
    "validation = pd.DataFrame.from_dict(validation)\n",
    "for i in range(11):\n",
    "    validation[str(i)] = validation[str(i)].apply(lambda x: x[1])\n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Validation (Static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:24:33.146819Z",
     "iopub.status.busy": "2021-02-24T20:24:33.146548Z",
     "iopub.status.idle": "2021-02-24T20:24:50.393511Z",
     "shell.execute_reply": "2021-02-24T20:24:50.390304Z",
     "shell.execute_reply.started": "2021-02-24T20:24:33.146795Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_ contains a sample of training + validation data\n",
    "random.seed(100)\n",
    "df_ = df.iloc[:int(0.8*len(df))].sample(n=1100000, replace=False, random_state=1).sort_values(by = 'orderDate').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-24T20:24:50.401425Z",
     "iopub.status.busy": "2021-02-24T20:24:50.400070Z",
     "iopub.status.idle": "2021-02-24T20:24:50.510963Z",
     "shell.execute_reply": "2021-02-24T20:24:50.509739Z",
     "shell.execute_reply.started": "2021-02-24T20:24:50.401369Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderDate</th>\n",
       "      <th>productId</th>\n",
       "      <th>sellerId</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>quantityOrdered</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>cancellationDate</th>\n",
       "      <th>cancellationReasonCode</th>\n",
       "      <th>promisedDeliveryDate</th>\n",
       "      <th>shipmentDate</th>\n",
       "      <th>transporterCode</th>\n",
       "      <th>transporterName</th>\n",
       "      <th>transporterNameOther</th>\n",
       "      <th>dateTimeFirstDeliveryMoment</th>\n",
       "      <th>fulfilmentType</th>\n",
       "      <th>startDateCase</th>\n",
       "      <th>cntDistinctCaseIds</th>\n",
       "      <th>returnDateTime</th>\n",
       "      <th>quantityReturned</th>\n",
       "      <th>returnCode</th>\n",
       "      <th>productTitle</th>\n",
       "      <th>brickName</th>\n",
       "      <th>chunkName</th>\n",
       "      <th>productGroup</th>\n",
       "      <th>productSubGroup</th>\n",
       "      <th>productSubSubGroup</th>\n",
       "      <th>registrationDateSeller</th>\n",
       "      <th>countryOriginSeller</th>\n",
       "      <th>currentCountryAvailabilitySeller</th>\n",
       "      <th>calculationDefinitive</th>\n",
       "      <th>noCancellation</th>\n",
       "      <th>onTimeDelivery</th>\n",
       "      <th>noCase</th>\n",
       "      <th>hasOneCase</th>\n",
       "      <th>hasMoreCases</th>\n",
       "      <th>noReturn</th>\n",
       "      <th>detailedMatchClassification</th>\n",
       "      <th>generalMatchClassification</th>\n",
       "      <th>caseDays</th>\n",
       "      <th>returnDays</th>\n",
       "      <th>cancellationDays</th>\n",
       "      <th>actualDeliveryDays</th>\n",
       "      <th>shipmentDays</th>\n",
       "      <th>partnerSellingDays</th>\n",
       "      <th>promisedDeliveryDays</th>\n",
       "      <th>orderYear</th>\n",
       "      <th>orderMonth</th>\n",
       "      <th>orderWeekday</th>\n",
       "      <th>orderCorona</th>\n",
       "      <th>orderMonday</th>\n",
       "      <th>orderTuesday</th>\n",
       "      <th>orderWednesday</th>\n",
       "      <th>orderThursday</th>\n",
       "      <th>orderFriday</th>\n",
       "      <th>orderSaturday</th>\n",
       "      <th>orderSunday</th>\n",
       "      <th>orderJanuary</th>\n",
       "      <th>orderFebruary</th>\n",
       "      <th>orderMarch</th>\n",
       "      <th>orderApril</th>\n",
       "      <th>orderMay</th>\n",
       "      <th>orderJune</th>\n",
       "      <th>orderJuly</th>\n",
       "      <th>orderAugust</th>\n",
       "      <th>orderSeptember</th>\n",
       "      <th>orderOctober</th>\n",
       "      <th>orderNovember</th>\n",
       "      <th>orderDecember</th>\n",
       "      <th>orderYear2020</th>\n",
       "      <th>productTitleLength</th>\n",
       "      <th>fulfilmentByBol</th>\n",
       "      <th>countryCodeNL</th>\n",
       "      <th>countryOriginNL</th>\n",
       "      <th>countryOriginBE</th>\n",
       "      <th>countryOriginDE</th>\n",
       "      <th>determinantClassification</th>\n",
       "      <th>binaryMatchClassification</th>\n",
       "      <th>transporterCodeGeneral</th>\n",
       "      <th>productGroupGeneral</th>\n",
       "      <th>groupHealth</th>\n",
       "      <th>groupHome</th>\n",
       "      <th>groupSports</th>\n",
       "      <th>groupComputer</th>\n",
       "      <th>groupPets</th>\n",
       "      <th>groupToys</th>\n",
       "      <th>groupBooks</th>\n",
       "      <th>groupBaby</th>\n",
       "      <th>groupMusic</th>\n",
       "      <th>groupFood</th>\n",
       "      <th>groupOffice</th>\n",
       "      <th>groupFashion</th>\n",
       "      <th>groupOther</th>\n",
       "      <th>groupCar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000084842057</td>\n",
       "      <td>1003805</td>\n",
       "      <td>3.662279</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 10:54:16</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YONO Aroma Diffuser Luchtbevochtiger 400ml – V...</td>\n",
       "      <td>Oliediffusors (Niet-elektrisch)</td>\n",
       "      <td>Aromadiffuser</td>\n",
       "      <td>Health PG</td>\n",
       "      <td>Ontspanning</td>\n",
       "      <td>Aromatherapie</td>\n",
       "      <td>2014-11-10</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1513</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>155</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Health &amp; Care</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000102226038</td>\n",
       "      <td>1377785</td>\n",
       "      <td>2.638343</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 08:41:01</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby fruitspeen – Gezonde speen – Roze – Duopack</td>\n",
       "      <td>Fopspenen/Bijtringen</td>\n",
       "      <td>Fopspeen</td>\n",
       "      <td>Baby PG</td>\n",
       "      <td>Eten en Drinken Baby</td>\n",
       "      <td>Babyvoeding Accessoires</td>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Baby &amp; Kids</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000082827166</td>\n",
       "      <td>1159544</td>\n",
       "      <td>2.830268</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT_BRIEF</td>\n",
       "      <td>PostNL Briefpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 14:13:40</td>\n",
       "      <td>FBB</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fosco Zakmes - Zwart - 19.5cm - 100% Metaal</td>\n",
       "      <td>Hobbymessen (Niet-elektrisch)</td>\n",
       "      <td>Zakmes</td>\n",
       "      <td>Camping and Outdoor</td>\n",
       "      <td>Outdooruitrusting</td>\n",
       "      <td>Outdooruitrusting</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1025</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>BRIEF</td>\n",
       "      <td>Sports, Outdoor &amp; Travel</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000086651881</td>\n",
       "      <td>1134056</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>TNT</td>\n",
       "      <td>PostNL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03 07:20:01</td>\n",
       "      <td>FBR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Premium Starter Kit XL voor Nintendo Switch (m...</td>\n",
       "      <td>Spelcomputer – Accessoires</td>\n",
       "      <td>Console start- of accessoirepakket</td>\n",
       "      <td>Games Accessories</td>\n",
       "      <td>Games Accessories</td>\n",
       "      <td>Games Accessories</td>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1114</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>153</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>All good</td>\n",
       "      <td>KNOWN</td>\n",
       "      <td>POSTNL</td>\n",
       "      <td>Music, Film &amp; Games</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>9200000043474064</td>\n",
       "      <td>829931</td>\n",
       "      <td>2.297573</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>BRIEFPOST</td>\n",
       "      <td>Briefpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>FBR</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zwart S-line TPU hoesje LG G4</td>\n",
       "      <td>Hoesjes voor Mobiele Telefoon</td>\n",
       "      <td>Hoesje voor mobiele telefoon</td>\n",
       "      <td>Telephone and Tablet Accessories</td>\n",
       "      <td>Telefonie en Tablet Bescherming</td>\n",
       "      <td>Telefonie Bescherming</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>NL</td>\n",
       "      <td>NL</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown delivery</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BRIEF</td>\n",
       "      <td>Computer &amp; Electronics</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orderDate         productId  sellerId  totalPrice  quantityOrdered  \\\n",
       "0 2019-01-01  9200000084842057   1003805    3.662279                1   \n",
       "1 2019-01-01  9200000102226038   1377785    2.638343                1   \n",
       "2 2019-01-01  9200000082827166   1159544    2.830268                1   \n",
       "3 2019-01-01  9200000086651881   1134056    3.314186                1   \n",
       "4 2019-01-01  9200000043474064    829931    2.297573                1   \n",
       "\n",
       "  countryCode cancellationDate cancellationReasonCode promisedDeliveryDate  \\\n",
       "0          BE              NaT                    NaN           2019-01-03   \n",
       "1          NL              NaT                    NaN           2019-01-03   \n",
       "2          NL              NaT                    NaN           2019-01-08   \n",
       "3          NL              NaT                    NaN           2019-01-03   \n",
       "4          NL              NaT                    NaN           2019-01-03   \n",
       "\n",
       "  shipmentDate transporterCode   transporterName transporterNameOther  \\\n",
       "0   2019-01-02             TNT            PostNL                  NaN   \n",
       "1   2019-01-02             TNT            PostNL                  NaN   \n",
       "2   2019-01-02       TNT_BRIEF  PostNL Briefpost                  NaN   \n",
       "3   2019-01-02             TNT            PostNL                  NaN   \n",
       "4   2019-01-02       BRIEFPOST         Briefpost                  NaN   \n",
       "\n",
       "  dateTimeFirstDeliveryMoment fulfilmentType startDateCase  \\\n",
       "0         2019-01-03 10:54:16            FBB           NaT   \n",
       "1         2019-01-03 08:41:01            FBB           NaT   \n",
       "2         2019-01-03 14:13:40            FBB           NaT   \n",
       "3         2019-01-03 07:20:01            FBR           NaT   \n",
       "4                         NaT            FBR           NaT   \n",
       "\n",
       "   cntDistinctCaseIds returnDateTime  quantityReturned returnCode  \\\n",
       "0                 NaN            NaT               NaN        NaN   \n",
       "1                 NaN            NaT               NaN        NaN   \n",
       "2                 NaN            NaT               NaN        NaN   \n",
       "3                 NaN            NaT               NaN        NaN   \n",
       "4                 NaN            NaT               NaN        NaN   \n",
       "\n",
       "                                        productTitle  \\\n",
       "0  YONO Aroma Diffuser Luchtbevochtiger 400ml – V...   \n",
       "1   Baby fruitspeen – Gezonde speen – Roze – Duopack   \n",
       "2        Fosco Zakmes - Zwart - 19.5cm - 100% Metaal   \n",
       "3  Premium Starter Kit XL voor Nintendo Switch (m...   \n",
       "4                      Zwart S-line TPU hoesje LG G4   \n",
       "\n",
       "                         brickName                           chunkName  \\\n",
       "0  Oliediffusors (Niet-elektrisch)                       Aromadiffuser   \n",
       "1             Fopspenen/Bijtringen                            Fopspeen   \n",
       "2    Hobbymessen (Niet-elektrisch)                              Zakmes   \n",
       "3       Spelcomputer – Accessoires  Console start- of accessoirepakket   \n",
       "4    Hoesjes voor Mobiele Telefoon        Hoesje voor mobiele telefoon   \n",
       "\n",
       "                       productGroup                  productSubGroup  \\\n",
       "0                         Health PG                      Ontspanning   \n",
       "1                           Baby PG             Eten en Drinken Baby   \n",
       "2               Camping and Outdoor                Outdooruitrusting   \n",
       "3                 Games Accessories                Games Accessories   \n",
       "4  Telephone and Tablet Accessories  Telefonie en Tablet Bescherming   \n",
       "\n",
       "        productSubSubGroup registrationDateSeller countryOriginSeller  \\\n",
       "0            Aromatherapie             2014-11-10                  NL   \n",
       "1  Babyvoeding Accessoires             2018-08-12                  NL   \n",
       "2        Outdooruitrusting             2016-03-12                  NL   \n",
       "3        Games Accessories             2015-12-14                  NL   \n",
       "4    Telefonie Bescherming             2013-07-31                  NL   \n",
       "\n",
       "  currentCountryAvailabilitySeller  calculationDefinitive  noCancellation  \\\n",
       "0                               NL                   True            True   \n",
       "1                               NL                   True            True   \n",
       "2                               NL                   True            True   \n",
       "3                               NL                   True            True   \n",
       "4                               NL                   True            True   \n",
       "\n",
       "  onTimeDelivery  noCase  hasOneCase  hasMoreCases  noReturn  \\\n",
       "0           True    True         0.0           0.0      True   \n",
       "1           True    True         0.0           0.0      True   \n",
       "2           True    True         0.0           0.0      True   \n",
       "3           True    True         0.0           0.0      True   \n",
       "4            NaN    True         0.0           0.0      True   \n",
       "\n",
       "  detailedMatchClassification generalMatchClassification  caseDays  \\\n",
       "0                       HAPPY                      HAPPY       NaN   \n",
       "1                       HAPPY                      HAPPY       NaN   \n",
       "2                       HAPPY                      HAPPY       NaN   \n",
       "3                       HAPPY                      HAPPY       NaN   \n",
       "4                     UNKNOWN                    UNKNOWN       NaN   \n",
       "\n",
       "   returnDays  cancellationDays  actualDeliveryDays  shipmentDays  \\\n",
       "0         NaN               NaN                 2.0           1.0   \n",
       "1         NaN               NaN                 2.0           1.0   \n",
       "2         NaN               NaN                 2.0           1.0   \n",
       "3         NaN               NaN                 2.0           1.0   \n",
       "4         NaN               NaN                 NaN           1.0   \n",
       "\n",
       "   partnerSellingDays  promisedDeliveryDays  orderYear  orderMonth  \\\n",
       "0                1513                     2       2019           1   \n",
       "1                 142                     2       2019           1   \n",
       "2                1025                     7       2019           1   \n",
       "3                1114                     2       2019           1   \n",
       "4                1980                     2       2019           1   \n",
       "\n",
       "   orderWeekday  orderCorona  orderMonday  orderTuesday  orderWednesday  \\\n",
       "0             1        False        False          True           False   \n",
       "1             1        False        False          True           False   \n",
       "2             1        False        False          True           False   \n",
       "3             1        False        False          True           False   \n",
       "4             1        False        False          True           False   \n",
       "\n",
       "   orderThursday  orderFriday  orderSaturday  orderSunday  orderJanuary  \\\n",
       "0          False        False          False        False          True   \n",
       "1          False        False          False        False          True   \n",
       "2          False        False          False        False          True   \n",
       "3          False        False          False        False          True   \n",
       "4          False        False          False        False          True   \n",
       "\n",
       "   orderFebruary  orderMarch  orderApril  orderMay  orderJune  orderJuly  \\\n",
       "0          False       False       False     False      False      False   \n",
       "1          False       False       False     False      False      False   \n",
       "2          False       False       False     False      False      False   \n",
       "3          False       False       False     False      False      False   \n",
       "4          False       False       False     False      False      False   \n",
       "\n",
       "   orderAugust  orderSeptember  orderOctober  orderNovember  orderDecember  \\\n",
       "0        False           False         False          False          False   \n",
       "1        False           False         False          False          False   \n",
       "2        False           False         False          False          False   \n",
       "3        False           False         False          False          False   \n",
       "4        False           False         False          False          False   \n",
       "\n",
       "   orderYear2020  productTitleLength  fulfilmentByBol  countryCodeNL  \\\n",
       "0          False                 155             True          False   \n",
       "1          False                  48             True           True   \n",
       "2          False                  43             True           True   \n",
       "3          False                 153            False           True   \n",
       "4          False                  29            False           True   \n",
       "\n",
       "   countryOriginNL  countryOriginBE  countryOriginDE  \\\n",
       "0             True            False            False   \n",
       "1             True            False            False   \n",
       "2             True            False            False   \n",
       "3             True            False            False   \n",
       "4             True            False            False   \n",
       "\n",
       "  determinantClassification binaryMatchClassification transporterCodeGeneral  \\\n",
       "0                  All good                     KNOWN                 POSTNL   \n",
       "1                  All good                     KNOWN                 POSTNL   \n",
       "2                  All good                     KNOWN                  BRIEF   \n",
       "3                  All good                     KNOWN                 POSTNL   \n",
       "4          Unknown delivery                   UNKNOWN                  BRIEF   \n",
       "\n",
       "        productGroupGeneral  groupHealth  groupHome  groupSports  \\\n",
       "0             Health & Care         True      False        False   \n",
       "1               Baby & Kids        False      False        False   \n",
       "2  Sports, Outdoor & Travel        False      False         True   \n",
       "3       Music, Film & Games        False      False        False   \n",
       "4    Computer & Electronics        False      False        False   \n",
       "\n",
       "   groupComputer  groupPets  groupToys  groupBooks  groupBaby  groupMusic  \\\n",
       "0          False      False      False       False      False       False   \n",
       "1          False      False      False       False       True       False   \n",
       "2          False      False      False       False      False       False   \n",
       "3          False      False      False       False      False        True   \n",
       "4           True      False      False       False      False       False   \n",
       "\n",
       "   groupFood  groupOffice  groupFashion  groupOther  groupCar  \n",
       "0      False        False         False       False     False  \n",
       "1      False        False         False       False     False  \n",
       "2      False        False         False       False     False  \n",
       "3      False        False         False       False     False  \n",
       "4      False        False         False       False     False  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T20:27:36.613118Z",
     "iopub.status.busy": "2021-02-24T20:27:36.612825Z",
     "iopub.status.idle": "2021-02-24T20:27:36.620102Z",
     "shell.execute_reply": "2021-02-24T20:27:36.618385Z",
     "shell.execute_reply.started": "2021-02-24T20:27:36.613086Z"
    }
   },
   "outputs": [],
   "source": [
    "Tree = ClassHierarchy('ORDERS')\n",
    "Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "# combinations = [('RF','DT','NN'),('DT','RF','NN'),\n",
    "#                 ('RF','DT','DT'),('DT','RF','DT'),\n",
    "#                 ('RF','DT','RF'),('DT','RF','RF')]\n",
    "\n",
    "combinations = [('LR','RF','RF'),('RF','LR','LR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T09:54:32.864251Z",
     "iopub.status.busy": "2021-02-26T09:54:32.862345Z",
     "iopub.status.idle": "2021-02-26T09:54:32.888097Z",
     "shell.execute_reply": "2021-02-26T09:54:32.883764Z",
     "shell.execute_reply.started": "2021-02-26T09:54:32.864157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,11):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T08:31:20.055572Z",
     "iopub.status.busy": "2021-02-19T08:31:20.055018Z",
     "iopub.status.idle": "2021-02-19T08:31:52.407681Z",
     "shell.execute_reply": "2021-02-19T08:31:52.406890Z",
     "shell.execute_reply.started": "2021-02-19T08:31:20.055511Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_preBurn, y_preBurn = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 0)\n",
    "index = range(0, X_preBurn.shape[0])\n",
    "\n",
    "X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "#X_train_val = X.iloc[0:int(0.75*len(X))]\n",
    "X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "       \n",
    "#y_train_val = y.iloc[0:int(0.75*len(y))]\n",
    "y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "\n",
    "#X_test_full = X.iloc[int(0.75*len(X)):]\n",
    "#y_test_full = y.iloc[int(0.75*len(y)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T09:56:09.891484Z",
     "iopub.status.busy": "2021-02-26T09:56:09.891191Z",
     "iopub.status.idle": "2021-02-26T14:22:15.575481Z",
     "shell.execute_reply": "2021-02-26T14:22:15.567619Z",
     "shell.execute_reply.started": "2021-02-26T09:56:09.891459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [39:10<00:00, 117.53s/trial, best loss: -0.9852817062604355]\n",
      "100%|██████████| 20/20 [3:45:08<00:00, 675.44s/trial, best loss: -0.9804503807902645]  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "output = {}\n",
    "\n",
    "for DAY in range(10,11):\n",
    "    \n",
    "    X_preBurn, y_preBurn = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAY)\n",
    "    index = range(0, X_preBurn.shape[0])\n",
    "\n",
    "    X_train_val = X_preBurn.iloc[int(0.1*len(X_preBurn)):]\n",
    "    y_train_val = y_preBurn.iloc[int(0.1*len(y_preBurn)):]\n",
    "\n",
    "    #X_train_val = X.iloc[0:int(0.75*len(X))]\n",
    "    X_train = X_train_val.iloc[0:int(0.8*len(X_train_val))]\n",
    "    X_val = X_train_val.iloc[int(0.8*len(X_train_val)):]\n",
    "\n",
    "    #y_train_val = y.iloc[0:int(0.75*len(y))]\n",
    "    y_train = y_train_val.iloc[0:int(0.8*len(y_train_val))]\n",
    "    y_val = y_train_val.iloc[int(0.8*len(y_train_val)):]\n",
    "\n",
    "    #X_test_full = X.iloc[int(0.75*len(X)):]\n",
    "    #y_test_full = y.iloc[int(0.75*len(y)):]\n",
    "\n",
    "    output[DAY] = {}\n",
    "\n",
    "    for combination in combinations:\n",
    "\n",
    "        best_param, f1, accuracy = hyperopt(get_hyperspace(combination), X_train, y_train, X_val, y_val, 20)\n",
    "\n",
    "        output[DAY][str(combination)] = (DAY, best_param, f1, accuracy)\n",
    "\n",
    "        with open('/Users/LV/Desktop/validationPart3.json', 'w') as f:\n",
    "            json.dump(output, f, cls = NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T11:15:33.450204Z",
     "iopub.status.busy": "2021-02-21T11:15:33.448320Z",
     "iopub.status.idle": "2021-02-21T11:15:33.510769Z",
     "shell.execute_reply": "2021-02-21T11:15:33.509102Z",
     "shell.execute_reply.started": "2021-02-21T11:15:33.450093Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/LV/Desktop/Validation/validation1.json') as f:\n",
    "    results1 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Validation/validation2.json') as f:\n",
    "    results2 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Validation/validation3.json') as f:\n",
    "    results3 = json.load(f)\n",
    "with open('/Users/LV/Desktop/Validation/validation4.json') as f:\n",
    "    results4 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-21T12:14:17.662425Z",
     "iopub.status.busy": "2021-02-21T12:14:17.662130Z",
     "iopub.status.idle": "2021-02-21T12:14:17.820882Z",
     "shell.execute_reply": "2021-02-21T12:14:17.820156Z",
     "shell.execute_reply.started": "2021-02-21T12:14:17.662398Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'DT')</th>\n",
       "      <td>0.854815</td>\n",
       "      <td>0.876907</td>\n",
       "      <td>0.894954</td>\n",
       "      <td>0.920188</td>\n",
       "      <td>0.936639</td>\n",
       "      <td>0.954157</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>0.971652</td>\n",
       "      <td>0.976273</td>\n",
       "      <td>0.980445</td>\n",
       "      <td>0.981540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'RF')</th>\n",
       "      <td>0.851265</td>\n",
       "      <td>0.871202</td>\n",
       "      <td>0.896070</td>\n",
       "      <td>0.921924</td>\n",
       "      <td>0.937989</td>\n",
       "      <td>0.954333</td>\n",
       "      <td>0.963244</td>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.976259</td>\n",
       "      <td>0.977721</td>\n",
       "      <td>0.981673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'RF')</th>\n",
       "      <td>0.851975</td>\n",
       "      <td>0.879984</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.920837</td>\n",
       "      <td>0.942735</td>\n",
       "      <td>0.955765</td>\n",
       "      <td>0.967191</td>\n",
       "      <td>0.974183</td>\n",
       "      <td>0.979108</td>\n",
       "      <td>0.981989</td>\n",
       "      <td>0.984803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'DT')</th>\n",
       "      <td>0.845037</td>\n",
       "      <td>0.865596</td>\n",
       "      <td>0.896348</td>\n",
       "      <td>0.914484</td>\n",
       "      <td>0.939641</td>\n",
       "      <td>0.954634</td>\n",
       "      <td>0.964196</td>\n",
       "      <td>0.970961</td>\n",
       "      <td>0.975027</td>\n",
       "      <td>0.978087</td>\n",
       "      <td>0.981287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'DT')</th>\n",
       "      <td>0.849603</td>\n",
       "      <td>0.881825</td>\n",
       "      <td>0.899603</td>\n",
       "      <td>0.921985</td>\n",
       "      <td>0.942769</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.973198</td>\n",
       "      <td>0.977740</td>\n",
       "      <td>0.980778</td>\n",
       "      <td>0.983854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'RF')</th>\n",
       "      <td>0.840994</td>\n",
       "      <td>0.863138</td>\n",
       "      <td>0.891179</td>\n",
       "      <td>0.914802</td>\n",
       "      <td>0.939100</td>\n",
       "      <td>0.954785</td>\n",
       "      <td>0.965408</td>\n",
       "      <td>0.971422</td>\n",
       "      <td>0.976147</td>\n",
       "      <td>0.979192</td>\n",
       "      <td>0.981252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'DT')</th>\n",
       "      <td>0.843224</td>\n",
       "      <td>0.866109</td>\n",
       "      <td>0.895169</td>\n",
       "      <td>0.916512</td>\n",
       "      <td>0.939995</td>\n",
       "      <td>0.955726</td>\n",
       "      <td>0.966212</td>\n",
       "      <td>0.973129</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.980805</td>\n",
       "      <td>0.983939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'RF')</th>\n",
       "      <td>0.839108</td>\n",
       "      <td>0.862149</td>\n",
       "      <td>0.892034</td>\n",
       "      <td>0.918828</td>\n",
       "      <td>0.940897</td>\n",
       "      <td>0.957314</td>\n",
       "      <td>0.967233</td>\n",
       "      <td>0.974205</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.982009</td>\n",
       "      <td>0.984831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1         2         3         4  \\\n",
       "('RF', 'DT', 'DT')  0.854815  0.876907  0.894954  0.920188  0.936639   \n",
       "('RF', 'DT', 'RF')  0.851265  0.871202  0.896070  0.921924  0.937989   \n",
       "('DT', 'DT', 'RF')  0.851975  0.879984  0.899471  0.920837  0.942735   \n",
       "('RF', 'RF', 'DT')  0.845037  0.865596  0.896348  0.914484  0.939641   \n",
       "('DT', 'DT', 'DT')  0.849603  0.881825  0.899603  0.921985  0.942769   \n",
       "('RF', 'RF', 'RF')  0.840994  0.863138  0.891179  0.914802  0.939100   \n",
       "('DT', 'RF', 'DT')  0.843224  0.866109  0.895169  0.916512  0.939995   \n",
       "('DT', 'RF', 'RF')  0.839108  0.862149  0.892034  0.918828  0.940897   \n",
       "\n",
       "                           5         6         7         8         9        10  \n",
       "('RF', 'DT', 'DT')  0.954157  0.966417  0.971652  0.976273  0.980445  0.981540  \n",
       "('RF', 'DT', 'RF')  0.954333  0.963244  0.968697  0.976259  0.977721  0.981673  \n",
       "('DT', 'DT', 'RF')  0.955765  0.967191  0.974183  0.979108  0.981989  0.984803  \n",
       "('RF', 'RF', 'DT')  0.954634  0.964196  0.970961  0.975027  0.978087  0.981287  \n",
       "('DT', 'DT', 'DT')  0.956585  0.966699  0.973198  0.977740  0.980778  0.983854  \n",
       "('RF', 'RF', 'RF')  0.954785  0.965408  0.971422  0.976147  0.979192  0.981252  \n",
       "('DT', 'RF', 'DT')  0.955726  0.966212  0.973129  0.978035  0.980805  0.983939  \n",
       "('DT', 'RF', 'RF')  0.957314  0.967233  0.974205  0.979100  0.982009  0.984831  "
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame.from_dict(results1)\n",
    "results_df2 = pd.DataFrame.from_dict(results2)\n",
    "results_df3 = pd.DataFrame.from_dict(results3)\n",
    "results_df4 = pd.DataFrame.from_dict(results4)\n",
    "for i in range(11):\n",
    "    results_df1[str(i)] = results_df1[str(i)].apply(lambda x: x[2])\n",
    "    results_df2[str(i)] = results_df2[str(i)].apply(lambda x: x[2])\n",
    "    results_df3[str(i)] = results_df3[str(i)].apply(lambda x: x[1])\n",
    "    results_df4[str(i)] = results_df4[str(i)].apply(lambda x: x[2])\n",
    "results_df = pd.concat([results_df1,results_df2,results_df3,results_df4])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-21T12:08:56.509253Z",
     "iopub.status.busy": "2021-02-21T12:08:56.508999Z",
     "iopub.status.idle": "2021-02-21T12:08:56.655176Z",
     "shell.execute_reply": "2021-02-21T12:08:56.650017Z",
     "shell.execute_reply.started": "2021-02-21T12:08:56.509230Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'DT')</th>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'DT', 'RF')</th>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'RF')</th>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'DT')</th>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 14.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_2': 0, 'DT_max_depth_2': 6.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'DT', 'DT')</th>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('RF', 'RF', 'RF')</th>\n",
       "      <td>{'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...</td>\n",
       "      <td>{'RF_max_depth_0': 12.0, 'RF_max_depth_1': 11....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...</td>\n",
       "      <td>{'RF_max_depth_0': 14.0, 'RF_max_depth_1': 9.0...</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 10.0, 'RF_max_depth_1': 9.0...</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "      <td>{'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'DT')</th>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_criterion_2': 0, 'DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('DT', 'RF', 'RF')</th>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_max_depth_0': 14.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...</td>\n",
       "      <td>{'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...   \n",
       "\n",
       "                                                                    1  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 0, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 12.0, 'RF_max_depth_1': 11....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...   \n",
       "\n",
       "                                                                    2  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 0, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...   \n",
       "\n",
       "                                                                    3  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 9.0, 'RF_max_depth_1': 14.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 9.0, '...   \n",
       "\n",
       "                                                                    4  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 14.0, 'RF_max_depth_1': 9.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 0, 'DT_max_depth_0': 14.0, ...   \n",
       "\n",
       "                                                                    5  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 6.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 9.0, '...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 11.0, ...   \n",
       "\n",
       "                                                                    6  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 0, 'DT_max_depth_0': 9.0, '...   \n",
       "\n",
       "                                                                    7  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 14.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...   \n",
       "\n",
       "                                                                    8  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 10.0, 'RF_max_depth_1': 9.0...   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 7.0, '...   \n",
       "\n",
       "                                                                    9  \\\n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 0, 'DT_max_depth_1': 9.0, '...   \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...   \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 1, 'DT_max_depth_2': 10.0, ...   \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 0, 'DT...   \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....   \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_2': 1, 'DT...   \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...   \n",
       "\n",
       "                                                                   10  \n",
       "('RF', 'DT', 'DT')  {'DT_criterion_1': 1, 'DT_criterion_2': 0, 'DT...  \n",
       "('RF', 'DT', 'RF')  {'DT_criterion_1': 1, 'DT_max_depth_1': 10.0, ...  \n",
       "('DT', 'DT', 'RF')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...  \n",
       "('RF', 'RF', 'DT')  {'DT_criterion_2': 0, 'DT_max_depth_2': 6.0, '...  \n",
       "('DT', 'DT', 'DT')  {'DT_criterion_0': 1, 'DT_criterion_1': 1, 'DT...  \n",
       "('RF', 'RF', 'RF')  {'RF_max_depth_0': 13.0, 'RF_max_depth_1': 10....  \n",
       "('DT', 'RF', 'DT')  {'DT_criterion_0': 0, 'DT_criterion_2': 0, 'DT...  \n",
       "('DT', 'RF', 'RF')  {'DT_criterion_0': 1, 'DT_max_depth_0': 10.0, ...  "
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame.from_dict(results1)\n",
    "results_df2 = pd.DataFrame.from_dict(results2)\n",
    "results_df3 = pd.DataFrame.from_dict(results3)\n",
    "results_df4 = pd.DataFrame.from_dict(results4)\n",
    "for i in range(11):\n",
    "    results_df1[str(i)] = results_df1[str(i)].apply(lambda x: x[1])\n",
    "    results_df2[str(i)] = results_df2[str(i)].apply(lambda x: x[1])\n",
    "    results_df3[str(i)] = results_df3[str(i)].apply(lambda x: x[0])\n",
    "    results_df4[str(i)] = results_df4[str(i)].apply(lambda x: x[1])\n",
    "hypers_df = pd.concat([results_df1,results_df2,results_df3,results_df4])\n",
    "hypers_df\n",
    "#DTDTRF = hypers_df.reset_index().loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Hierarchy Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T13:54:54.032061Z",
     "iopub.status.busy": "2021-02-14T13:54:54.029871Z",
     "iopub.status.idle": "2021-02-14T13:54:54.062616Z",
     "shell.execute_reply": "2021-02-14T13:54:54.050111Z",
     "shell.execute_reply.started": "2021-02-14T13:54:54.031976Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "# classifier = RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = 10)\n",
    "# classifier = svm.LinearSVC(C=1, penalty=\"l1\", dual=False, class_weight = 'balanced')\n",
    "# classifier = HistGradientBoostingClassifier(random_state=0)\n",
    "# classifier = DecisionTreeClassifier(random_state=0, max_depth=10, class_weight='balanced')\n",
    "# classifier = KerasClassifier(build_fn = functions.neuralNetwork,epochs = 10,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-28T11:56:49.699169Z",
     "iopub.status.busy": "2021-02-28T11:56:49.698929Z",
     "iopub.status.idle": "2021-02-28T11:56:49.727968Z",
     "shell.execute_reply": "2021-02-28T11:56:49.725075Z",
     "shell.execute_reply.started": "2021-02-28T11:56:49.699146Z"
    }
   },
   "outputs": [],
   "source": [
    "Tree = ClassHierarchy('ORDERS')\n",
    "Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "HC = HierarchicalClassifier(Tree)\n",
    "# HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "#                     'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "#                     'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', n_estimators = 40, max_depth = 10)})\n",
    "HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced'),\n",
    "                            'KNOWN'   : LogisticRegression(random_state=0, class_weight='balanced'),\n",
    "                            'UNHAPPY' : LogisticRegression(random_state=0, class_weight='balanced')})\n",
    "\n",
    "THRESHOLDS = {'KNOWN'          :0.95,\n",
    "              'UNKNOWN'        :0.95,\n",
    "              'HAPPY'          :0.7,\n",
    "              'UNHAPPY'        :0.7,\n",
    "              'HEAVILY UNHAPPY':0.7,\n",
    "              'MEDIUM UNHAPPY' :0.8,\n",
    "              'MILDLY UNHAPPY' :0.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Single fit single point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T15:42:46.256732Z",
     "iopub.status.busy": "2021-02-24T15:42:46.256475Z",
     "iopub.status.idle": "2021-02-24T15:42:53.120397Z",
     "shell.execute_reply": "2021-02-24T15:42:53.119669Z",
     "shell.execute_reply.started": "2021-02-24T15:42:46.256709Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 0)\n",
    "index = range(0, X.shape[0])\n",
    "X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size = 0.2, random_state = 0, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T15:42:56.195458Z",
     "iopub.status.busy": "2021-02-24T15:42:56.195200Z",
     "iopub.status.idle": "2021-02-24T15:43:03.464818Z",
     "shell.execute_reply": "2021-02-24T15:43:03.463335Z",
     "shell.execute_reply.started": "2021-02-24T15:42:56.195433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDERS</th>\n",
       "      <th>KNOWN</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>HAPPY</th>\n",
       "      <th>UNHAPPY</th>\n",
       "      <th>HEAVILY UNHAPPY</th>\n",
       "      <th>MEDIUM UNHAPPY</th>\n",
       "      <th>MILDLY UNHAPPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973726</td>\n",
       "      <td>0.026274</td>\n",
       "      <td>0.674793</td>\n",
       "      <td>0.325207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907652</td>\n",
       "      <td>0.092348</td>\n",
       "      <td>0.553734</td>\n",
       "      <td>0.446266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972427</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>0.666976</td>\n",
       "      <td>0.333024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973924</td>\n",
       "      <td>0.026076</td>\n",
       "      <td>0.643522</td>\n",
       "      <td>0.356478</td>\n",
       "      <td>0.131056</td>\n",
       "      <td>0.236707</td>\n",
       "      <td>0.632237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444113</td>\n",
       "      <td>0.555887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962158</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.667667</td>\n",
       "      <td>0.332333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.137679</td>\n",
       "      <td>0.862321</td>\n",
       "      <td>0.811409</td>\n",
       "      <td>0.111217</td>\n",
       "      <td>0.077374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976305</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>0.672058</td>\n",
       "      <td>0.327942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105306</td>\n",
       "      <td>0.894694</td>\n",
       "      <td>0.177532</td>\n",
       "      <td>0.822468</td>\n",
       "      <td>0.382414</td>\n",
       "      <td>0.431204</td>\n",
       "      <td>0.186381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>0.913570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ORDERS     KNOWN   UNKNOWN     HAPPY   UNHAPPY  HEAVILY UNHAPPY  \\\n",
       "80000    NaN  0.973726  0.026274  0.674793  0.325207              NaN   \n",
       "80001    NaN  0.907652  0.092348  0.553734  0.446266              NaN   \n",
       "80002    NaN  0.972427  0.027573  0.666976  0.333024              NaN   \n",
       "80003    NaN  0.973924  0.026076  0.643522  0.356478         0.131056   \n",
       "80004    NaN  0.444113  0.555887       NaN       NaN              NaN   \n",
       "...      ...       ...       ...       ...       ...              ...   \n",
       "99995    NaN  0.962158  0.037842  0.667667  0.332333              NaN   \n",
       "99996    NaN  0.252000  0.748000  0.137679  0.862321         0.811409   \n",
       "99997    NaN  0.976305  0.023695  0.672058  0.327942              NaN   \n",
       "99998    NaN  0.105306  0.894694  0.177532  0.822468         0.382414   \n",
       "99999    NaN  0.086430  0.913570       NaN       NaN              NaN   \n",
       "\n",
       "       MEDIUM UNHAPPY  MILDLY UNHAPPY  \n",
       "80000             NaN             NaN  \n",
       "80001             NaN             NaN  \n",
       "80002             NaN             NaN  \n",
       "80003        0.236707        0.632237  \n",
       "80004             NaN             NaN  \n",
       "...               ...             ...  \n",
       "99995             NaN             NaN  \n",
       "99996        0.111217        0.077374  \n",
       "99997             NaN             NaN  \n",
       "99998        0.431204        0.186381  \n",
       "99999             NaN             NaN  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'UNKNOWN': 0.9545210531404656, 'KNOWN': 0.9874215652680951, #11761   #42\n",
    "HC = HC.fit(X_train,y_train)\n",
    "probs = HC.get_probabilities(X_test, y_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-18T17:03:14.646493Z",
     "iopub.status.busy": "2021-02-18T17:03:14.646075Z",
     "iopub.status.idle": "2021-02-18T17:03:14.944861Z",
     "shell.execute_reply": "2021-02-18T17:03:14.943787Z",
     "shell.execute_reply.started": "2021-02-18T17:03:14.646459Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4614711304590311"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score_ancestors(ch, y_test_internal['detailedMatchClassification'], pred_internal, beta=1)\n",
    "#precision_score_ancestors(ch, y_test_internal['detailedMatchClassification'], pred_internal)\n",
    "recall_score_ancestors(ch, y_test_internal['detailedMatchClassification'], pred_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-22T15:35:18.521412Z",
     "iopub.status.busy": "2021-02-22T15:35:18.521155Z",
     "iopub.status.idle": "2021-02-22T15:35:20.715792Z",
     "shell.execute_reply": "2021-02-22T15:35:20.708844Z",
     "shell.execute_reply.started": "2021-02-22T15:35:18.521386Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          HAPPY       0.89      0.24      0.38     27774\n",
      "HEAVILY UNHAPPY       0.87      0.12      0.21       535\n",
      "          KNOWN       0.00      0.00      0.00         0\n",
      " MEDIUM UNHAPPY       0.00      0.00      0.00       956\n",
      " MILDLY UNHAPPY       0.16      0.01      0.01      4453\n",
      "         ORDERS       0.00      0.00      0.00         0\n",
      "        UNHAPPY       0.00      0.00      0.00         0\n",
      "        UNKNOWN       0.90      0.74      0.81     16282\n",
      "\n",
      "       accuracy                           0.38     50000\n",
      "      macro avg       0.35      0.14      0.18     50000\n",
      "   weighted avg       0.81      0.38      0.48     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report(y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class_report(y_test['detailedMatchClassification'], pred)\n",
    "# global_scores(y_test['detailedMatchClassification'], pred)\n",
    "# local_scores(y_test['detailedMatchClassification'], pred)\n",
    "# precision_score_ancestors(ch, y_test['detailedMatchClassification'], pred)\n",
    "# recall_score_ancestors(ch, y_test['detailedMatchClassification'], pred)\n",
    "# f1_score_ancestors(ch, y_test['detailedMatchClassification'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T08:40:49.847357Z",
     "iopub.status.busy": "2021-02-24T08:40:49.840018Z",
     "iopub.status.idle": "2021-02-24T08:41:10.808475Z",
     "shell.execute_reply": "2021-02-24T08:41:10.807777Z",
     "shell.execute_reply.started": "2021-02-24T08:40:49.846959Z"
    }
   },
   "outputs": [],
   "source": [
    "hypers = pd.DataFrame({'1_criterion'   : ['entropy', 'gini',    'gini', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
    "                       '2_criterion'   : ['entropy', 'gini', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy'], \n",
    "                       '1_max_depth'   : [5,  6,  11, 11, 11, 11, 11,  5,  5,  5,  5],\n",
    "                       '2_max_depth'   : [6,  7,  11,  5,  5,  5,  5,  6,  6,  6,  6], \n",
    "                       '3_max_depth'   : [14, 10,  8,  9,  9,  9,  9, 14, 14, 14, 14],\n",
    "                       '3_n_estimators': [40, 30, 20, 45, 45, 45, 45, 40, 40, 40, 40]})\n",
    "\n",
    "day = 3\n",
    "HC = HierarchicalClassifier(Tree)\n",
    "HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '1_criterion'], max_depth = hypers.loc[day, '1_max_depth']),\n",
    "                    'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '2_criterion'], max_depth = hypers.loc[day, '2_max_depth']),\n",
    "                    'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[day, '3_max_depth'], n_estimators = hypers.loc[day, '3_n_estimators'])})\n",
    "\n",
    "X, y  = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, day)\n",
    "index = range(0, X.shape[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "HC.fit(X_train,y_train)\n",
    "y_hat = HC.get_probabilities(X_train, y_train)\n",
    "\n",
    "probs = pd.concat([y_train, y_hat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T09:04:57.287256Z",
     "iopub.status.busy": "2021-02-24T09:04:57.286777Z",
     "iopub.status.idle": "2021-02-24T09:04:57.651275Z",
     "shell.execute_reply": "2021-02-24T09:04:57.647529Z",
     "shell.execute_reply.started": "2021-02-24T09:04:57.287216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWx0lEQVR4nO3df4xd9Znf8fdncUOICSSBZEQxWTsNScOPriWPXKQoq6Fki5vNLmQFrVkUQ0LrBCXSrhZVge1KSRshkW5TVJTGqbMgQ3YXB4WwUBHSUNIpaQshJnFiIGEzBG8y2AIRKDD5QXecp3/c77B3xmPPeO6M79j3/ZKu7pnne77nnocz+ONzzr3XqSokSfq1fu+AJGl5MBAkSYCBIElqDARJEmAgSJKaFf3egYU6+eSTa/Xq1dNqP/vZz1i5cmV/dmgZGOT+B7l3GOz+B7l3OPT+H3744Wer6o2zjR2xgbB69Wp27NgxrTY6OsrIyEh/dmgZGOT+B7l3GOz+B7l3OPT+k/zNgca8ZCRJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCjuBPKktaPlZffXffXnvbhsH92orF5hmCJAkwECRJjYEgSQLmEQhJbkryTJJHumpfTLKzPXYn2dnqq5P8omvsc11z1iXZlWQsyQ1J0urHtu2NJflmktWL36YkaS7zOUPYBmzoLlTVv6iqtVW1Frgd+HLX8BNTY1X14a76FmAzcHp7TG3zCuD5qnorcD3wqYU0IknqzZyBUFX3A8/NNtb+lv/PgVsPto0kpwAnVNUDVVXALcCFbfgC4Oa2/CXgvKmzB0nS4dPr207fBTxdVT/sqq1J8h3gReBPquobwKnAeNc6461Ge/4JQFVNJnkBOAl4duaLJdlM5yyDoaEhRkdHp41PTEzsVxskg9z/IPcO/e//qrMn+/ba/e693xaz/14D4RKmnx3sBd5cVT9Nsg74qyRnArP9jb/a88HGphertgJbAYaHh2vmvxLkv5w0uP0Pcu/Q//4v7/PnEDz2I4uyrQUHQpIVwO8B66ZqVfUy8HJbfjjJE8Db6JwRrOqavgrY05bHgdOA8bbNEznAJSpJ0tLp5W2n7wZ+UFWvXApK8sYkx7Tlt9C5efyjqtoLvJTknHZ/YBNwZ5t2F3BZW74I+Hq7zyBJOozm87bTW4EHgLcnGU9yRRvayP43k38T+F6S79K5Qfzhqpr62/6VwJ8BY8ATwD2tfiNwUpIx4I+Aq3voR5K0QHNeMqqqSw5Qv3yW2u103oY62/o7gLNmqf8SuHiu/ZAkLS0/qSxJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSU2vX24nSQNpdR+/0G/3db+9JNv1DEGSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpGbOQEhyU5JnkjzSVftEkqeS7GyP93SNXZNkLMnjSc7vqq9LsquN3ZAkrX5ski+2+jeTrF7kHiVJ8zCfM4RtwIZZ6tdX1dr2+ApAkjOAjcCZbc5nkxzT1t8CbAZOb4+pbV4BPF9VbwWuBz61wF4kST2YMxCq6n7guXlu7wJge1W9XFVPAmPA+iSnACdU1QNVVcAtwIVdc25uy18Czps6e5AkHT69fNvpR5NsAnYAV1XV88CpwINd64y32t+25Zl12vNPAKpqMskLwEnAszNfMMlmOmcZDA0NMTo6Om18YmJiv9ogGeT+B7l36H//V5092bfX7lfv/ey5u9/F7H+hgbAF+CRQ7fnTwAeB2f5mXwepM8fY9GLVVmArwPDwcI2MjEwbHx0dZWZtkAxy/4PcO/S//8v7+FXQ2zas7Evv/ex596Ujrywv5rFf0LuMqurpqtpXVb8CPg+sb0PjwGldq64C9rT6qlnq0+YkWQGcyPwvUUmSFsmCAqHdE5jyPmDqHUh3ARvbO4fW0Ll5/FBV7QVeSnJOuz+wCbiza85lbfki4OvtPoMk6TCa85JRkluBEeDkJOPAx4GRJGvpXNrZDXwIoKoeTXIb8BgwCXykqva1TV1J5x1LxwH3tAfAjcAXkozROTPYuAh9SZIO0ZyBUFWXzFK+8SDrXwtcO0t9B3DWLPVfAhfPtR+SpKXlJ5UlSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSmjkDIclNSZ5J8khX7U+T/CDJ95LckeR1rb46yS+S7GyPz3XNWZdkV5KxJDckSasfm+SLrf7NJKsXv01J0lzmc4awDdgwo3YvcFZV/SPgr4FrusaeqKq17fHhrvoWYDNwentMbfMK4PmqeitwPfCpQ+5CktSzOQOhqu4HnptR+1pVTbYfHwRWHWwbSU4BTqiqB6qqgFuAC9vwBcDNbflLwHlTZw+SpMNnxSJs44PAF7t+XpPkO8CLwJ9U1TeAU4HxrnXGW432/BOAqppM8gJwEvDszBdKspnOWQZDQ0OMjo5OG5+YmNivNkgGuf9B7h363/9VZ0/OvdIS6Vfv/ey5u9/F7L+nQEjyb4BJ4C9aaS/w5qr6aZJ1wF8lOROY7W/8NbWZg4xNL1ZtBbYCDA8P18jIyLTx0dFRZtYGySD3P8i9Q//7v/zqu/v22ts2rOxL7/3sefelI68sL+axX3AgJLkMeC9wXrsMRFW9DLzclh9O8gTwNjpnBN2XlVYBe9ryOHAaMJ5kBXAiMy5RSZKW3oLedppkA/Ax4Her6udd9TcmOaYtv4XOzeMfVdVe4KUk57T7A5uAO9u0u4DL2vJFwNenAkaSdPjMeYaQ5FZgBDg5yTjwcTrvKjoWuLfd/32wvaPoN4F/l2QS2Ad8uKqm/rZ/JZ13LB0H3NMeADcCX0gyRufMYOOidCZJOiRzBkJVXTJL+cYDrHs7cPsBxnYAZ81S/yVw8Vz7IUlaWn5SWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAfMIhCQ3JXkmySNdtTckuTfJD9vz67vGrkkyluTxJOd31dcl2dXGbkiSVj82yRdb/ZtJVi9yj5KkeZjPGcI2YMOM2tXAfVV1OnBf+5kkZwAbgTPbnM8mOabN2QJsBk5vj6ltXgE8X1VvBa4HPrXQZiRJCzdnIFTV/cBzM8oXADe35ZuBC7vq26vq5ap6EhgD1ic5BTihqh6oqgJumTFnaltfAs6bOnuQJB0+C72HMFRVewHa85ta/VTgJ13rjbfaqW15Zn3anKqaBF4ATlrgfkmSFmjFIm9vtr/Z10HqB5uz/8aTzXQuOzE0NMTo6Oi08YmJif1qg2SQ+x/k3qH//V919mTfXrtfvfez5+5+F7P/hQbC00lOqaq97XLQM60+DpzWtd4qYE+rr5ql3j1nPMkK4ET2v0QFQFVtBbYCDA8P18jIyLTx0dFRZtYGySD3P8i9Q//7v/zqu/v22ts2rOxL7/3sefelI68sL+axX+glo7uAy9ryZcCdXfWN7Z1Da+jcPH6oXVZ6Kck57f7AphlzprZ1EfD1dp9BknQYzXmGkORWYAQ4Ock48HHgOuC2JFcAPwYuBqiqR5PcBjwGTAIfqap9bVNX0nnH0nHAPe0BcCPwhSRjdM4MNi5KZ5KkQzJnIFTVJQcYOu8A618LXDtLfQdw1iz1X9ICRZLUP35SWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKlZcCAkeXuSnV2PF5P8YZJPJHmqq/6erjnXJBlL8niS87vq65LsamM3JEmvjUmSDs2CA6GqHq+qtVW1FlgH/By4ow1fPzVWVV8BSHIGsBE4E9gAfDbJMW39LcBm4PT22LDQ/ZIkLcxiXTI6D3iiqv7mIOtcAGyvqper6klgDFif5BTghKp6oKoKuAW4cJH2S5I0TysWaTsbgVu7fv5okk3ADuCqqnoeOBV4sGud8Vb727Y8s76fJJvpnEkwNDTE6OjotPGJiYn9aoNkkPsf5N6h//1fdfZk3167X733s+fufhez/54DIcmrgN8FrmmlLcAngWrPnwY+CMx2X6AOUt+/WLUV2AowPDxcIyMj08ZHR0eZWRskg9z/IPcO/e//8qvv7ttrb9uwsi+997Pn3ZeOvLK8mMd+MS4Z/TPg21X1NEBVPV1V+6rqV8DngfVtvXHgtK55q4A9rb5qlrok6TBajEC4hK7LRe2ewJT3AY+05buAjUmOTbKGzs3jh6pqL/BSknPau4s2AXcuwn5Jkg5BT5eMkrwG+C3gQ13lf59kLZ3LPrunxqrq0SS3AY8Bk8BHqmpfm3MlsA04DrinPSRJh1FPgVBVPwdOmlF7/0HWvxa4dpb6DuCsXvZFktQbP6ksSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1PQUCEl2J9mVZGeSHa32hiT3Jvlhe3591/rXJBlL8niS87vq69p2xpLckCS97Jck6dAtxhnCuVW1tqqG289XA/dV1enAfe1nkpwBbATOBDYAn01yTJuzBdgMnN4eGxZhvyRJh2ApLhldANzclm8GLuyqb6+ql6vqSWAMWJ/kFOCEqnqgqgq4pWuOJOkwSefP4AVOTp4EngcK+C9VtTXJ/62q13Wt83xVvT7JZ4AHq+rPW/1G4B5gN3BdVb271d8FfKyq3jvL622mcybB0NDQuu3bt08bn5iY4Pjjj19wP0e6Qe5/kHuH/ve/66kX+vbaa048pi+997Pns0898ZXlQz3255577sNdV3SmWdHjfr2zqvYkeRNwb5IfHGTd2e4L1EHq+xertgJbAYaHh2tkZGTa+OjoKDNrg2SQ+x/k3qH//V9+9d19e+1tG1b2pfd+9rz70pFXlhfz2Pd0yaiq9rTnZ4A7gPXA0+0yEO35mbb6OHBa1/RVwJ5WXzVLXZJ0GC04EJKsTPLaqWXgnwKPAHcBl7XVLgPubMt3ARuTHJtkDZ2bxw9V1V7gpSTntHcXbeqaI0k6THq5ZDQE3NHeIboC+Muq+mqSbwG3JbkC+DFwMUBVPZrkNuAxYBL4SFXta9u6EtgGHEfnvsI9PeyXJGkBFhwIVfUj4Ddmqf8UOO8Ac64Frp2lvgM4a6H7IknqnZ9UliQBBoIkqTEQJEmAgSBJagwESRJgIEiSml6/ukKHaPUSftz9qrMnD/hx+t3X/faSva6ko4NnCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAnwu4yko8pSfleWjn4LPkNIclqS/5Hk+0keTfIHrf6JJE8l2dke7+mac02SsSSPJzm/q74uya42dkOS9NaWJOlQ9XKGMAlcVVXfTvJa4OEk97ax66vqP3SvnOQMYCNwJvD3gf+e5G1VtQ/YAmwGHgS+AmwA7ulh3yRJh2jBZwhVtbeqvt2WXwK+D5x6kCkXANur6uWqehIYA9YnOQU4oaoeqKoCbgEuXOh+SZIWJp0/g3vcSLIauB84C/gj4HLgRWAHnbOI55N8Bniwqv68zbmRzlnAbuC6qnp3q78L+FhVvXeW19lM50yCoaGhddu3b582PjExwfHHH99zP0tp11MvLNm2h46Dp38x+9jZp564ZK+7HBwJx34pTfW/lL9fy9WaE4/py7Hv53/r7v+fD/V3/9xzz324qoZnG+v5pnKS44HbgT+sqheTbAE+CVR7/jTwQWC2+wJ1kPr+xaqtwFaA4eHhGhkZmTY+OjrKzNpyc6B/wGYxXHX2JJ/eNfsh3X3pyJK97nJwJBz7pTTV/1L+fi1X2zas7Mux7+d/6+7/nxfzd7+nt50m+Xt0wuAvqurLAFX1dFXtq6pfAZ8H1rfVx4HTuqavAva0+qpZ6pKkw6iXdxkFuBH4flX9x676KV2rvQ94pC3fBWxMcmySNcDpwENVtRd4Kck5bZubgDsXul+SpIXp5ZLRO4H3A7uS7Gy1PwYuSbKWzmWf3cCHAKrq0SS3AY/ReYfSR9o7jACuBLYBx9G5r+A7jCTpMFtwIFTV/2L26/9fOcica4FrZ6nvoHNDWpLUJ351hSQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLU9PxPaErS7lf/ft9ee9R/T2vReIYgSQIMBElSYyBIkgDvIUjSgvTzvgm8sCRbNRAOs6X8JRr9tX/L7ld//ACjS/MLJOnosWwuGSXZkOTxJGNJru73/kjSoFkWZwhJjgH+M/BbwDjwrSR3VdVj/d0z6cjS38sYOtIti0AA1gNjVfUjgCTbgQuAJQmE1VffvRSbnZfdr+7bS0vSQaWq+r0PJLkI2FBV/7L9/H7gH1fVR2estxnY3H58O/D4jE2dDDy7xLu7nA1y/4PcOwx2/4PcOxx6/79eVW+cbWC5nCFkltp+SVVVW4GtB9xIsqOqhhdzx44kg9z/IPcOg93/IPcOi9v/crmpPA6c1vXzKmBPn/ZFkgbScgmEbwGnJ1mT5FXARuCuPu+TJA2UZXHJqKomk3wU+G/AMcBNVfXoAjZ1wMtJA2KQ+x/k3mGw+x/k3mER+18WN5UlSf23XC4ZSZL6zECQJAFHUCDM56stkowk2Znk0ST/s6u+O8muNrbj8O314pir9yT/uvW2M8kjSfYlecN85h4Jeuz/aD/2Jyb5r0m+237vPzDfuUeCHvs/2o/965PckeR7SR5KctZ85x5QVS37B50bzU8AbwFeBXwXOGPGOq+j88nmN7ef39Q1ths4ud99LFXvM9b/HeDrC5m7HB+99D8Ixx74Y+BTbfmNwHNt3YE49gfqf0CO/Z8CH2/L/xC4b75zD/Q4Us4QXvlqi6r6f8DUV1t0+33gy1X1Y4CqeuYw7+NSmU/v3S4Bbl3g3OWol/6PdPPpvYDXJglwPJ0/ECfnOXe566X/I918ej8DuA+gqn4ArE4yNM+5szpSAuFU4CddP4+3Wre3Aa9PMprk4SSbusYK+Fqrb+bIMp/eAUjyGmADcPuhzl3Geukfjv5j/xngHXQ+yLkL+IOq+tU85y53vfQPR/+x/y7wewBJ1gO/TudDvQs+9svicwjzMJ+vtlgBrAPOA44DHkjyYFX9NfDOqtqT5E3AvUl+UFX3L+0uL5p5fa1H8zvA/66q5xYwd7nqpX84+o/9+cBO4J8A/4BOj9+Y59zlbsH9V9WLHP3H/jrgPyXZSScMv0Pn7GjBx/5IOUOYz1dbjANfraqfVdWzwP3AbwBU1Z72/AxwB51TqiPFoXytx0amXy45Gr4SpJf+B+HYf4DOpdKqqjHgSTrXkwfl2B+o/6P+2FfVi1X1gapaC2yicw/lyfnMPaB+3zyZ5w2WFcCPgDX83U2SM2es8w4619NWAK8BHgHOAlYCr23rrAT+D51vVu17X4vVe1vvRDrXT1ce6tzl/Oix/6P+2ANbgE+05SHgKTrffjkQx/4g/Q/CsX8df3cD/V8Bt8x37oEeR8QlozrAV1sk+XAb/1xVfT/JV4HvAb8C/qyqHknyFuCOzj0nVgB/WVVf7U8nh24+vbdV3wd8rap+Ntfcw9tBb3rpn84fEEf7sf8ksC3JLjqXCj5WnTNkBuTYz9r/gPx//w7gliT76LzD8oqDzZ3P6/rVFZIk4Mi5hyBJWmIGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1Px/3jDtMMOZCm8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = 'HAPPY'\n",
    "check_pos = probs[(probs[check]>0.5) & (probs['detailedMatchClassification'].isin([check]))]\n",
    "check_neg = probs[(probs[check]>0.5) & (~probs['detailedMatchClassification'].isin([check]))]\n",
    "check_pos[check].hist()\n",
    "check_neg[check].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T09:21:35.420508Z",
     "iopub.status.busy": "2021-02-24T09:21:35.420258Z",
     "iopub.status.idle": "2021-02-24T09:21:35.436432Z",
     "shell.execute_reply": "2021-02-24T09:21:35.434479Z",
     "shell.execute_reply.started": "2021-02-24T09:21:35.420485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830901    789\n",
       "0.897491    397\n",
       "0.695356    367\n",
       "0.804675    149\n",
       "0.658031      9\n",
       "Name: HAPPY, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_neg['HAPPY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T14:32:17.906622Z",
     "iopub.status.busy": "2021-02-17T14:32:17.906323Z",
     "iopub.status.idle": "2021-02-17T14:32:17.912083Z",
     "shell.execute_reply": "2021-02-17T14:32:17.909928Z",
     "shell.execute_reply.started": "2021-02-17T14:32:17.906590Z"
    }
   },
   "outputs": [],
   "source": [
    "#combinations = [i for i in product(['DT','RF','NN'],repeat=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:04:34.251693Z",
     "iopub.status.busy": "2021-03-05T10:04:34.251390Z",
     "iopub.status.idle": "2021-03-05T10:04:34.267533Z",
     "shell.execute_reply": "2021-03-05T10:04:34.264466Z",
     "shell.execute_reply.started": "2021-03-05T10:04:34.251628Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hyperspace(combination):\n",
    "    \n",
    "    param_hyperopt = {}\n",
    "    \n",
    "    for node, clf in enumerate(combination):\n",
    "        \n",
    "        if clf == 'DT':\n",
    "            hyper = {'DT_criterion_'+str(node)   : hp.choice('DT_criterion_'+str(node) ,['gini','entropy']),\n",
    "                     'DT_max_depth_'+str(node)   : scope.int(hp.quniform('DT_max_depth_'+str(node), 5, 15, 1))}\n",
    "        elif clf == 'RF':\n",
    "            hyper = {'RF_max_depth_'   +str(node) : scope.int(hp.quniform('RF_max_depth_'+str(node), 5, 15, 1)),\n",
    "                     'RF_n_estimators_'+str(node) : scope.int(hp.quniform('RF_n_estimators_'+str(node), 10, 50, 5))}\n",
    "        elif clf == 'NN':\n",
    "            hyper = {'NN_dropout_'+str(node)  : hp.uniform('NN_dropout_'+str(node), 0, 0.5),\n",
    "                     'NN_nodes_'  +str(node)  : scope.int(hp.quniform('NN_nodes_'+str(node), 5, 50, 5)),\n",
    "                     'NN_layers_' +str(node)  : scope.int(hp.quniform('NN_layers_'+str(node), 1, 2, 1))}\n",
    "        elif clf == 'LR':\n",
    "            hyper = {'LR_penalty_' + str(node) : hp.choice('LR_penalty_' + str(node), ['l1','l2'])}\n",
    "            \n",
    "        param_hyperopt = {**param_hyperopt, **hyper}\n",
    "        \n",
    "    return param_hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:04:34.495251Z",
     "iopub.status.busy": "2021-03-05T10:04:34.494962Z",
     "iopub.status.idle": "2021-03-05T10:04:34.505338Z",
     "shell.execute_reply": "2021-03-05T10:04:34.503521Z",
     "shell.execute_reply.started": "2021-03-05T10:04:34.495223Z"
    }
   },
   "outputs": [],
   "source": [
    "def clf_hypers(params):\n",
    "\n",
    "    clf = {}\n",
    "    \n",
    "    for ix, node in enumerate(['ORDERS','KNOWN','UNHAPPY']):\n",
    "\n",
    "        node_hypers = [x for x in list(params.keys()) if x[-1] == str(ix)]\n",
    "\n",
    "        if combination[ix] == 'DT':\n",
    "            clf[node] = DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = params[node_hypers[1]], criterion = params[node_hypers[0]])\n",
    "        elif combination[ix] == 'RF':\n",
    "            clf[node] = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = params[node_hypers[0]], n_estimators = params[node_hypers[1]])\n",
    "        elif combination[ix] == 'NN':\n",
    "            if ix == 2:\n",
    "                output = 3\n",
    "            else:\n",
    "                output = 1\n",
    "            clf[node] = KerasClassifier(functions.neuralNetwork, output = output, nodes = params[node_hypers[1]], layers = params[node_hypers[2]], droprate = params[node_hypers[0]], epochs = 15, verbose = 0)\n",
    "        elif combination[ix] == 'LR':\n",
    "            clf[node] = LogisticRegression(penalty = params[node_hypers[0]], class_weight = 'balanced', solver = 'liblinear')\n",
    "            \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:04:35.104140Z",
     "iopub.status.busy": "2021-03-05T10:04:35.103800Z",
     "iopub.status.idle": "2021-03-05T10:04:35.115808Z",
     "shell.execute_reply": "2021-03-05T10:04:35.113696Z",
     "shell.execute_reply.started": "2021-03-05T10:04:35.104104Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    \n",
    "    HC = HierarchicalClassifier(Tree)\n",
    "    HC.fit_classifiers(clf_hypers(params))\n",
    "    \n",
    "    HC = HC.fit(X_train,y_train)\n",
    "    pred = HC.predict(X_val)\n",
    "    \n",
    "    score = f1_score_ancestors(Tree, y_val['detailedMatchClassification'], pred, beta=1)\n",
    "    accuracy = metrics.accuracy_score(y_val, pred)\n",
    "    #cross validation score to be implemented\n",
    "    \n",
    "    return {'loss': -score, 'status': STATUS_OK, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T10:04:35.656649Z",
     "iopub.status.busy": "2021-03-05T10:04:35.656390Z",
     "iopub.status.idle": "2021-03-05T10:04:35.666901Z",
     "shell.execute_reply": "2021-03-05T10:04:35.664321Z",
     "shell.execute_reply.started": "2021-03-05T10:04:35.656625Z"
    }
   },
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X_train, y_train, X_val, y_val, num_eval):\n",
    "\n",
    "    trials = Trials()\n",
    "\n",
    "    best_param = fmin(objective_function, \n",
    "                      param_space, \n",
    "                      algo = tpe.suggest, \n",
    "                      max_evals = num_eval, \n",
    "                      trials = trials,\n",
    "                      rstate = np.random.RandomState(1))\n",
    "    \n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    index_min_loss = loss.index(min(loss))\n",
    "    accuracy_scores = [x['result']['accuracy'] for x in trials.trials]\n",
    "    \n",
    "    f1 = min(loss)*-1\n",
    "    accuracy = accuracy_scores[index_min_loss]\n",
    "    \n",
    "    return best_param, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T20:16:56.130427Z",
     "iopub.status.busy": "2021-02-17T20:16:56.128273Z",
     "iopub.status.idle": "2021-02-17T22:17:13.700600Z",
     "shell.execute_reply": "2021-02-17T22:17:13.691358Z",
     "shell.execute_reply.started": "2021-02-17T20:16:56.130312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [2:00:17<13:21, 801.93s/trial, best loss: -0.7816644024189379]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-425-d5cf0371aaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_hyperspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-423-7b9cd86e5e4c>\u001b[0m in \u001b[0;36mhyperopt\u001b[0;34m(param_space, X_train, y_train, X_test, y_test, num_eval)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     best_param = fmin(objective_function, \n\u001b[0m\u001b[1;32m      6\u001b[0m                       \u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-422-27897c696584>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mHC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-407-50e5fafd7f05>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0my_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mstage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mstage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "combination = ('NN', 'NN', 'NN')\n",
    "best_param, trials = hyperopt(get_hyperspace(combination), X_train, y_train, X_test, y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAT-HCOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T17:15:10.820454Z",
     "iopub.status.busy": "2021-03-11T17:15:10.820160Z",
     "iopub.status.idle": "2021-03-11T17:15:10.843427Z",
     "shell.execute_reply": "2021-03-11T17:15:10.842085Z",
     "shell.execute_reply.started": "2021-03-11T17:15:10.820429Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSIFIERS = {0: {'ORDERS'  : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 10, n_estimators = 45),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 9 , n_estimators = 30),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 12, n_estimators = 30)},\n",
    "               1: {'ORDERS'  : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 12, n_estimators = 30),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 30),\n",
    "                   'UNHAPPY' : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l2')},\n",
    "               2: {'ORDERS'  : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 12, n_estimators = 30),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 30),\n",
    "                   'UNHAPPY' : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l2')},\n",
    "               3: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l2'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 12, n_estimators = 30),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 30)},\n",
    "               4: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l2'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 12, n_estimators = 30),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 30)},\n",
    "               5: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l2'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 12, n_estimators = 30),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 30)},\n",
    "               6: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l1'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 10, n_estimators = 45),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 45)},\n",
    "               7: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l1'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 10, n_estimators = 45),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 45)},\n",
    "               8: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l1'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 10, n_estimators = 45),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 45)},\n",
    "               9: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l1'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 10, n_estimators = 45),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 45)},\n",
    "              10: {'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = 'l1'),\n",
    "                   'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 10, n_estimators = 45),\n",
    "                   'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = 14, n_estimators = 45)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T17:19:49.169092Z",
     "iopub.status.busy": "2021-03-11T17:19:49.168777Z",
     "iopub.status.idle": "2021-03-11T17:19:49.190631Z",
     "shell.execute_reply": "2021-03-11T17:19:49.189073Z",
     "shell.execute_reply.started": "2021-03-11T17:19:49.169059Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamicHierarchicalClassifier(START, END, threshold = None, threshold_type = None):  \n",
    "  \n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "    \n",
    "#     hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "#                            '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "#                            '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "#                            '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "#                            '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "    \n",
    "#     # Lourens\n",
    "    OPTION = 2\n",
    "    certainties = [0.7, 0.6, 0.8]\n",
    "    \n",
    "#     # Thomas\n",
    "#     OPTION = 2\n",
    "#     certainties = [0.9, 0.4, 0.5]\n",
    "    \n",
    "#     # Jim\n",
    "#     OPTION = 2\n",
    "#     certainties = [0.6, 0.8]\n",
    "    \n",
    "    # Mathilde\n",
    "#     OPTION = 2\n",
    "#     certainties = [0, 0.1, 0.2]\n",
    "    \n",
    "    statistics, previous_pred_block, feature_importances = None, None, None\n",
    "    \n",
    "    for CERTAINTY in certainties:  \n",
    "        for DAYS in range(START, END+1):\n",
    "\n",
    "            X, y = functions.dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "            X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "            y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "            X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "            y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "            X_test = X.iloc[int(0.8*len(X)):]\n",
    "            y_test = y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "            N_test = len(y_test)\n",
    "\n",
    "            HC = HierarchicalClassifier(Tree)\n",
    "            HC.fit_classifiers(CLASSIFIERS[DAYS])\n",
    "#             HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "#                                 'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "#                                 'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "\n",
    "            HC = HC.fit(X_train,y_train)\n",
    "\n",
    "            y_train_hat = HC.get_probabilities(X_train, y_train)\n",
    "            probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "\n",
    "            THRESHOLDS = {}\n",
    "            for node in range(1,8):\n",
    "                name, threshold = opt_threshold(probs, node, DAYS, CERTAINTY, OPTION)\n",
    "                THRESHOLDS[name] = threshold\n",
    "\n",
    "            if DAYS == START: #create dataframe to save predictions\n",
    "                y_hat = pd.DataFrame([Tree.root] * len(X_test),\n",
    "                                        columns=[DAYS],\n",
    "                                        index=X_test.index)\n",
    "                index_no_leaf = X_test.index\n",
    "            else:\n",
    "                y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "            if DAYS < END:\n",
    "                pred = HC.predict_proba2(X_test.loc[index_no_leaf], THRESHOLDS = THRESHOLDS)\n",
    "\n",
    "                check_no_leaf = ~pred.isin(Tree._get_leaf_nodes())\n",
    "                index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "                check_leaf    = pred.isin(Tree._get_leaf_nodes())      #from current non_leaf predictions which are now leaf\n",
    "                index_leaf    = check_leaf[check_leaf].index\n",
    "                y_hat_stage   = pd.DataFrame(pred, index = index_leaf)\n",
    "            else:\n",
    "                pred        = HC.predict(X_test.loc[index_no_leaf]) #last day you want a label for each order\n",
    "                y_hat_stage = pd.DataFrame(pred, index = index_no_leaf)\n",
    "                index_leaf  = index_no_leaf\n",
    "\n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[DAYS]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(DAYS, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "\n",
    "            current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "\n",
    "            statistics, feature_importances, previous_pred_block = get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, \n",
    "                                                                                   previous_pred_block, THRESHOLDS, OPTION, CERTAINTY, y_test, Tree, HC, feature_importances, statistics)\n",
    "            \n",
    "            file_name = 'statistics_optimal_'+str(OPTION)+'_'+str(CERTAINTY)+'.json'\n",
    "            path_name = '/Users/LV/Desktop/' + file_name\n",
    "            with open(path_name, 'w') as f:\n",
    "                json.dump(statistics, f, cls = NumpyEncoder)\n",
    "\n",
    "            print('DAYS: ',DAYS)\n",
    "     \n",
    "    final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "    return final_pred, statistics, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T17:15:11.752776Z",
     "iopub.status.busy": "2021-03-11T17:15:11.752481Z",
     "iopub.status.idle": "2021-03-11T17:17:16.784670Z",
     "shell.execute_reply": "2021-03-11T17:17:16.783520Z",
     "shell.execute_reply.started": "2021-03-11T17:15:11.752745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n"
     ]
    }
   ],
   "source": [
    "pred, statistics, feature_importances = dynamicHierarchicalClassifier(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T17:17:16.786908Z",
     "iopub.status.busy": "2021-03-11T17:17:16.786433Z",
     "iopub.status.idle": "2021-03-11T17:17:16.812381Z",
     "shell.execute_reply": "2021-03-11T17:17:16.810626Z",
     "shell.execute_reply.started": "2021-03-11T17:17:16.786838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'%classified': {0: 0.4005, 1: 0.6424, 2: 0.7623, 3: 0.83505, 4: 1.0},\n",
       " 'N_classified': {0: 8010, 1: 4838, 2: 2398, 3: 1455, 4: 3299},\n",
       " 'N_predicted': {0: 20000, 1: 11990, 2: 7152, 3: 4754, 4: 3299},\n",
       " 'leaf_accuracy': {0: 0.8917602996254682,\n",
       "  1: 0.9047126911947085,\n",
       "  2: 0.9478732276897415,\n",
       "  3: 0.9429553264604811,\n",
       "  4: 0.8390421339799939},\n",
       " 'total_leaf_accuracy': {0: 0.8917602996254682,\n",
       "  1: 0.8966376089663761,\n",
       "  2: 0.9046963137872229,\n",
       "  3: 0.9080294593138135,\n",
       "  4: 0.89665},\n",
       " 'leaf_precision': {0: 0.9319505611592556,\n",
       "  1: 0.936728960547209,\n",
       "  2: 0.9657453342782897,\n",
       "  3: 0.9652103559870551,\n",
       "  4: 0.8567921440261865},\n",
       " 'total_leaf_precision': {0: 0.9319505611592556,\n",
       "  1: 0.9337076128452728,\n",
       "  2: 0.9388255717412635,\n",
       "  3: 0.9410769761822575,\n",
       "  4: 0.9289089727686219},\n",
       " 'leaf_recall': {0: 0.8799463447350772,\n",
       "  1: 0.8881297046902142,\n",
       "  2: 0.9412848261570343,\n",
       "  3: 0.93203125,\n",
       "  4: 0.787514103046258},\n",
       " 'total_leaf_recall': {0: 0.8799463447350772,\n",
       "  1: 0.882947547249947,\n",
       "  2: 0.8920324153757889,\n",
       "  3: 0.8953954282711508,\n",
       "  4: 0.8793546944025051},\n",
       " 'label_precision': {0: 0.9422733480407606,\n",
       "  1: 0.9373386737872719,\n",
       "  2: 0.9470845972362656,\n",
       "  3: 0.9676755803702616,\n",
       "  4: 0.8567921440261865},\n",
       " 'label_recall': {0: 0.706593666299039,\n",
       "  1: 0.7098274467511458,\n",
       "  2: 0.7408383865014501,\n",
       "  3: 0.7416666666666667,\n",
       "  4: 0.787514103046258},\n",
       " 'block_precision': {0: 0.9715725806451613,\n",
       "  1: 0.9389763779527559,\n",
       "  2: 0.9006466784244562,\n",
       "  3: 0.9742212674543501,\n",
       "  4: None},\n",
       " 'block_recall': {0: 0.4599160145065852,\n",
       "  1: 0.46153846153846156,\n",
       "  2: 0.4724020968239285,\n",
       "  3: 0.4824468085106383,\n",
       "  4: None},\n",
       " 'block_Nchange': {0: None,\n",
       "  1: 0.012145748987854251,\n",
       "  2: 0.06029462144570058,\n",
       "  3: 0.26573889993373095,\n",
       "  4: 0.00563063063063063},\n",
       " 'block_Pchange': {0: None,\n",
       "  1: 0.5052631578947369,\n",
       "  2: 0.5053100376841384,\n",
       "  3: 0.2392312789927104,\n",
       "  4: 0.9943693693693694},\n",
       " '%blocking': {0: {'ORDERS': 0.35250000000000004,\n",
       "   'KNOWN': 0.4478427089022392,\n",
       "   'UNHAPPY': 0.47619047619047616},\n",
       "  1: {'ORDERS': 0.3530442035029191,\n",
       "   'KNOWN': 0.4538061158100195,\n",
       "   'UNHAPPY': 0.5180722891566265},\n",
       "  2: {'ORDERS': 0.4537192393736018,\n",
       "   'KNOWN': 0.40648148148148144,\n",
       "   'UNHAPPY': 0.6486486486486487},\n",
       "  3: {'ORDERS': 0.5071518721076989,\n",
       "   'KNOWN': 0.5317809943360604,\n",
       "   'UNHAPPY': 0.11977715877437323},\n",
       "  4: {'ORDERS': None, 'KNOWN': None, 'UNHAPPY': None}},\n",
       " '%Tblocking': {0: {'ORDERS': 7050, 'KNOWN': 4920, 'UNHAPPY': 20},\n",
       "  1: {'ORDERS': 4233, 'KNOWN': 2790, 'UNHAPPY': 129},\n",
       "  2: {'ORDERS': 3245, 'KNOWN': 1317, 'UNHAPPY': 192},\n",
       "  3: {'ORDERS': 2411, 'KNOWN': 845, 'UNHAPPY': 43},\n",
       "  4: {'ORDERS': None, 'KNOWN': None, 'UNHAPPY': None}},\n",
       " 'tree_error': {0: 0.3430711610486891,\n",
       "  1: 0.30673832162050435,\n",
       "  2: 0.16680567139282734,\n",
       "  3: 0.17869415807560138,\n",
       "  4: 0.5547135495604729},\n",
       " 'thresholds': {0: {'UNKNOWN': 0.9352362128717864,\n",
       "   'KNOWN': 0.8460911223308856,\n",
       "   'HAPPY': 0.6294692612650575,\n",
       "   'UNHAPPY': 0.5689012602429953,\n",
       "   'MILDLY UNHAPPY': 0.5379979034584862,\n",
       "   'MEDIUM UNHAPPY': 0.513490478135275,\n",
       "   'HEAVILY UNHAPPY': 0.522522063382517},\n",
       "  1: {'UNKNOWN': 0.9428769608748546,\n",
       "   'KNOWN': 0.8098728297303404,\n",
       "   'HAPPY': 0.6425314762716771,\n",
       "   'UNHAPPY': 0.5488730838012692,\n",
       "   'MILDLY UNHAPPY': 0.6982396194943986,\n",
       "   'MEDIUM UNHAPPY': 0.504620545128814,\n",
       "   'HEAVILY UNHAPPY': 0.6466018252914443},\n",
       "  2: {'UNKNOWN': 0.9490638576634052,\n",
       "   'KNOWN': 0.7475572799875209,\n",
       "   'HAPPY': 0.7088425832663954,\n",
       "   'UNHAPPY': 0.5668283993733625,\n",
       "   'MILDLY UNHAPPY': 0.7110447430700426,\n",
       "   'MEDIUM UNHAPPY': 0.5162685920502782,\n",
       "   'HEAVILY UNHAPPY': 0.6443892425535437},\n",
       "  3: {'UNKNOWN': 0.9629113616482676,\n",
       "   'KNOWN': 0.7369050841013924,\n",
       "   'HAPPY': 0.762439511953893,\n",
       "   'UNHAPPY': 0.5994140981534664,\n",
       "   'MILDLY UNHAPPY': 0.5522882004703187,\n",
       "   'MEDIUM UNHAPPY': 0.5343560496665526,\n",
       "   'HEAVILY UNHAPPY': 0.5119561685851466},\n",
       "  4: {'UNKNOWN': 0.9587631506500888,\n",
       "   'KNOWN': 0.6550733751127823,\n",
       "   'HAPPY': 0.7777626943986095,\n",
       "   'UNHAPPY': 0.6205233876479768,\n",
       "   'MILDLY UNHAPPY': 0.5620335981252514,\n",
       "   'MEDIUM UNHAPPY': 0.5185608035955513,\n",
       "   'HEAVILY UNHAPPY': 0.5067794973506039}},\n",
       " 'option': {0: 2, 1: 2, 2: 2, 3: 2, 4: 2},\n",
       " 'certainty': {0: 0.7, 1: 0.7, 2: 0.7, 3: 0.7, 4: 0.7},\n",
       " 'precision_UNKNOWN': {0: 0.9220977596741344,\n",
       "  1: 0.9266625233064015,\n",
       "  2: 0.9535232383808095,\n",
       "  3: 0.9535809018567639,\n",
       "  4: 0.8480703468490474},\n",
       " 'recall_UNKNOWN': {0: 0.7999116607773852,\n",
       "  1: 0.808130081300813,\n",
       "  2: 0.8724279835390947,\n",
       "  3: 0.8725728155339806,\n",
       "  4: 0.6707882534775889},\n",
       " 'f1_UNKNOWN': {0: 0.856669820245979,\n",
       "  1: 0.8633468442385639,\n",
       "  2: 0.9111747851002866,\n",
       "  3: 0.9112801013941698,\n",
       "  4: 0.7490830636461704},\n",
       " 'precision_HAPPY': {0: 0.9356739707835325,\n",
       "  1: 0.9461241556770665,\n",
       "  2: 0.9778733866011063,\n",
       "  3: 0.9727272727272728,\n",
       "  4: 0.9672131147540983},\n",
       " 'recall_HAPPY': {0: 0.8950377133783247,\n",
       "  1: 0.9115277347381469,\n",
       "  2: 0.958433734939759,\n",
       "  3: 0.9469026548672567,\n",
       "  4: 0.9379968203497615},\n",
       " 'f1_HAPPY': {0: 0.9149048411313557,\n",
       "  1: 0.9285037878787878,\n",
       "  2: 0.9680559780955278,\n",
       "  3: 0.9596412556053813,\n",
       "  4: 0.9523809523809523},\n",
       " 'precision_MILDLY UNHAPPY': {0: 0.5454545454545454,\n",
       "  1: 0.8366666666666667,\n",
       "  2: 0.8791208791208791,\n",
       "  3: 0.9642346208869814,\n",
       "  4: 0.6193939393939394},\n",
       " 'recall_MILDLY UNHAPPY': {0: 0.7058823529411765,\n",
       "  1: 0.9094202898550725,\n",
       "  2: 0.9411764705882353,\n",
       "  3: 0.9683908045977011,\n",
       "  4: 0.7754172989377845},\n",
       " 'f1_MILDLY UNHAPPY': {0: 0.6153846153846153,\n",
       "  1: 0.8715277777777778,\n",
       "  2: 0.9090909090909091,\n",
       "  3: 0.9663082437275987,\n",
       "  4: 0.6886792452830188},\n",
       " 'precision_MEDIUM UNHAPPY': {0: None,\n",
       "  1: 0.7333333333333333,\n",
       "  2: 0.75,\n",
       "  3: 0.9494949494949495,\n",
       "  4: 0.9148936170212766},\n",
       " 'recall_MEDIUM UNHAPPY': {0: None,\n",
       "  1: 0.7333333333333333,\n",
       "  2: 0.75,\n",
       "  3: 0.9494949494949495,\n",
       "  4: 0.9280575539568345},\n",
       " 'f1_MEDIUM UNHAPPY': {0: None,\n",
       "  1: 0.7333333333333333,\n",
       "  2: 0.75,\n",
       "  3: 0.9494949494949495,\n",
       "  4: 0.9214285714285715},\n",
       " 'precision_HEAVILY UNHAPPY': {0: None,\n",
       "  1: None,\n",
       "  2: 1.0,\n",
       "  3: 1.0,\n",
       "  4: 0.9333333333333333},\n",
       " 'recall_HEAVILY UNHAPPY': {0: None,\n",
       "  1: None,\n",
       "  2: 1.0,\n",
       "  3: 1.0,\n",
       "  4: 0.9333333333333333},\n",
       " 'f1_HEAVILY UNHAPPY': {0: None,\n",
       "  1: None,\n",
       "  2: 1.0,\n",
       "  3: 1.0,\n",
       "  4: 0.9333333333333333},\n",
       " 'precision_KNOWN': {0: 0.973780487804878,\n",
       "  1: 0.9627240143369176,\n",
       "  2: 0.9552012148823082,\n",
       "  3: 0.9739644970414201,\n",
       "  4: None},\n",
       " 'recall_KNOWN': {0: 0.45934803451581974,\n",
       "  1: 0.4555630936227951,\n",
       "  2: 0.4530068419157364,\n",
       "  3: 0.4694808899030234,\n",
       "  4: None},\n",
       " 'f1_KNOWN': {0: 0.6242345276872964,\n",
       "  1: 0.618466497812572,\n",
       "  2: 0.6145578895945286,\n",
       "  3: 0.6335642802155503,\n",
       "  4: None},\n",
       " 'precision_UNHAPPY': {0: 0.7,\n",
       "  1: 0.6821705426356589,\n",
       "  2: 0.7135416666666666,\n",
       "  3: 0.9767441860465116,\n",
       "  4: None},\n",
       " 'recall_UNHAPPY': {0: 0.5833333333333334,\n",
       "  1: 0.5770491803278689,\n",
       "  2: 0.5879828326180258,\n",
       "  3: 0.6614173228346457,\n",
       "  4: None},\n",
       " 'f1_UNHAPPY': {0: 0.6363636363636365,\n",
       "  1: 0.6252220248667851,\n",
       "  2: 0.6447058823529411,\n",
       "  3: 0.7887323943661971,\n",
       "  4: None}}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-03-03T15:49:21.559632Z",
     "iopub.status.busy": "2021-03-03T15:49:21.548826Z",
     "iopub.status.idle": "2021-03-03T15:49:21.753489Z",
     "shell.execute_reply": "2021-03-03T15:49:21.752486Z",
     "shell.execute_reply.started": "2021-03-03T15:49:21.559494Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%classified</th>\n",
       "      <td>0.389673</td>\n",
       "      <td>0.548674</td>\n",
       "      <td>0.649158</td>\n",
       "      <td>0.708673</td>\n",
       "      <td>0.753399</td>\n",
       "      <td>0.776252</td>\n",
       "      <td>0.787030</td>\n",
       "      <td>0.792993</td>\n",
       "      <td>0.798207</td>\n",
       "      <td>0.802316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_classified</th>\n",
       "      <td>371978.000000</td>\n",
       "      <td>151781.000000</td>\n",
       "      <td>95921.000000</td>\n",
       "      <td>56812.000000</td>\n",
       "      <td>42695.000000</td>\n",
       "      <td>21815.000000</td>\n",
       "      <td>10289.000000</td>\n",
       "      <td>5692.000000</td>\n",
       "      <td>4977.000000</td>\n",
       "      <td>3923.000000</td>\n",
       "      <td>188707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_predicted</th>\n",
       "      <td>954590.000000</td>\n",
       "      <td>582612.000000</td>\n",
       "      <td>430831.000000</td>\n",
       "      <td>334910.000000</td>\n",
       "      <td>278098.000000</td>\n",
       "      <td>235403.000000</td>\n",
       "      <td>213588.000000</td>\n",
       "      <td>203299.000000</td>\n",
       "      <td>197607.000000</td>\n",
       "      <td>192630.000000</td>\n",
       "      <td>188707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaf_accuracy</th>\n",
       "      <td>0.907040</td>\n",
       "      <td>0.941159</td>\n",
       "      <td>0.952961</td>\n",
       "      <td>0.953197</td>\n",
       "      <td>0.957021</td>\n",
       "      <td>0.960761</td>\n",
       "      <td>0.955584</td>\n",
       "      <td>0.956606</td>\n",
       "      <td>0.960217</td>\n",
       "      <td>0.970941</td>\n",
       "      <td>0.967187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_leaf_accuracy</th>\n",
       "      <td>0.907040</td>\n",
       "      <td>0.916927</td>\n",
       "      <td>0.922505</td>\n",
       "      <td>0.925083</td>\n",
       "      <td>0.926979</td>\n",
       "      <td>0.927973</td>\n",
       "      <td>0.928351</td>\n",
       "      <td>0.928564</td>\n",
       "      <td>0.928771</td>\n",
       "      <td>0.928987</td>\n",
       "      <td>0.936538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaf_precision</th>\n",
       "      <td>0.939998</td>\n",
       "      <td>0.965407</td>\n",
       "      <td>0.972158</td>\n",
       "      <td>0.973109</td>\n",
       "      <td>0.974015</td>\n",
       "      <td>0.977949</td>\n",
       "      <td>0.978356</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981719</td>\n",
       "      <td>0.985651</td>\n",
       "      <td>0.980724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_leaf_precision</th>\n",
       "      <td>0.939998</td>\n",
       "      <td>0.947748</td>\n",
       "      <td>0.951807</td>\n",
       "      <td>0.953711</td>\n",
       "      <td>0.954891</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>0.955980</td>\n",
       "      <td>0.956235</td>\n",
       "      <td>0.956446</td>\n",
       "      <td>0.956622</td>\n",
       "      <td>0.961357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaf_recall</th>\n",
       "      <td>0.879901</td>\n",
       "      <td>0.926713</td>\n",
       "      <td>0.945047</td>\n",
       "      <td>0.946235</td>\n",
       "      <td>0.945776</td>\n",
       "      <td>0.960042</td>\n",
       "      <td>0.967589</td>\n",
       "      <td>0.975874</td>\n",
       "      <td>0.974789</td>\n",
       "      <td>0.979855</td>\n",
       "      <td>0.960087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_leaf_recall</th>\n",
       "      <td>0.879901</td>\n",
       "      <td>0.893930</td>\n",
       "      <td>0.902219</td>\n",
       "      <td>0.906063</td>\n",
       "      <td>0.908323</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>0.910794</td>\n",
       "      <td>0.911424</td>\n",
       "      <td>0.911927</td>\n",
       "      <td>0.912319</td>\n",
       "      <td>0.921509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_precision</th>\n",
       "      <td>0.950019</td>\n",
       "      <td>0.968139</td>\n",
       "      <td>0.975530</td>\n",
       "      <td>0.980693</td>\n",
       "      <td>0.981588</td>\n",
       "      <td>0.993608</td>\n",
       "      <td>0.996568</td>\n",
       "      <td>0.998254</td>\n",
       "      <td>0.998562</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.980724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_recall</th>\n",
       "      <td>0.694441</td>\n",
       "      <td>0.673916</td>\n",
       "      <td>0.647766</td>\n",
       "      <td>0.611142</td>\n",
       "      <td>0.588473</td>\n",
       "      <td>0.557477</td>\n",
       "      <td>0.534289</td>\n",
       "      <td>0.519787</td>\n",
       "      <td>0.522629</td>\n",
       "      <td>0.514938</td>\n",
       "      <td>0.960087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_precision</th>\n",
       "      <td>0.974947</td>\n",
       "      <td>0.972517</td>\n",
       "      <td>0.979208</td>\n",
       "      <td>0.985990</td>\n",
       "      <td>0.985351</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_recall</th>\n",
       "      <td>0.461266</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.483149</td>\n",
       "      <td>0.491220</td>\n",
       "      <td>0.496361</td>\n",
       "      <td>0.499518</td>\n",
       "      <td>0.500110</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.503867</td>\n",
       "      <td>0.500617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_Nchange</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093113</td>\n",
       "      <td>0.060670</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>0.034253</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_Pchange</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.305884</td>\n",
       "      <td>0.249340</td>\n",
       "      <td>0.141131</td>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.051526</td>\n",
       "      <td>0.032920</td>\n",
       "      <td>0.028211</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.020884</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree_error</th>\n",
       "      <td>0.308669</td>\n",
       "      <td>0.195591</td>\n",
       "      <td>0.153918</td>\n",
       "      <td>0.149440</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.112645</td>\n",
       "      <td>0.099438</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>0.070099</td>\n",
       "      <td>0.102646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>option</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certainty</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_UNKNOWN</th>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.921308</td>\n",
       "      <td>0.932704</td>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.957956</td>\n",
       "      <td>0.970422</td>\n",
       "      <td>0.973536</td>\n",
       "      <td>0.982812</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>0.990257</td>\n",
       "      <td>0.965566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_UNKNOWN</th>\n",
       "      <td>0.787460</td>\n",
       "      <td>0.797106</td>\n",
       "      <td>0.822589</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.883651</td>\n",
       "      <td>0.916223</td>\n",
       "      <td>0.924599</td>\n",
       "      <td>0.950151</td>\n",
       "      <td>0.952596</td>\n",
       "      <td>0.971329</td>\n",
       "      <td>0.905298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_UNKNOWN</th>\n",
       "      <td>0.847462</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>0.874192</td>\n",
       "      <td>0.895714</td>\n",
       "      <td>0.919304</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.948437</td>\n",
       "      <td>0.966206</td>\n",
       "      <td>0.967890</td>\n",
       "      <td>0.980702</td>\n",
       "      <td>0.934461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_HAPPY</th>\n",
       "      <td>0.946561</td>\n",
       "      <td>0.976523</td>\n",
       "      <td>0.985244</td>\n",
       "      <td>0.985516</td>\n",
       "      <td>0.988595</td>\n",
       "      <td>0.988588</td>\n",
       "      <td>0.988501</td>\n",
       "      <td>0.990552</td>\n",
       "      <td>0.989723</td>\n",
       "      <td>0.992018</td>\n",
       "      <td>0.988248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_HAPPY</th>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.954151</td>\n",
       "      <td>0.970917</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.977447</td>\n",
       "      <td>0.977433</td>\n",
       "      <td>0.977263</td>\n",
       "      <td>0.981280</td>\n",
       "      <td>0.979655</td>\n",
       "      <td>0.984162</td>\n",
       "      <td>0.976769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_HAPPY</th>\n",
       "      <td>0.927453</td>\n",
       "      <td>0.965207</td>\n",
       "      <td>0.978028</td>\n",
       "      <td>0.978430</td>\n",
       "      <td>0.982990</td>\n",
       "      <td>0.982979</td>\n",
       "      <td>0.982850</td>\n",
       "      <td>0.985894</td>\n",
       "      <td>0.984664</td>\n",
       "      <td>0.988074</td>\n",
       "      <td>0.982475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_MILDLY UNHAPPY</th>\n",
       "      <td>0.668412</td>\n",
       "      <td>0.943464</td>\n",
       "      <td>0.960883</td>\n",
       "      <td>0.979843</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.984599</td>\n",
       "      <td>0.986676</td>\n",
       "      <td>0.985300</td>\n",
       "      <td>0.983046</td>\n",
       "      <td>0.985997</td>\n",
       "      <td>0.970088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_MILDLY UNHAPPY</th>\n",
       "      <td>0.789691</td>\n",
       "      <td>0.961993</td>\n",
       "      <td>0.973229</td>\n",
       "      <td>0.982613</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.984599</td>\n",
       "      <td>0.986676</td>\n",
       "      <td>0.985300</td>\n",
       "      <td>0.983046</td>\n",
       "      <td>0.985997</td>\n",
       "      <td>0.971059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_MILDLY UNHAPPY</th>\n",
       "      <td>0.724008</td>\n",
       "      <td>0.952638</td>\n",
       "      <td>0.967017</td>\n",
       "      <td>0.981226</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.984599</td>\n",
       "      <td>0.986676</td>\n",
       "      <td>0.985300</td>\n",
       "      <td>0.983046</td>\n",
       "      <td>0.985997</td>\n",
       "      <td>0.970574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_MEDIUM UNHAPPY</th>\n",
       "      <td>0.941781</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.922971</td>\n",
       "      <td>0.916028</td>\n",
       "      <td>0.934438</td>\n",
       "      <td>0.931142</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.940129</td>\n",
       "      <td>0.917516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_MEDIUM UNHAPPY</th>\n",
       "      <td>0.941781</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.924437</td>\n",
       "      <td>0.930882</td>\n",
       "      <td>0.918896</td>\n",
       "      <td>0.935406</td>\n",
       "      <td>0.931142</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.940129</td>\n",
       "      <td>0.919220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_MEDIUM UNHAPPY</th>\n",
       "      <td>0.941781</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.922359</td>\n",
       "      <td>0.926910</td>\n",
       "      <td>0.917460</td>\n",
       "      <td>0.934921</td>\n",
       "      <td>0.931142</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.940129</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_HEAVILY UNHAPPY</th>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.988866</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.938484</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.985876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_HEAVILY UNHAPPY</th>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.988866</td>\n",
       "      <td>0.964059</td>\n",
       "      <td>0.946609</td>\n",
       "      <td>0.959055</td>\n",
       "      <td>0.977597</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.985876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_HEAVILY UNHAPPY</th>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.988866</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.973631</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.985876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_KNOWN</th>\n",
       "      <td>0.979984</td>\n",
       "      <td>0.981898</td>\n",
       "      <td>0.985605</td>\n",
       "      <td>0.991373</td>\n",
       "      <td>0.997443</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_KNOWN</th>\n",
       "      <td>0.459155</td>\n",
       "      <td>0.461264</td>\n",
       "      <td>0.471415</td>\n",
       "      <td>0.479468</td>\n",
       "      <td>0.485086</td>\n",
       "      <td>0.488157</td>\n",
       "      <td>0.488727</td>\n",
       "      <td>0.487754</td>\n",
       "      <td>0.491283</td>\n",
       "      <td>0.489774</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_KNOWN</th>\n",
       "      <td>0.625325</td>\n",
       "      <td>0.627669</td>\n",
       "      <td>0.637780</td>\n",
       "      <td>0.646340</td>\n",
       "      <td>0.652730</td>\n",
       "      <td>0.655921</td>\n",
       "      <td>0.656498</td>\n",
       "      <td>0.655676</td>\n",
       "      <td>0.658859</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_UNHAPPY</th>\n",
       "      <td>0.769362</td>\n",
       "      <td>0.860530</td>\n",
       "      <td>0.918413</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>0.882878</td>\n",
       "      <td>0.983993</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_UNHAPPY</th>\n",
       "      <td>0.606101</td>\n",
       "      <td>0.632496</td>\n",
       "      <td>0.647493</td>\n",
       "      <td>0.651571</td>\n",
       "      <td>0.638435</td>\n",
       "      <td>0.663071</td>\n",
       "      <td>0.665925</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_UNHAPPY</th>\n",
       "      <td>0.678043</td>\n",
       "      <td>0.729099</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>0.767974</td>\n",
       "      <td>0.741018</td>\n",
       "      <td>0.792267</td>\n",
       "      <td>0.798400</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_ORDERS</th>\n",
       "      <td>0.356616</td>\n",
       "      <td>0.463957</td>\n",
       "      <td>0.422790</td>\n",
       "      <td>0.409850</td>\n",
       "      <td>0.357964</td>\n",
       "      <td>0.344329</td>\n",
       "      <td>0.339607</td>\n",
       "      <td>0.339151</td>\n",
       "      <td>0.336304</td>\n",
       "      <td>0.332840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nblock_ORDERS</th>\n",
       "      <td>340422.000000</td>\n",
       "      <td>270307.000000</td>\n",
       "      <td>182151.000000</td>\n",
       "      <td>137263.000000</td>\n",
       "      <td>99549.000000</td>\n",
       "      <td>81056.000000</td>\n",
       "      <td>72536.000000</td>\n",
       "      <td>68949.000000</td>\n",
       "      <td>66456.000000</td>\n",
       "      <td>64115.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockCum_ORDERS</th>\n",
       "      <td>0.356616</td>\n",
       "      <td>0.283166</td>\n",
       "      <td>0.190816</td>\n",
       "      <td>0.143793</td>\n",
       "      <td>0.104285</td>\n",
       "      <td>0.084912</td>\n",
       "      <td>0.075987</td>\n",
       "      <td>0.072229</td>\n",
       "      <td>0.069617</td>\n",
       "      <td>0.067165</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_KNOWN</th>\n",
       "      <td>0.499785</td>\n",
       "      <td>0.572978</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.758616</td>\n",
       "      <td>0.819833</td>\n",
       "      <td>0.876829</td>\n",
       "      <td>0.904911</td>\n",
       "      <td>0.926490</td>\n",
       "      <td>0.920134</td>\n",
       "      <td>0.936453</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nblock_KNOWN</th>\n",
       "      <td>239259.000000</td>\n",
       "      <td>154071.000000</td>\n",
       "      <td>145123.000000</td>\n",
       "      <td>133772.000000</td>\n",
       "      <td>128285.000000</td>\n",
       "      <td>126472.000000</td>\n",
       "      <td>124904.000000</td>\n",
       "      <td>123881.000000</td>\n",
       "      <td>119887.000000</td>\n",
       "      <td>119291.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockCum_KNOWN</th>\n",
       "      <td>0.250641</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.152027</td>\n",
       "      <td>0.140136</td>\n",
       "      <td>0.134388</td>\n",
       "      <td>0.132488</td>\n",
       "      <td>0.130846</td>\n",
       "      <td>0.129774</td>\n",
       "      <td>0.125590</td>\n",
       "      <td>0.124966</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block_UNHAPPY</th>\n",
       "      <td>0.703384</td>\n",
       "      <td>0.464378</td>\n",
       "      <td>0.419583</td>\n",
       "      <td>0.391172</td>\n",
       "      <td>0.487630</td>\n",
       "      <td>0.519013</td>\n",
       "      <td>0.610122</td>\n",
       "      <td>0.665042</td>\n",
       "      <td>0.783720</td>\n",
       "      <td>0.811916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nblock_UNHAPPY</th>\n",
       "      <td>2931.000000</td>\n",
       "      <td>6453.000000</td>\n",
       "      <td>7636.000000</td>\n",
       "      <td>7063.000000</td>\n",
       "      <td>7569.000000</td>\n",
       "      <td>6060.000000</td>\n",
       "      <td>5859.000000</td>\n",
       "      <td>4777.000000</td>\n",
       "      <td>6287.000000</td>\n",
       "      <td>5301.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockCum_UNHAPPY</th>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_UNKNOWN</th>\n",
       "      <td>0.957780</td>\n",
       "      <td>0.963744</td>\n",
       "      <td>0.964990</td>\n",
       "      <td>0.967851</td>\n",
       "      <td>0.965788</td>\n",
       "      <td>0.974574</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>0.987030</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.991858</td>\n",
       "      <td>0.993324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_KNOWN</th>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.892985</td>\n",
       "      <td>0.802189</td>\n",
       "      <td>0.732150</td>\n",
       "      <td>0.665363</td>\n",
       "      <td>0.641860</td>\n",
       "      <td>0.669030</td>\n",
       "      <td>0.878293</td>\n",
       "      <td>0.833456</td>\n",
       "      <td>0.776140</td>\n",
       "      <td>0.719511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_HAPPY</th>\n",
       "      <td>0.640923</td>\n",
       "      <td>0.660922</td>\n",
       "      <td>0.749200</td>\n",
       "      <td>0.779623</td>\n",
       "      <td>0.808173</td>\n",
       "      <td>0.840274</td>\n",
       "      <td>0.827747</td>\n",
       "      <td>0.828817</td>\n",
       "      <td>0.848136</td>\n",
       "      <td>0.858391</td>\n",
       "      <td>0.850792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_UNHAPPY</th>\n",
       "      <td>0.634789</td>\n",
       "      <td>0.592680</td>\n",
       "      <td>0.635013</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.697447</td>\n",
       "      <td>0.679875</td>\n",
       "      <td>0.709254</td>\n",
       "      <td>0.718323</td>\n",
       "      <td>0.713070</td>\n",
       "      <td>0.717167</td>\n",
       "      <td>0.738769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_MILDLY UNHAPPY</th>\n",
       "      <td>0.570339</td>\n",
       "      <td>0.582812</td>\n",
       "      <td>0.597833</td>\n",
       "      <td>0.620083</td>\n",
       "      <td>0.642760</td>\n",
       "      <td>0.662906</td>\n",
       "      <td>0.690769</td>\n",
       "      <td>0.703961</td>\n",
       "      <td>0.708536</td>\n",
       "      <td>0.709510</td>\n",
       "      <td>0.717887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_MEDIUM UNHAPPY</th>\n",
       "      <td>0.518530</td>\n",
       "      <td>0.521901</td>\n",
       "      <td>0.523902</td>\n",
       "      <td>0.528841</td>\n",
       "      <td>0.535179</td>\n",
       "      <td>0.538826</td>\n",
       "      <td>0.555522</td>\n",
       "      <td>0.573664</td>\n",
       "      <td>0.595948</td>\n",
       "      <td>0.611325</td>\n",
       "      <td>0.613877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold_HEAVILY UNHAPPY</th>\n",
       "      <td>0.503309</td>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.482482</td>\n",
       "      <td>0.474807</td>\n",
       "      <td>0.478955</td>\n",
       "      <td>0.470693</td>\n",
       "      <td>0.475613</td>\n",
       "      <td>0.475529</td>\n",
       "      <td>0.480784</td>\n",
       "      <td>0.496976</td>\n",
       "      <td>0.489021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0              1              2  \\\n",
       "%classified                     0.389673       0.548674       0.649158   \n",
       "N_classified               371978.000000  151781.000000   95921.000000   \n",
       "N_predicted                954590.000000  582612.000000  430831.000000   \n",
       "leaf_accuracy                   0.907040       0.941159       0.952961   \n",
       "total_leaf_accuracy             0.907040       0.916927       0.922505   \n",
       "leaf_precision                  0.939998       0.965407       0.972158   \n",
       "total_leaf_precision            0.939998       0.947748       0.951807   \n",
       "leaf_recall                     0.879901       0.926713       0.945047   \n",
       "total_leaf_recall               0.879901       0.893930       0.902219   \n",
       "label_precision                 0.950019       0.968139       0.975530   \n",
       "label_recall                    0.694441       0.673916       0.647766   \n",
       "block_precision                 0.974947       0.972517       0.979208   \n",
       "block_recall                    0.461266       0.469965       0.483149   \n",
       "block_Nchange                        NaN       0.093113       0.060670   \n",
       "block_Pchange                        NaN       0.305884       0.249340   \n",
       "tree_error                      0.308669       0.195591       0.153918   \n",
       "option                          2.000000       2.000000       2.000000   \n",
       "certainty                       0.700000       0.700000       0.700000   \n",
       "precision_UNKNOWN               0.917361       0.921308       0.932704   \n",
       "recall_UNKNOWN                  0.787460       0.797106       0.822589   \n",
       "f1_UNKNOWN                      0.847462       0.854719       0.874192   \n",
       "precision_HAPPY                 0.946561       0.976523       0.985244   \n",
       "recall_HAPPY                    0.909102       0.954151       0.970917   \n",
       "f1_HAPPY                        0.927453       0.965207       0.978028   \n",
       "precision_MILDLY UNHAPPY        0.668412       0.943464       0.960883   \n",
       "recall_MILDLY UNHAPPY           0.789691       0.961993       0.973229   \n",
       "f1_MILDLY UNHAPPY               0.724008       0.952638       0.967017   \n",
       "precision_MEDIUM UNHAPPY        0.941781       0.934579       0.920290   \n",
       "recall_MEDIUM UNHAPPY           0.941781       0.934579       0.924437   \n",
       "f1_MEDIUM UNHAPPY               0.941781       0.934579       0.922359   \n",
       "precision_HEAVILY UNHAPPY       0.998229       0.998773       0.988866   \n",
       "recall_HEAVILY UNHAPPY          0.998229       0.998773       0.988866   \n",
       "f1_HEAVILY UNHAPPY              0.998229       0.998773       0.988866   \n",
       "precision_KNOWN                 0.979984       0.981898       0.985605   \n",
       "recall_KNOWN                    0.459155       0.461264       0.471415   \n",
       "f1_KNOWN                        0.625325       0.627669       0.637780   \n",
       "precision_UNHAPPY               0.769362       0.860530       0.918413   \n",
       "recall_UNHAPPY                  0.606101       0.632496       0.647493   \n",
       "f1_UNHAPPY                      0.678043       0.729099       0.759517   \n",
       "block_ORDERS                    0.356616       0.463957       0.422790   \n",
       "Nblock_ORDERS              340422.000000  270307.000000  182151.000000   \n",
       "blockCum_ORDERS                 0.356616       0.283166       0.190816   \n",
       "block_KNOWN                     0.499785       0.572978       0.655882   \n",
       "Nblock_KNOWN               239259.000000  154071.000000  145123.000000   \n",
       "blockCum_KNOWN                  0.250641       0.161400       0.152027   \n",
       "block_UNHAPPY                   0.703384       0.464378       0.419583   \n",
       "Nblock_UNHAPPY               2931.000000    6453.000000    7636.000000   \n",
       "blockCum_UNHAPPY                0.003070       0.006760       0.007999   \n",
       "threshold_UNKNOWN               0.957780       0.963744       0.964990   \n",
       "threshold_KNOWN                 0.898138       0.892985       0.802189   \n",
       "threshold_HAPPY                 0.640923       0.660922       0.749200   \n",
       "threshold_UNHAPPY               0.634789       0.592680       0.635013   \n",
       "threshold_MILDLY UNHAPPY        0.570339       0.582812       0.597833   \n",
       "threshold_MEDIUM UNHAPPY        0.518530       0.521901       0.523902   \n",
       "threshold_HEAVILY UNHAPPY       0.503309       0.487983       0.482482   \n",
       "\n",
       "                                       3              4              5  \\\n",
       "%classified                     0.708673       0.753399       0.776252   \n",
       "N_classified                56812.000000   42695.000000   21815.000000   \n",
       "N_predicted                334910.000000  278098.000000  235403.000000   \n",
       "leaf_accuracy                   0.953197       0.957021       0.960761   \n",
       "total_leaf_accuracy             0.925083       0.926979       0.927973   \n",
       "leaf_precision                  0.973109       0.974015       0.977949   \n",
       "total_leaf_precision            0.953711       0.954891       0.955604   \n",
       "leaf_recall                     0.946235       0.945776       0.960042   \n",
       "total_leaf_recall               0.906063       0.908323       0.909874   \n",
       "label_precision                 0.980693       0.981588       0.993608   \n",
       "label_recall                    0.611142       0.588473       0.557477   \n",
       "block_precision                 0.985990       0.985351       0.998030   \n",
       "block_recall                    0.491220       0.496361       0.499518   \n",
       "block_Nchange                   0.055375       0.034253       0.021118   \n",
       "block_Pchange                   0.141131       0.091582       0.051526   \n",
       "tree_error                      0.149440       0.136597       0.112583   \n",
       "option                          2.000000       2.000000       2.000000   \n",
       "certainty                       0.700000       0.700000       0.700000   \n",
       "precision_UNKNOWN               0.944955       0.957956       0.970422   \n",
       "recall_UNKNOWN                  0.851351       0.883651       0.916223   \n",
       "f1_UNKNOWN                      0.895714       0.919304       0.942544   \n",
       "precision_HAPPY                 0.985516       0.988595       0.988588   \n",
       "recall_HAPPY                    0.971445       0.977447       0.977433   \n",
       "f1_HAPPY                        0.978430       0.982990       0.982979   \n",
       "precision_MILDLY UNHAPPY        0.979843       0.984925       0.984599   \n",
       "recall_MILDLY UNHAPPY           0.982613       0.984925       0.984599   \n",
       "f1_MILDLY UNHAPPY               0.981226       0.984925       0.984599   \n",
       "precision_MEDIUM UNHAPPY        0.922971       0.916028       0.934438   \n",
       "recall_MEDIUM UNHAPPY           0.930882       0.918896       0.935406   \n",
       "f1_MEDIUM UNHAPPY               0.926910       0.917460       0.934921   \n",
       "precision_HEAVILY UNHAPPY       0.955975       0.938484       0.953052   \n",
       "recall_HEAVILY UNHAPPY          0.964059       0.946609       0.959055   \n",
       "f1_HEAVILY UNHAPPY              0.960000       0.942529       0.956044   \n",
       "precision_KNOWN                 0.991373       0.997443       0.999375   \n",
       "recall_KNOWN                    0.479468       0.485086       0.488157   \n",
       "f1_KNOWN                        0.646340       0.652730       0.655921   \n",
       "precision_UNHAPPY               0.935013       0.882878       0.983993   \n",
       "recall_UNHAPPY                  0.651571       0.638435       0.663071   \n",
       "f1_UNHAPPY                      0.767974       0.741018       0.792267   \n",
       "block_ORDERS                    0.409850       0.357964       0.344329   \n",
       "Nblock_ORDERS              137263.000000   99549.000000   81056.000000   \n",
       "blockCum_ORDERS                 0.143793       0.104285       0.084912   \n",
       "block_KNOWN                     0.758616       0.819833       0.876829   \n",
       "Nblock_KNOWN               133772.000000  128285.000000  126472.000000   \n",
       "blockCum_KNOWN                  0.140136       0.134388       0.132488   \n",
       "block_UNHAPPY                   0.391172       0.487630       0.519013   \n",
       "Nblock_UNHAPPY               7063.000000    7569.000000    6060.000000   \n",
       "blockCum_UNHAPPY                0.007399       0.007929       0.006348   \n",
       "threshold_UNKNOWN               0.967851       0.965788       0.974574   \n",
       "threshold_KNOWN                 0.732150       0.665363       0.641860   \n",
       "threshold_HAPPY                 0.779623       0.808173       0.840274   \n",
       "threshold_UNHAPPY               0.633122       0.697447       0.679875   \n",
       "threshold_MILDLY UNHAPPY        0.620083       0.642760       0.662906   \n",
       "threshold_MEDIUM UNHAPPY        0.528841       0.535179       0.538826   \n",
       "threshold_HEAVILY UNHAPPY       0.474807       0.478955       0.470693   \n",
       "\n",
       "                                       6              7              8  \\\n",
       "%classified                     0.787030       0.792993       0.798207   \n",
       "N_classified                10289.000000    5692.000000    4977.000000   \n",
       "N_predicted                213588.000000  203299.000000  197607.000000   \n",
       "leaf_accuracy                   0.955584       0.956606       0.960217   \n",
       "total_leaf_accuracy             0.928351       0.928564       0.928771   \n",
       "leaf_precision                  0.978356       0.981217       0.981719   \n",
       "total_leaf_precision            0.955980       0.956235       0.956446   \n",
       "leaf_recall                     0.967589       0.975874       0.974789   \n",
       "total_leaf_recall               0.910794       0.911424       0.911927   \n",
       "label_precision                 0.996568       0.998254       0.998562   \n",
       "label_recall                    0.534289       0.519787       0.522629   \n",
       "block_precision                 0.999407       0.999933       0.999940   \n",
       "block_recall                    0.500110       0.497311       0.503867   \n",
       "block_Nchange                   0.007508       0.011609       0.002277   \n",
       "block_Pchange                   0.032920       0.028211       0.038746   \n",
       "tree_error                      0.112645       0.099438       0.095037   \n",
       "option                          2.000000       2.000000       2.000000   \n",
       "certainty                       0.700000       0.700000       0.700000   \n",
       "precision_UNKNOWN               0.973536       0.982812       0.983683   \n",
       "recall_UNKNOWN                  0.924599       0.950151       0.952596   \n",
       "f1_UNKNOWN                      0.948437       0.966206       0.967890   \n",
       "precision_HAPPY                 0.988501       0.990552       0.989723   \n",
       "recall_HAPPY                    0.977263       0.981280       0.979655   \n",
       "f1_HAPPY                        0.982850       0.985894       0.984664   \n",
       "precision_MILDLY UNHAPPY        0.986676       0.985300       0.983046   \n",
       "recall_MILDLY UNHAPPY           0.986676       0.985300       0.983046   \n",
       "f1_MILDLY UNHAPPY               0.986676       0.985300       0.983046   \n",
       "precision_MEDIUM UNHAPPY        0.931142       0.935504       0.936087   \n",
       "recall_MEDIUM UNHAPPY           0.931142       0.935504       0.936087   \n",
       "f1_MEDIUM UNHAPPY               0.931142       0.935504       0.936087   \n",
       "precision_HEAVILY UNHAPPY       0.969697       0.980676       0.985876   \n",
       "recall_HEAVILY UNHAPPY          0.977597       0.980676       0.985876   \n",
       "f1_HEAVILY UNHAPPY              0.973631       0.980676       0.985876   \n",
       "precision_KNOWN                 0.999664       0.999927       0.999933   \n",
       "recall_KNOWN                    0.488727       0.487754       0.491283   \n",
       "f1_KNOWN                        0.656498       0.655676       0.658859   \n",
       "precision_UNHAPPY               0.996672       1.000000       1.000000   \n",
       "recall_UNHAPPY                  0.665925       0.666667       0.666667   \n",
       "f1_UNHAPPY                      0.798400       0.800000       0.800000   \n",
       "block_ORDERS                    0.339607       0.339151       0.336304   \n",
       "Nblock_ORDERS               72536.000000   68949.000000   66456.000000   \n",
       "blockCum_ORDERS                 0.075987       0.072229       0.069617   \n",
       "block_KNOWN                     0.904911       0.926490       0.920134   \n",
       "Nblock_KNOWN               124904.000000  123881.000000  119887.000000   \n",
       "blockCum_KNOWN                  0.130846       0.129774       0.125590   \n",
       "block_UNHAPPY                   0.610122       0.665042       0.783720   \n",
       "Nblock_UNHAPPY               5859.000000    4777.000000    6287.000000   \n",
       "blockCum_UNHAPPY                0.006138       0.005004       0.006586   \n",
       "threshold_UNKNOWN               0.981420       0.987030       0.990040   \n",
       "threshold_KNOWN                 0.669030       0.878293       0.833456   \n",
       "threshold_HAPPY                 0.827747       0.828817       0.848136   \n",
       "threshold_UNHAPPY               0.709254       0.718323       0.713070   \n",
       "threshold_MILDLY UNHAPPY        0.690769       0.703961       0.708536   \n",
       "threshold_MEDIUM UNHAPPY        0.555522       0.573664       0.595948   \n",
       "threshold_HEAVILY UNHAPPY       0.475613       0.475529       0.480784   \n",
       "\n",
       "                                       9             10  \n",
       "%classified                     0.802316       1.000000  \n",
       "N_classified                 3923.000000  188707.000000  \n",
       "N_predicted                192630.000000  188707.000000  \n",
       "leaf_accuracy                   0.970941       0.967187  \n",
       "total_leaf_accuracy             0.928987       0.936538  \n",
       "leaf_precision                  0.985651       0.980724  \n",
       "total_leaf_precision            0.956622       0.961357  \n",
       "leaf_recall                     0.979855       0.960087  \n",
       "total_leaf_recall               0.912319       0.921509  \n",
       "label_precision                 0.999115       0.980724  \n",
       "label_recall                    0.514938       0.960087  \n",
       "block_precision                 0.999938            NaN  \n",
       "block_recall                    0.500617            NaN  \n",
       "block_Nchange                   0.011682       0.000000  \n",
       "block_Pchange                   0.020884       1.000000  \n",
       "tree_error                      0.070099       0.102646  \n",
       "option                          2.000000       2.000000  \n",
       "certainty                       0.700000       0.700000  \n",
       "precision_UNKNOWN               0.990257       0.965566  \n",
       "recall_UNKNOWN                  0.971329       0.905298  \n",
       "f1_UNKNOWN                      0.980702       0.934461  \n",
       "precision_HAPPY                 0.992018       0.988248  \n",
       "recall_HAPPY                    0.984162       0.976769  \n",
       "f1_HAPPY                        0.988074       0.982475  \n",
       "precision_MILDLY UNHAPPY        0.985997       0.970088  \n",
       "recall_MILDLY UNHAPPY           0.985997       0.971059  \n",
       "f1_MILDLY UNHAPPY               0.985997       0.970574  \n",
       "precision_MEDIUM UNHAPPY        0.940129       0.917516  \n",
       "recall_MEDIUM UNHAPPY           0.940129       0.919220  \n",
       "f1_MEDIUM UNHAPPY               0.940129       0.918367  \n",
       "precision_HEAVILY UNHAPPY       1.000000       0.759386  \n",
       "recall_HEAVILY UNHAPPY          1.000000       0.759386  \n",
       "f1_HEAVILY UNHAPPY              1.000000       0.759386  \n",
       "precision_KNOWN                 0.999933            NaN  \n",
       "recall_KNOWN                    0.489774            NaN  \n",
       "f1_KNOWN                        0.657500            NaN  \n",
       "precision_UNHAPPY               1.000000            NaN  \n",
       "recall_UNHAPPY                  0.666667            NaN  \n",
       "f1_UNHAPPY                      0.800000            NaN  \n",
       "block_ORDERS                    0.332840            NaN  \n",
       "Nblock_ORDERS               64115.000000            NaN  \n",
       "blockCum_ORDERS                 0.067165            NaN  \n",
       "block_KNOWN                     0.936453            NaN  \n",
       "Nblock_KNOWN               119291.000000            NaN  \n",
       "blockCum_KNOWN                  0.124966            NaN  \n",
       "block_UNHAPPY                   0.811916            NaN  \n",
       "Nblock_UNHAPPY               5301.000000            NaN  \n",
       "blockCum_UNHAPPY                0.005553            NaN  \n",
       "threshold_UNKNOWN               0.991858       0.993324  \n",
       "threshold_KNOWN                 0.776140       0.719511  \n",
       "threshold_HAPPY                 0.858391       0.850792  \n",
       "threshold_UNHAPPY               0.717167       0.738769  \n",
       "threshold_MILDLY UNHAPPY        0.709510       0.717887  \n",
       "threshold_MEDIUM UNHAPPY        0.611325       0.613877  \n",
       "threshold_HEAVILY UNHAPPY       0.496976       0.489021  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/LV/Desktop/Statistics/Final/statistics_2_0.7.json') as f:\n",
    "    statistics = json.load(f)\n",
    "\n",
    "results = pd.DataFrame.from_dict(statistics)\n",
    "\n",
    "for ix, node in enumerate(['ORDERS','KNOWN','UNHAPPY']):\n",
    "    col_name1 = 'block_'+node\n",
    "    results[col_name1] = results['%blocking'].apply(lambda x: x[node])\n",
    "    col_name2 = 'Nblock_'+node\n",
    "    results[col_name2] = results['%Tblocking'].apply(lambda x: x[node])\n",
    "    col_name3 = 'blockCum_'+node\n",
    "    results[col_name3] = results[col_name2] / results['N_predicted'].iloc[0]\n",
    "for ix, node in enumerate(['UNKNOWN','KNOWN','HAPPY','UNHAPPY','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']):\n",
    "    col_name = 'threshold_'+node\n",
    "    results[col_name] = results['thresholds'].apply(lambda x: x[node])\n",
    "\n",
    "results_plot = results.drop(['%blocking','%Tblocking','thresholds'], axis = 1)\n",
    "results = results_plot.transpose()\n",
    "\n",
    "# with pd.ExcelWriter('/Users/LV/Desktop/OUTPUT.xlsx', mode = 'a', engine = 'openpyxl') as writer: \n",
    "#     results.to_excel(writer, sheet_name = 'LRRFRF-O2C70-2') #CHANGE SHEET NAME!\n",
    "\n",
    "#feature_importances.to_excel('/Users/LV/Desktop/OUTPUT_featureimportance.xlsx')\n",
    "#pred.to_csv('/Users/LV/Desktop/OUTPUT_pred.xlsx')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T15:54:19.689278Z",
     "iopub.status.busy": "2021-03-03T15:54:19.688980Z",
     "iopub.status.idle": "2021-03-03T15:54:19.708284Z",
     "shell.execute_reply": "2021-03-03T15:54:19.705467Z",
     "shell.execute_reply.started": "2021-03-03T15:54:19.689249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 87.99)(1, 92.67)(2, 94.5)(3, 94.62)(4, 94.58)(5, 96.0)(6, 96.76)(7, 97.59)(8, 97.48)(9, 97.99)(10, 96.01)"
     ]
    }
   ],
   "source": [
    "# LATEX COORDINATES GENERATOR\n",
    "col = results_plot['leaf_recall']\n",
    "for i in range(11):\n",
    "    print((i,round(col[i]*100,2)), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T12:14:08.657483Z",
     "iopub.status.busy": "2021-03-03T12:14:08.657202Z",
     "iopub.status.idle": "2021-03-03T12:14:08.666964Z",
     "shell.execute_reply": "2021-03-03T12:14:08.665710Z",
     "shell.execute_reply.started": "2021-03-03T12:14:08.657459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 91.61)(1, 96.55)(2, 97.07)(3, 96.82)(4, 96.65)(5, 97.3)(6, 98.05)(7, 97.42)(8, 98.35)(9, 98.32)(10, 97.63)"
     ]
    }
   ],
   "source": [
    "# LATEX COORDINATES GENERATOR\n",
    "col = results_plot['leaf_accuracy']\n",
    "for i in range(11):\n",
    "    print((i,round(col[i]*100,2)), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T16:17:00.456805Z",
     "iopub.status.busy": "2021-03-03T16:17:00.456499Z",
     "iopub.status.idle": "2021-03-03T16:17:00.464755Z",
     "shell.execute_reply": "2021-03-03T16:17:00.463747Z",
     "shell.execute_reply.started": "2021-03-03T16:17:00.456781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 90.9)(1, 94.57)(2, 95.84)(3, 95.95)(4, 95.97)(5, 96.89)(6, 97.29)(7, 97.85)(8, 97.82)(9, 98.27)(10, 97.03)"
     ]
    }
   ],
   "source": [
    "precision_col = results_plot['leaf_precision']\n",
    "recall_col = results_plot['leaf_recall']\n",
    "beta = 1\n",
    "for i in range(11):\n",
    "    f1 = ((beta ** 2 + 1) * precision_col[i] * recall_col[i]) / ((beta ** 2 * precision_col[i]) + recall_col[i])\n",
    "    print((i,round(f1*100,2)), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-23T11:27:36.736165Z",
     "iopub.status.busy": "2021-02-23T11:27:36.735878Z",
     "iopub.status.idle": "2021-02-23T11:27:37.057709Z",
     "shell.execute_reply": "2021-02-23T11:27:37.055693Z",
     "shell.execute_reply.started": "2021-02-23T11:27:36.736139Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot parameters\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Colors\n",
    "bol_darkblue  = '#0009AA' #dark blue\n",
    "bol_lightblue = '#D2EFFF' #light blue\n",
    "bol_happy     = '#26DD8C' #green\n",
    "bol_unknown   = '#BFBFBF' #grey\n",
    "bol_mildly    = '#FFBC89' #light orange\n",
    "bol_medium    = '#FF7B18' #medium orange\n",
    "bol_heavy     = '#D23C00' #red\n",
    "bol_order     = '#78CEFF' #light blue\n",
    "bol_lines     = '#B7B18B' #taupe\n",
    "\n",
    "### Plotten\n",
    "#plt.plot(data, color = , marker = , linewidth = , label = , clip_on = False)\n",
    "plt.figure(figsize = (16,8))\n",
    "\n",
    "plt.plot(results_plot['%classified']*100  , color = bol_darkblue, marker = 'o', label = 'Classified', clip_on = False)\n",
    "plt.plot(results_plot['leaf_accuracy']*100, color = bol_medium  , marker = 'o', label = 'Accuracy')\n",
    "\n",
    "### Titel\n",
    "plt.title('', fontweight = 'bold')\n",
    "\n",
    "### Assen\n",
    "plt.ylabel('Percentage', fontweight = 'normal')\n",
    "plt.ylim(30,100)\n",
    "\n",
    "plt.xlabel('Days after order date', fontweight = 'normal')\n",
    "plt.xticks(range(11))\n",
    "#plt.xlim(-0.1, 30.1)\n",
    "\n",
    "### Legend\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "### Grafiek Lay-out\n",
    "plt.grid(color='#C0C0C0', linestyle='--', linewidth=1, axis='y')\n",
    "plt.tick_params(axis='x', direction='in', length=5, colors='black')\n",
    "plt.tick_params(axis='y', length=0)\n",
    "sns.despine(left=False, bottom=False, right=True)\n",
    "\n",
    "#plt.savefig('plot.png',dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### CAT-HCOT (Flavius Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T20:55:07.624593Z",
     "iopub.status.busy": "2021-03-09T20:55:07.624017Z",
     "iopub.status.idle": "2021-03-09T20:55:07.663408Z",
     "shell.execute_reply": "2021-03-09T20:55:07.661763Z",
     "shell.execute_reply.started": "2021-03-09T20:55:07.624543Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamicFullHierarchicalClassifier(START, END, threshold = None, threshold_type = None):  \n",
    "  \n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "    \n",
    "    hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "                           '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "                           '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "                           '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "    \n",
    "#     # Lourens\n",
    "    OPTION = 2\n",
    "    certainties = [0.6,0.7,0.8]\n",
    "    \n",
    "#     # Thomas\n",
    "#     OPTION = 2\n",
    "#     certainties = [0.3, 0.4, 0.5]\n",
    "    \n",
    "#     # Jim\n",
    "#     OPTION = 2\n",
    "#     certainties = [0.9, 1.0]\n",
    "    \n",
    "    # Mathilde\n",
    "#     OPTION = 2\n",
    "#     certainties = [0, 0.1, 0.2]\n",
    "    \n",
    "    statistics, previous_pred_block, feature_importances = None, None, None\n",
    "    \n",
    "    for CERTAINTY in certainties:  \n",
    "        for DAYS in range(START, END+1):\n",
    "\n",
    "            X, y = functions.dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "            X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "            y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "            X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "            y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "            X_test = X.iloc[int(0.8*len(X)):]\n",
    "            y_test = y.iloc[int(0.8*len(y)):]\n",
    "            #print('Data pre-processing done')\n",
    "\n",
    "            N_test = len(y_test)\n",
    "\n",
    "            HC = HierarchicalClassifier(Tree)\n",
    "            HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "                                'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "                                'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "\n",
    "            HC = HC.fit(X_train,y_train)\n",
    "\n",
    "            y_train_hat = HC.get_probabilities(X_train, y_train)\n",
    "            probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "\n",
    "            THRESHOLDS = {}\n",
    "            for node in range(1,8):\n",
    "                name, threshold = opt_threshold(probs, node, DAYS, CERTAINTY, OPTION)\n",
    "                THRESHOLDS[name] = threshold\n",
    "\n",
    "            if DAYS == START: #create dataframe to save predictions\n",
    "                y_hat = pd.DataFrame([Tree.root] * len(X_test),\n",
    "                                        columns=[DAYS],\n",
    "                                        index=X_test.index)\n",
    "                index_no_leaf = X_test.index\n",
    "            else:\n",
    "                y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "            if DAYS < END:\n",
    "                pred = HC.predict_proba2(X_test, THRESHOLDS = THRESHOLDS)  #DIFFERENCE ALL TESTING EACH DAY!\n",
    "\n",
    "                check_no_leaf = ~pred.isin(Tree._get_leaf_nodes())\n",
    "                index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "                check_leaf    = pred.isin(Tree._get_leaf_nodes())      #from current non_leaf predictions which are now leaf\n",
    "                index_leaf    = check_leaf[check_leaf].index\n",
    "                y_hat_stage   = pd.DataFrame(pred, index = index_leaf)\n",
    "            else:\n",
    "                pred        = HC.predict(X_test) #last day you want a label for each order\n",
    "                y_hat_stage = pd.DataFrame(pred, index = X_test.index)\n",
    "                index_leaf  = X_test.index\n",
    "\n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            #y_hat.stage_col = y_hat.stage_col.fillna(y_hat[DAYS]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(DAYS, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "                \n",
    "            current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "\n",
    "            statistics, feature_importances, previous_pred_block = get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, \n",
    "                                                                                   previous_pred_block, THRESHOLDS, OPTION, CERTAINTY, y_test, Tree, HC, feature_importances, statistics)\n",
    "            \n",
    "            if DAYS == 0:\n",
    "                previous_leaf = index_leaf\n",
    "                cumu_leaf = index_leaf\n",
    "                statistics['leaf_improve'] = {}\n",
    "                statistics['cum%classified'] = {}\n",
    "                statistics['cum%classified'][DAYS] = len(index_leaf) / N_test\n",
    "            else:\n",
    "                index_intersect = previous_leaf.intersection(index_leaf)\n",
    "                acc_prev = metrics.accuracy_score(y_test.loc[index_intersect], y_hat[DAYS - 1].loc[index_intersect])\n",
    "                acc_now = metrics.accuracy_score(y_test.loc[index_intersect], y_hat[DAYS].loc[index_intersect])\n",
    "                acc_diff = (acc_now - acc_prev)/acc_prev\n",
    "                statistics['leaf_improve'][DAYS] = acc_diff\n",
    "                statistics['cum%classified'][DAYS] = len(cumu_leaf.union(index_leaf)) / N_test\n",
    "                cumu_leaf = cumu_leaf.union(index_leaf)\n",
    "                previous_leaf = index_leaf\n",
    "            \n",
    "            file_name = 'statistics_full_'+str(CERTAINTY)+'.json'\n",
    "            path_name = '/Users/LV/Desktop/' + file_name\n",
    "            with open(path_name, 'w') as f:\n",
    "                json.dump(statistics, f, cls = NumpyEncoder)\n",
    "\n",
    "            print('DAYS: ',DAYS)\n",
    "     \n",
    "    final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "    return y_hat, statistics, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T20:55:26.653184Z",
     "iopub.status.busy": "2021-03-09T20:55:26.652847Z",
     "iopub.status.idle": "2021-03-10T11:49:53.624411Z",
     "shell.execute_reply": "2021-03-10T11:49:53.620017Z",
     "shell.execute_reply.started": "2021-03-09T20:55:26.653145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n",
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n",
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "y_hat, statistics, feature_importances = dynamicFullHierarchicalClassifier(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-03-09T20:38:52.838175Z",
     "iopub.status.busy": "2021-03-09T20:38:52.837875Z",
     "iopub.status.idle": "2021-03-09T20:38:52.860847Z",
     "shell.execute_reply": "2021-03-09T20:38:52.859394Z",
     "shell.execute_reply.started": "2021-03-09T20:38:52.838148Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'%classified': {0: 0.40549,\n",
       "  1: 0.48413,\n",
       "  2: 0.58787,\n",
       "  3: 0.63512,\n",
       "  4: 0.67787,\n",
       "  5: 0.70019,\n",
       "  6: 1.0},\n",
       " 'N_classified': {0: 40549,\n",
       "  1: 48413,\n",
       "  2: 58787,\n",
       "  3: 63512,\n",
       "  4: 67787,\n",
       "  5: 70019,\n",
       "  6: 100000},\n",
       " 'N_predicted': {0: 100000,\n",
       "  1: 100000,\n",
       "  2: 100000,\n",
       "  3: 100000,\n",
       "  4: 100000,\n",
       "  5: 100000,\n",
       "  6: 100000},\n",
       " 'leaf_accuracy': {0: 0.9026856395965375,\n",
       "  1: 0.9375167826823374,\n",
       "  2: 0.9570993587017538,\n",
       "  3: 0.9662583448797077,\n",
       "  4: 0.9715284641597947,\n",
       "  5: 0.9764492494894244,\n",
       "  6: 0.96602},\n",
       " 'total_leaf_accuracy': {0: 0.9026856395965375,\n",
       "  1: 0.9375167826823374,\n",
       "  2: 0.9570993587017538,\n",
       "  3: 0.9662583448797077,\n",
       "  4: 0.9715284641597947,\n",
       "  5: 0.9764492494894244,\n",
       "  6: 0.96602},\n",
       " 'leaf_precision': {0: 0.9372120416896537,\n",
       "  1: 0.9600792681406884,\n",
       "  2: 0.9729761485136882,\n",
       "  3: 0.9800079069851025,\n",
       "  4: 0.9832536496816915,\n",
       "  5: 0.9865018158077284,\n",
       "  6: 0.9801494361868638},\n",
       " 'total_leaf_precision': {0: 0.9372120416896537,\n",
       "  1: 0.9600792681406884,\n",
       "  2: 0.9729761485136882,\n",
       "  3: 0.9800079069851025,\n",
       "  4: 0.9832536496816915,\n",
       "  5: 0.9865018158077284,\n",
       "  6: 0.9801494361868638},\n",
       " 'leaf_recall': {0: 0.8769340234663839,\n",
       "  1: 0.91549898384854,\n",
       "  2: 0.9453376205787781,\n",
       "  3: 0.9568295464514431,\n",
       "  4: 0.9631596083047409,\n",
       "  5: 0.9705185744221335,\n",
       "  6: 0.9573234690233887},\n",
       " 'total_leaf_recall': {0: 0.8769340234663839,\n",
       "  1: 0.91549898384854,\n",
       "  2: 0.9453376205787781,\n",
       "  3: 0.9568295464514431,\n",
       "  4: 0.9631596083047409,\n",
       "  5: 0.9705185744221335,\n",
       "  6: 0.9573234690233887},\n",
       " 'label_precision': {0: 0.9482114845010052,\n",
       "  1: 0.9642041867016368,\n",
       "  2: 0.974388623726812,\n",
       "  3: 0.9810814723384154,\n",
       "  4: 0.9839197499747958,\n",
       "  5: 0.9882226382408003,\n",
       "  6: 0.9801494361868638},\n",
       " 'label_recall': {0: 0.7056918055429948,\n",
       "  1: 0.7517646702414493,\n",
       "  2: 0.8154546203261407,\n",
       "  3: 0.8354788476511809,\n",
       "  4: 0.8413103044856993,\n",
       "  5: 0.8539316347657075,\n",
       "  6: 0.9573234690233887},\n",
       " 'block_precision': {0: 0.9796631848219995,\n",
       "  1: 0.9787768041918014,\n",
       "  2: 0.9816722205392305,\n",
       "  3: 0.987069613591941,\n",
       "  4: 0.987550517954197,\n",
       "  5: 0.9984481838902091,\n",
       "  6: None},\n",
       " 'block_recall': {0: 0.4599831845297674,\n",
       "  1: 0.46411942791523125,\n",
       "  2: 0.47905681762184005,\n",
       "  3: 0.4907799651133815,\n",
       "  4: 0.49882678680369796,\n",
       "  5: 0.5007539643934235,\n",
       "  6: None},\n",
       " 'block_Nchange': {0: None,\n",
       "  1: 0.08479582227549011,\n",
       "  2: 0.057966466421590604,\n",
       "  3: 0.0530844240496428,\n",
       "  4: 0.03430962343096234,\n",
       "  5: 0.018510335346393677,\n",
       "  6: 0.0005087763927753752},\n",
       " 'block_Pchange': {0: None,\n",
       "  1: 0.325913877236538,\n",
       "  2: 0.44163005469380434,\n",
       "  3: 0.2584867288939876,\n",
       "  4: 0.19408995815899582,\n",
       "  5: 0.21598664506309226,\n",
       "  6: 0.9994912236072246},\n",
       " '%blocking': {0: {'ORDERS': 0.36089000000000004,\n",
       "   'KNOWN': 0.4680290443912545,\n",
       "   'UNHAPPY': 0.36328125},\n",
       "  1: {'ORDERS': 0.29281,\n",
       "   'KNOWN': 0.41615520550287877,\n",
       "   'UNHAPPY': 0.21259842519685035},\n",
       "  2: {'ORDERS': 0.22036,\n",
       "   'KNOWN': 0.31530811729706754,\n",
       "   'UNHAPPY': 0.14539990753582988},\n",
       "  3: {'ORDERS': 0.17367999999999995,\n",
       "   'KNOWN': 0.2966838638502223,\n",
       "   'UNHAPPY': 0.13662456946039037},\n",
       "  4: {'ORDERS': 0.11846000000000001,\n",
       "   'KNOWN': 0.30223921698217127,\n",
       "   'UNHAPPY': 0.1540504648074369},\n",
       "  5: {'ORDERS': 0.10326000000000002,\n",
       "   'KNOWN': 0.2882636928724569,\n",
       "   'UNHAPPY': 0.11632947976878616},\n",
       "  6: {'ORDERS': None, 'KNOWN': None, 'UNHAPPY': None}},\n",
       " '%Tblocking': {0: {'ORDERS': 36089, 'KNOWN': 23269, 'UNHAPPY': 93},\n",
       "  1: {'ORDERS': 29281, 'KNOWN': 21901, 'UNHAPPY': 405},\n",
       "  2: {'ORDERS': 22036, 'KNOWN': 18548, 'UNHAPPY': 629},\n",
       "  3: {'ORDERS': 17368, 'KNOWN': 18287, 'UNHAPPY': 833},\n",
       "  4: {'ORDERS': 11846, 'KNOWN': 19207, 'UNHAPPY': 1160},\n",
       "  5: {'ORDERS': 10326, 'KNOWN': 18689, 'UNHAPPY': 966},\n",
       "  6: {'ORDERS': None, 'KNOWN': None, 'UNHAPPY': None}},\n",
       " 'tree_error': {0: 0.32138893684184566,\n",
       "  1: 0.21302129593291058,\n",
       "  2: 0.14469185364111112,\n",
       "  3: 0.11251417055044716,\n",
       "  4: 0.09408883709265789,\n",
       "  5: 0.07606506805295705,\n",
       "  6: 0.11124},\n",
       " 'thresholds': {0: {'UNKNOWN': 0.9574461417796616,\n",
       "   'KNOWN': 0.9009165664602791,\n",
       "   'HAPPY': 0.6377841360848012,\n",
       "   'UNHAPPY': 0.6421051236066674,\n",
       "   'MILDLY UNHAPPY': 0.5667034205532351,\n",
       "   'MEDIUM UNHAPPY': 0.5097879910525904,\n",
       "   'HEAVILY UNHAPPY': 0.5089886971916681},\n",
       "  1: {'UNKNOWN': 0.9628948576614446,\n",
       "   'KNOWN': 0.8955368364225927,\n",
       "   'HAPPY': 0.6536728277149911,\n",
       "   'UNHAPPY': 0.5892305291250702,\n",
       "   'MILDLY UNHAPPY': 0.5756778495963965,\n",
       "   'MEDIUM UNHAPPY': 0.5058333992310794,\n",
       "   'HEAVILY UNHAPPY': 0.4862338734136319},\n",
       "  2: {'UNKNOWN': 0.9639222617100619,\n",
       "   'KNOWN': 0.8025108777931873,\n",
       "   'HAPPY': 0.7489475848503319,\n",
       "   'UNHAPPY': 0.6195433800389695,\n",
       "   'MILDLY UNHAPPY': 0.5789994913662724,\n",
       "   'MEDIUM UNHAPPY': 0.5090189709615108,\n",
       "   'HEAVILY UNHAPPY': 0.47472466577103084},\n",
       "  3: {'UNKNOWN': 0.9667628229166014,\n",
       "   'KNOWN': 0.7332210215441697,\n",
       "   'HAPPY': 0.7820869217485062,\n",
       "   'UNHAPPY': 0.6445289621776233,\n",
       "   'MILDLY UNHAPPY': 0.5914416830818436,\n",
       "   'MEDIUM UNHAPPY': 0.5110738524117914,\n",
       "   'HEAVILY UNHAPPY': 0.4802423231453403},\n",
       "  4: {'UNKNOWN': 0.9650239780503279,\n",
       "   'KNOWN': 0.6676551787477578,\n",
       "   'HAPPY': 0.8102018081095268,\n",
       "   'UNHAPPY': 0.6779130820919271,\n",
       "   'MILDLY UNHAPPY': 0.6214765730704791,\n",
       "   'MEDIUM UNHAPPY': 0.5220635539822799,\n",
       "   'HEAVILY UNHAPPY': 0.4914228520917719},\n",
       "  5: {'UNKNOWN': 0.9739212559403692,\n",
       "   'KNOWN': 0.6390492566972799,\n",
       "   'HAPPY': 0.8183979964238518,\n",
       "   'UNHAPPY': 0.6730527935714172,\n",
       "   'MILDLY UNHAPPY': 0.6305793371189995,\n",
       "   'MEDIUM UNHAPPY': 0.5232128197935277,\n",
       "   'HEAVILY UNHAPPY': 0.496554876286049},\n",
       "  6: {'UNKNOWN': 0.9815699478603652,\n",
       "   'KNOWN': 0.6838407309854623,\n",
       "   'HAPPY': 0.8227977135234353,\n",
       "   'UNHAPPY': 0.6993094953995228,\n",
       "   'MILDLY UNHAPPY': 0.6421541896075981,\n",
       "   'MEDIUM UNHAPPY': 0.5436877234435255,\n",
       "   'HEAVILY UNHAPPY': 0.4947365267461869}},\n",
       " 'option': {0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2},\n",
       " 'certainty': {0: 0.7, 1: 0.7, 2: 0.7, 3: 0.7, 4: 0.7, 5: 0.7, 6: 0.7},\n",
       " 'precision_UNKNOWN': {0: 0.9146822601099056,\n",
       "  1: 0.9264315719655096,\n",
       "  2: 0.9417942421234129,\n",
       "  3: 0.9533676288463371,\n",
       "  4: 0.9631375736638894,\n",
       "  5: 0.9708143794533232,\n",
       "  6: 0.9516355140186916},\n",
       " 'recall_UNKNOWN': {0: 0.7815905123111191,\n",
       "  1: 0.8079537237888648,\n",
       "  2: 0.8437880348281996,\n",
       "  3: 0.8720752908370005,\n",
       "  4: 0.897005942692759,\n",
       "  5: 0.9172720702902134,\n",
       "  6: 0.8721160537444462},\n",
       " 'f1_UNKNOWN': {0: 0.8429151111832494,\n",
       "  1: 0.8631459690501325,\n",
       "  2: 0.8901014789758277,\n",
       "  3: 0.9109113664808282,\n",
       "  4: 0.9288962057071182,\n",
       "  5: 0.9432840491277478,\n",
       "  6: 0.9101421747995866},\n",
       " 'precision_HAPPY': {0: 0.9437614538790471,\n",
       "  1: 0.973005794386038,\n",
       "  2: 0.9859670106533893,\n",
       "  3: 0.9889273635045901,\n",
       "  4: 0.9909132891448441,\n",
       "  5: 0.9924286469344609,\n",
       "  6: 0.9899667032694556},\n",
       " 'recall_HAPPY': {0: 0.9054910436279717,\n",
       "  1: 0.9504168643665695,\n",
       "  2: 0.9724824757541256,\n",
       "  3: 0.9781751563184515,\n",
       "  4: 0.9819902278814963,\n",
       "  5: 0.984971083104927,\n",
       "  6: 0.9801843035133405},\n",
       " 'f1_HAPPY': {0: 0.9242302443401694,\n",
       "  1: 0.9615786856858743,\n",
       "  2: 0.9791783205917086,\n",
       "  3: 0.9835218740614676,\n",
       "  4: 0.9864315798724961,\n",
       "  5: 0.9886858022944325,\n",
       "  6: 0.9850512170943937},\n",
       " 'precision_MILDLY UNHAPPY': {0: 0.7090909090909091,\n",
       "  1: 0.9154401154401154,\n",
       "  2: 0.9402145056812148,\n",
       "  3: 0.976564839772387,\n",
       "  4: 0.9843032159264931,\n",
       "  5: 0.989551735760027,\n",
       "  6: 0.9826079120483013},\n",
       " 'recall_MILDLY UNHAPPY': {0: 0.8125,\n",
       "  1: 0.9471484025082114,\n",
       "  2: 0.96385804485086,\n",
       "  3: 0.9817839668799397,\n",
       "  4: 0.985875886751454,\n",
       "  5: 0.989551735760027,\n",
       "  6: 0.9846042710731862},\n",
       " 'f1_MILDLY UNHAPPY': {0: 0.7572815533980584,\n",
       "  1: 0.9310243616084531,\n",
       "  2: 0.9518894801913669,\n",
       "  3: 0.9791674486693441,\n",
       "  4: 0.9850889236565664,\n",
       "  5: 0.989551735760027,\n",
       "  6: 0.983605078591886},\n",
       " 'precision_MEDIUM UNHAPPY': {0: 0.946236559139785,\n",
       "  1: 0.946969696969697,\n",
       "  2: 0.9333333333333333,\n",
       "  3: 0.9343326195574589,\n",
       "  4: 0.9408181026979983,\n",
       "  5: 0.9467353951890034,\n",
       "  6: 0.9370662837999522},\n",
       " 'recall_MEDIUM UNHAPPY': {0: 0.946236559139785,\n",
       "  1: 0.946969696969697,\n",
       "  2: 0.9368029739776952,\n",
       "  3: 0.9403735632183908,\n",
       "  4: 0.9449300699300699,\n",
       "  5: 0.9483648881239243,\n",
       "  6: 0.9438418896119547},\n",
       " 'f1_MEDIUM UNHAPPY': {0: 0.946236559139785,\n",
       "  1: 0.946969696969697,\n",
       "  2: 0.935064935064935,\n",
       "  3: 0.93734335839599,\n",
       "  4: 0.9428696031399912,\n",
       "  5: 0.9475494411006019,\n",
       "  6: 0.9404418828049952},\n",
       " 'precision_HEAVILY UNHAPPY': {0: 0.9956709956709957,\n",
       "  1: 0.9968701095461658,\n",
       "  2: 0.9768518518518519,\n",
       "  3: 0.9845410628019323,\n",
       "  4: 0.993859649122807,\n",
       "  5: 0.988479262672811,\n",
       "  6: 0.9756738987508218},\n",
       " 'recall_HEAVILY UNHAPPY': {0: 0.9956709956709957,\n",
       "  1: 0.9968701095461658,\n",
       "  2: 0.9768518518518519,\n",
       "  3: 0.9845410628019323,\n",
       "  4: 0.993859649122807,\n",
       "  5: 0.988479262672811,\n",
       "  6: 0.9756738987508218},\n",
       " 'f1_HEAVILY UNHAPPY': {0: 0.9956709956709957,\n",
       "  1: 0.9968701095461658,\n",
       "  2: 0.9768518518518519,\n",
       "  3: 0.9845410628019323,\n",
       "  4: 0.993859649122807,\n",
       "  5: 0.988479262672811,\n",
       "  6: 0.9756738987508218},\n",
       " 'precision_KNOWN': {0: 0.9805320383342645,\n",
       "  1: 0.9806858134331765,\n",
       "  2: 0.9826935518654303,\n",
       "  3: 0.9900475747798982,\n",
       "  4: 0.9978132972353829,\n",
       "  5: 0.9992508962491305,\n",
       "  6: None},\n",
       " 'recall_KNOWN': {0: 0.4590836837763335,\n",
       "  1: 0.45953058473651553,\n",
       "  2: 0.47048346712784905,\n",
       "  3: 0.48014957434959027,\n",
       "  4: 0.48686617213697797,\n",
       "  5: 0.4884140600481222,\n",
       "  6: None},\n",
       " 'f1_KNOWN': {0: 0.6253700252165333,\n",
       "  1: 0.6258158508158508,\n",
       "  2: 0.6363176176927509,\n",
       "  3: 0.646676429617459,\n",
       "  4: 0.6544194225811409,\n",
       "  5: 0.6561264822134387,\n",
       "  6: None},\n",
       " 'precision_UNHAPPY': {0: 0.8709677419354839,\n",
       "  1: 0.9271604938271605,\n",
       "  2: 0.9666136724960255,\n",
       "  3: 0.9543817527010804,\n",
       "  4: 0.9025862068965518,\n",
       "  5: 0.9906832298136646,\n",
       "  6: None},\n",
       " 'recall_UNHAPPY': {0: 0.6352941176470588,\n",
       "  1: 0.6496539792387543,\n",
       "  2: 0.6590785907859079,\n",
       "  3: 0.6562113082955014,\n",
       "  4: 0.6435156730178242,\n",
       "  5: 0.6645833333333333,\n",
       "  6: None},\n",
       " 'f1_UNHAPPY': {0: 0.7346938775510204,\n",
       "  1: 0.7639877924720244,\n",
       "  2: 0.7837576538833387,\n",
       "  3: 0.7776962582538518,\n",
       "  4: 0.7513455328310011,\n",
       "  5: 0.795511221945137,\n",
       "  6: None},\n",
       " 'leaf_improve': {1: 0.014899059734513298,\n",
       "  2: 0.013275663783189104,\n",
       "  3: 0.007346367629338784,\n",
       "  4: 0.005239179954441914,\n",
       "  5: 0.004108198675710139,\n",
       "  6: 0.0039052215884159552},\n",
       " 'cum%classified': {0: 0.40549,\n",
       "  1: 0.57724,\n",
       "  2: 0.68612,\n",
       "  3: 0.74279,\n",
       "  4: 0.78933,\n",
       "  5: 0.81385,\n",
       "  6: 1.0}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Base Case 2 (Flat) - Flavius Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T21:46:53.897827Z",
     "iopub.status.busy": "2021-03-10T21:46:53.897416Z",
     "iopub.status.idle": "2021-03-10T21:46:53.929218Z",
     "shell.execute_reply": "2021-03-10T21:46:53.927839Z",
     "shell.execute_reply.started": "2021-03-10T21:46:53.897785Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamicFullFlatClassifier(START, END, threshold = None, threshold_type = None):  \n",
    "    \n",
    "    hypers = pd.DataFrame({'LR_penalty'     : ['l1','l1','l1','l1','l1','l1','l2','l1','l1','l1','l1'],\n",
    "                           'RF_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           'RF_n_estimators': [45,45,40,45,40,45,40,45,45,45,45]})\n",
    "    \n",
    "#     # Lourens\n",
    "    OPTION = 2\n",
    "    certainties = [0.7]\n",
    "    \n",
    "#     # Thomas\n",
    "#     OPTION = 2\n",
    "#     certainties = [0.3, 0.4, 0.5]\n",
    "    \n",
    "#     # Jim\n",
    "#     OPTION = 2\n",
    "#     certainties = [0.9, 1.0]\n",
    "    \n",
    "    # Mathilde\n",
    "#     OPTION = 2\n",
    "#     certainties = [0, 0.1, 0.2]\n",
    "\n",
    "    statistics = {'accuracy'  :{},\n",
    "                  'classified':{},\n",
    "                  'thresholds':{},\n",
    "                  'precision' :{},\n",
    "                  'recall'    :{},\n",
    "                  'f1'        :{}}\n",
    "    for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']: \n",
    "        statistics['precision_'+leaf] = {}\n",
    "        statistics['recall_'+leaf]    = {}\n",
    "        statistics['f1_'+leaf]        = {}\n",
    "    \n",
    "    #statistics, previous_pred_block, feature_importances = None, None, None\n",
    "    \n",
    "    for CERTAINTY in certainties:  \n",
    "        for DAYS in range(START, END+1):\n",
    "\n",
    "            X, y = functions.dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "            X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "            y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "            X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "            y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "            X_test = X.iloc[int(0.8*len(X)):]\n",
    "            y_test = y.iloc[int(0.8*len(y)):]\n",
    "            #print('Data pre-processing done')\n",
    "            \n",
    "            N_test = len(y_test)\n",
    "\n",
    "            if DAYS < 5:\n",
    "                clf = LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, 'LR_penalty'])\n",
    "            else:\n",
    "                clf = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, 'RF_max_depth'], n_estimators = hypers.loc[DAYS, 'RF_n_estimators'])\n",
    "                \n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_train_hat = clf.predict_proba(X_train) \n",
    "            y_classes = clf.classes_\n",
    "            y_train_hat = pd.DataFrame(y_train_hat, index = X_train.index, columns = y_classes)\n",
    "            probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "            \n",
    "            THRESHOLDS = {}\n",
    "            for node in range(1,6):\n",
    "                name, threshold = flat_thresholds(probs, node, DAYS, CERTAINTY, steps = 100)\n",
    "                THRESHOLDS[name] = threshold\n",
    "\n",
    "            if DAYS == START: #create dataframe to save predictions\n",
    "                y_hat = pd.DataFrame(['ORDERS'] * len(X_test),\n",
    "                                        columns=[DAYS],\n",
    "                                        index=X_test.index)\n",
    "                index_no_leaf = X_test.index\n",
    "            else:\n",
    "                y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "            if DAYS < END:\n",
    "                y_proba = clf.predict_proba(X_test)\n",
    "                y_classes = clf.classes_\n",
    "            \n",
    "                max_prob = np.amax(y_proba, axis=1)              #max probability of classes\n",
    "                max_class = np.argmax(y_proba, axis=1)           #class number with max probability\n",
    "                max_class_thresholds = np.vectorize(lambda x: THRESHOLDS[y_classes[x]])(max_class)  #get node specific threshold\n",
    "\n",
    "                accept_index = np.where(max_prob >= max_class_thresholds)[0]\n",
    "                accept_class = np.take(max_class, accept_index)  #filtered list of orders which are above threshold\n",
    "\n",
    "                if len(accept_class) > 0: #check if samples reach threshold\n",
    "                    accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             #convert class number into label\n",
    "                    y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  #set labels to correct position\n",
    "                else:\n",
    "                    y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "            else:\n",
    "                pred        = clf.predict(X_test) #last day you want a label for each order\n",
    "                y_hat_stage = pd.DataFrame(pred, index = X_test.index)\n",
    "                index_leaf  = X_test.index\n",
    "\n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna('ORDERS') #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(DAYS, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "                \n",
    "            current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "            \n",
    "            check_no_leaf = (current_pred == 'ORDERS')    #from current non_leaf predictions which are now leaf\n",
    "            index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "            check_leaf    = (current_pred != 'ORDERS')    #from current non_leaf predictions which are now leaf\n",
    "            index_leaf    = check_leaf[check_leaf].index\n",
    "\n",
    "            #statistics, feature_importances, previous_pred_block = get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, \n",
    "            #                                                                       previous_pred_block, THRESHOLDS, OPTION, CERTAINTY, y_test, Tree, HC, feature_importances, statistics)\n",
    "            \n",
    "            if DAYS == 0:\n",
    "                previous_leaf = index_leaf\n",
    "                cumu_leaf = index_leaf\n",
    "                statistics['leaf_improve'] = {}\n",
    "                statistics['cum%classified'] = {}\n",
    "                statistics['cum%classified'][DAYS] = len(index_leaf) / N_test\n",
    "            else:\n",
    "                index_intersect = previous_leaf.intersection(index_leaf)\n",
    "                acc_prev = metrics.accuracy_score(y_test.loc[index_intersect], y_hat[DAYS - 1].loc[index_intersect])\n",
    "                acc_now = metrics.accuracy_score(y_test.loc[index_intersect], y_hat[DAYS].loc[index_intersect])\n",
    "                acc_diff = (acc_now - acc_prev)/acc_prev\n",
    "                statistics['leaf_improve'][DAYS] = acc_diff\n",
    "                statistics['cum%classified'][DAYS] = len(cumu_leaf.union(index_leaf)) / N_test\n",
    "                cumu_leaf = cumu_leaf.union(index_leaf)\n",
    "                previous_leaf = index_leaf\n",
    "            \n",
    "            #print(current_pred)\n",
    "            #print(index_leaf)\n",
    "            #print(current_pred.loc[index_leaf])\n",
    "            statistics['accuracy'][DAYS]   = metrics.accuracy_score(y_test.loc[index_leaf], current_pred.loc[index_leaf])\n",
    "            statistics['classified'][DAYS] = (current_pred != 'ORDERS').sum() / len(y_test)\n",
    "            statistics['thresholds'][DAYS] = THRESHOLDS\n",
    "            \n",
    "            precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test.loc[index_leaf], current_pred.loc[index_leaf], average = 'weighted', beta = 1)\n",
    "            \n",
    "            statistics['precision'][DAYS] = precision\n",
    "            statistics['recall'][DAYS]    = recall\n",
    "            statistics['f1'][DAYS]        = f1\n",
    "            \n",
    "            for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']:\n",
    "                leaf_ix = current_pred.loc[current_pred == leaf].index\n",
    "                precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test.loc[leaf_ix], current_pred.loc[leaf_ix])\n",
    "                statistics['precision_'+leaf][DAYS] = precision\n",
    "                statistics['recall_'+leaf][DAYS]    = recall\n",
    "                statistics['f1_'+leaf][DAYS]        = f1\n",
    "            \n",
    "            file_name = 'statistics_flat_full_'+str(CERTAINTY)+'.json'\n",
    "            path_name = '/Users/LV/Desktop/' + file_name\n",
    "            with open(path_name, 'w') as f:\n",
    "                json.dump(statistics, f, cls = NumpyEncoder)\n",
    "\n",
    "            print('DAYS: ',DAYS)\n",
    "     \n",
    "    final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        \n",
    "    return y_hat, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T21:46:59.199659Z",
     "iopub.status.busy": "2021-03-10T21:46:59.199361Z",
     "iopub.status.idle": "2021-03-11T10:50:42.924241Z",
     "shell.execute_reply": "2021-03-11T10:50:42.918665Z",
     "shell.execute_reply.started": "2021-03-10T21:46:59.199626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "y_hat, statistics = dynamicFullFlatClassifier(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-03-11T11:09:49.840315Z",
     "iopub.status.busy": "2021-03-11T11:09:49.839992Z",
     "iopub.status.idle": "2021-03-11T11:09:49.946189Z",
     "shell.execute_reply": "2021-03-11T11:09:49.935460Z",
     "shell.execute_reply.started": "2021-03-11T11:09:49.840282Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {0: 0.8888601683410263,\n",
       "  1: 0.9284199575881247,\n",
       "  2: 0.9501834623321196,\n",
       "  3: 0.9604429931934283,\n",
       "  4: 0.9639776627718792,\n",
       "  5: 0.9759037741350388,\n",
       "  6: 0.9804518500589962,\n",
       "  7: 0.9837115699063842,\n",
       "  8: 0.9859768635143331,\n",
       "  9: 0.9876666059340443,\n",
       "  10: 0.9819880786515677},\n",
       " 'classified': {0: 0.48227511287568486,\n",
       "  1: 0.5236384206832253,\n",
       "  2: 0.5949821389287547,\n",
       "  3: 0.5922291245456165,\n",
       "  4: 0.5890382258351753,\n",
       "  5: 0.5532993222221059,\n",
       "  6: 0.5540053845106276,\n",
       "  7: 0.5830042217077489,\n",
       "  8: 0.6200347793293456,\n",
       "  9: 0.5979614284666716,\n",
       "  10: 1.0},\n",
       " 'thresholds': {0: {'UNKNOWN': 0.6203176205097817,\n",
       "   'HAPPY': 0.6712599189728522,\n",
       "   'MILDLY UNHAPPY': 0.3675430552553664,\n",
       "   'MEDIUM UNHAPPY': 0.3692428155885042,\n",
       "   'HEAVILY UNHAPPY': 0.4957362793796634},\n",
       "  1: {'UNKNOWN': 0.6447920086645453,\n",
       "   'HAPPY': 0.6608566930711927,\n",
       "   'MILDLY UNHAPPY': 0.41484603020429106,\n",
       "   'MEDIUM UNHAPPY': 0.35960811635192175,\n",
       "   'HEAVILY UNHAPPY': 0.6894599643876529},\n",
       "  2: {'UNKNOWN': 0.6896234278327615,\n",
       "   'HAPPY': 0.8273592538420529,\n",
       "   'MILDLY UNHAPPY': 0.408095483382857,\n",
       "   'MEDIUM UNHAPPY': 0.3980433166992759,\n",
       "   'HEAVILY UNHAPPY': 0.6427896270157042},\n",
       "  3: {'UNKNOWN': 0.722608639670453,\n",
       "   'HAPPY': 0.8678150832011794,\n",
       "   'MILDLY UNHAPPY': 0.4197483874216572,\n",
       "   'MEDIUM UNHAPPY': 0.4139002813595152,\n",
       "   'HEAVILY UNHAPPY': 0.5775302283748961},\n",
       "  4: {'UNKNOWN': 0.7412302863956985,\n",
       "   'HAPPY': 0.8923227261749201,\n",
       "   'MILDLY UNHAPPY': 0.3918289503530533,\n",
       "   'MEDIUM UNHAPPY': 0.4251119377069074,\n",
       "   'HEAVILY UNHAPPY': 0.5850264130420595},\n",
       "  5: {'UNKNOWN': 0.7353972080354397,\n",
       "   'HAPPY': 0.7372835725224179,\n",
       "   'MILDLY UNHAPPY': 0.3583433708682378,\n",
       "   'MEDIUM UNHAPPY': 0.5231148463527304,\n",
       "   'HEAVILY UNHAPPY': 0.6840161881681158},\n",
       "  6: {'UNKNOWN': 0.7574671586806636,\n",
       "   'HAPPY': 0.7531083850345452,\n",
       "   'MILDLY UNHAPPY': 0.3879536020501978,\n",
       "   'MEDIUM UNHAPPY': 0.5165651653271007,\n",
       "   'HEAVILY UNHAPPY': 0.6942939212830253},\n",
       "  7: {'UNKNOWN': 0.7734701709023687,\n",
       "   'HAPPY': 0.7554076433071433,\n",
       "   'MILDLY UNHAPPY': 0.49997547719044283,\n",
       "   'MEDIUM UNHAPPY': 0.5229806728209372,\n",
       "   'HEAVILY UNHAPPY': 0.6454864918714727},\n",
       "  8: {'UNKNOWN': 0.7939619503848282,\n",
       "   'HAPPY': 0.7866111889096982,\n",
       "   'MILDLY UNHAPPY': 0.6242901623971532,\n",
       "   'MEDIUM UNHAPPY': 0.5595296980517492,\n",
       "   'HEAVILY UNHAPPY': 0.6002255510157417},\n",
       "  9: {'UNKNOWN': 0.8052583339051729,\n",
       "   'HAPPY': 0.7926927498636462,\n",
       "   'MILDLY UNHAPPY': 0.6386997084669379,\n",
       "   'MEDIUM UNHAPPY': 0.5917109087206839,\n",
       "   'HEAVILY UNHAPPY': 0.47233307731669394},\n",
       "  10: {'UNKNOWN': 0.8048212987354059,\n",
       "   'HAPPY': 0.8014930327941645,\n",
       "   'MILDLY UNHAPPY': 0.6804150791384972,\n",
       "   'MEDIUM UNHAPPY': 0.6023641853351828,\n",
       "   'HEAVILY UNHAPPY': 0.436361205118103}},\n",
       " 'precision': {0: 0.8512655302167957,\n",
       "  1: 0.9180924738492242,\n",
       "  2: 0.9456221753468973,\n",
       "  3: 0.9585048777387107,\n",
       "  4: 0.9629013491693805,\n",
       "  5: 0.9754307792701041,\n",
       "  6: 0.9802265825445274,\n",
       "  7: 0.9836046473809508,\n",
       "  8: 0.9858869264886955,\n",
       "  9: 0.9876132116543035,\n",
       "  10: 0.981439959378267},\n",
       " 'recall': {0: 0.8888601683410263,\n",
       "  1: 0.9284199575881247,\n",
       "  2: 0.9501834623321196,\n",
       "  3: 0.9604429931934283,\n",
       "  4: 0.9639776627718792,\n",
       "  5: 0.9759037741350388,\n",
       "  6: 0.9804518500589962,\n",
       "  7: 0.9837115699063842,\n",
       "  8: 0.9859768635143331,\n",
       "  9: 0.9876666059340443,\n",
       "  10: 0.9819880786515677},\n",
       " 'f1': {0: 0.8624082546450519,\n",
       "  1: 0.912689111148768,\n",
       "  2: 0.9452721706045667,\n",
       "  3: 0.9576612172476451,\n",
       "  4: 0.9621470382868823,\n",
       "  5: 0.9738749083473832,\n",
       "  6: 0.9786434762666009,\n",
       "  7: 0.9825901449277895,\n",
       "  8: 0.9854676524253236,\n",
       "  9: 0.9873563219115742,\n",
       "  10: 0.9812269326752712},\n",
       " 'precision_HAPPY': {0: array([0.90061789, 0.        , 0.        , 0.        , 0.        ]),\n",
       "  1: array([0.94129189, 0.        , 0.        , 0.        , 0.        ]),\n",
       "  2: array([0.97018143, 0.        , 0.        , 0.        ]),\n",
       "  3: array([0.97856161, 0.        , 0.        , 0.        ]),\n",
       "  4: array([0.98340117, 0.        , 0.        , 0.        ]),\n",
       "  5: array([0.98635091, 0.        , 0.        , 0.        ]),\n",
       "  6: array([0.98804282, 0.        , 0.        , 0.        ]),\n",
       "  7: array([0.98987861, 0.        , 0.        , 0.        ]),\n",
       "  8: array([0.9910321, 0.       , 0.       , 0.       ]),\n",
       "  9: array([0.99217886, 0.        , 0.        , 0.        ]),\n",
       "  10: array([0.98844022, 0.        , 0.        , 0.        , 0.        ])},\n",
       " 'recall_HAPPY': {0: array([1., 0., 0., 0., 0.]),\n",
       "  1: array([1., 0., 0., 0., 0.]),\n",
       "  2: array([1., 0., 0., 0.]),\n",
       "  3: array([1., 0., 0., 0.]),\n",
       "  4: array([1., 0., 0., 0.]),\n",
       "  5: array([1., 0., 0., 0.]),\n",
       "  6: array([1., 0., 0., 0.]),\n",
       "  7: array([1., 0., 0., 0.]),\n",
       "  8: array([1., 0., 0., 0.]),\n",
       "  9: array([1., 0., 0., 0.]),\n",
       "  10: array([1., 0., 0., 0., 0.])},\n",
       " 'f1_HAPPY': {0: array([0.94771063, 0.        , 0.        , 0.        , 0.        ]),\n",
       "  1: array([0.96975823, 0.        , 0.        , 0.        , 0.        ]),\n",
       "  2: array([0.98486507, 0.        , 0.        , 0.        ]),\n",
       "  3: array([0.98916466, 0.        , 0.        , 0.        ]),\n",
       "  4: array([0.99163113, 0.        , 0.        , 0.        ]),\n",
       "  5: array([0.99312856, 0.        , 0.        , 0.        ]),\n",
       "  6: array([0.99398545, 0.        , 0.        , 0.        ]),\n",
       "  7: array([0.99491357, 0.        , 0.        , 0.        ]),\n",
       "  8: array([0.99549585, 0.        , 0.        , 0.        ]),\n",
       "  9: array([0.99607408, 0.        , 0.        , 0.        ]),\n",
       "  10: array([0.99418651, 0.        , 0.        , 0.        , 0.        ])},\n",
       " 'precision_UNKNOWN': {0: array([0.        , 0.        , 0.        , 0.        , 0.92394071]),\n",
       "  1: array([0.        , 0.        , 0.        , 0.        , 0.93302398]),\n",
       "  2: array([0.        , 0.        , 0.        , 0.        , 0.94550929]),\n",
       "  3: array([0.       , 0.       , 0.       , 0.       , 0.9557742]),\n",
       "  4: array([0.        , 0.        , 0.        , 0.        , 0.96350001]),\n",
       "  5: array([0.        , 0.        , 0.        , 0.97774629]),\n",
       "  6: array([0.        , 0.        , 0.        , 0.98265247]),\n",
       "  7: array([0.        , 0.        , 0.        , 0.98546883]),\n",
       "  8: array([0.        , 0.        , 0.        , 0.98672354]),\n",
       "  9: array([0.        , 0.        , 0.        , 0.98890077]),\n",
       "  10: array([0.        , 0.        , 0.        , 0.        , 0.98298433])},\n",
       " 'recall_UNKNOWN': {0: array([0., 0., 0., 0., 1.]),\n",
       "  1: array([0., 0., 0., 0., 1.]),\n",
       "  2: array([0., 0., 0., 0., 1.]),\n",
       "  3: array([0., 0., 0., 0., 1.]),\n",
       "  4: array([0., 0., 0., 0., 1.]),\n",
       "  5: array([0., 0., 0., 1.]),\n",
       "  6: array([0., 0., 0., 1.]),\n",
       "  7: array([0., 0., 0., 1.]),\n",
       "  8: array([0., 0., 0., 1.]),\n",
       "  9: array([0., 0., 0., 1.]),\n",
       "  10: array([0., 0., 0., 0., 1.])},\n",
       " 'f1_UNKNOWN': {0: array([0.        , 0.        , 0.        , 0.        , 0.96046693]),\n",
       "  1: array([0.        , 0.        , 0.        , 0.        , 0.96535169]),\n",
       "  2: array([0.        , 0.        , 0.        , 0.        , 0.97199154]),\n",
       "  3: array([0.        , 0.        , 0.        , 0.        , 0.97738706]),\n",
       "  4: array([0.        , 0.        , 0.        , 0.        , 0.98141075]),\n",
       "  5: array([0.        , 0.        , 0.        , 0.98874795]),\n",
       "  6: array([0.        , 0.        , 0.        , 0.99125034]),\n",
       "  7: array([0.        , 0.        , 0.        , 0.99268124]),\n",
       "  8: array([0.        , 0.        , 0.        , 0.99331741]),\n",
       "  9: array([0.        , 0.        , 0.        , 0.99441941]),\n",
       "  10: array([0.        , 0.        , 0.        , 0.        , 0.99141916])},\n",
       " 'precision_MILDLY UNHAPPY': {0: array([0.        , 0.        , 0.        , 0.29258212, 0.        ]),\n",
       "  1: array([0.        , 0.        , 0.        , 0.74159744, 0.        ]),\n",
       "  2: array([0.        , 0.        , 0.        , 0.83878073, 0.        ]),\n",
       "  3: array([0.        , 0.        , 0.        , 0.92975869, 0.        ]),\n",
       "  4: array([0.        , 0.        , 0.        , 0.94291223, 0.        ]),\n",
       "  5: array([0.        , 0.        , 0.        , 0.93907654, 0.        ]),\n",
       "  6: array([0.        , 0.        , 0.        , 0.96124551, 0.        ]),\n",
       "  7: array([0.        , 0.        , 0.97153746]),\n",
       "  8: array([0.        , 0.        , 0.97697347]),\n",
       "  9: array([0.        , 0.        , 0.97969622]),\n",
       "  10: array([0.        , 0.        , 0.96816781, 0.        ])},\n",
       " 'recall_MILDLY UNHAPPY': {0: array([0., 0., 0., 1., 0.]),\n",
       "  1: array([0., 0., 0., 1., 0.]),\n",
       "  2: array([0., 0., 0., 1., 0.]),\n",
       "  3: array([0., 0., 0., 1., 0.]),\n",
       "  4: array([0., 0., 0., 1., 0.]),\n",
       "  5: array([0., 0., 0., 1., 0.]),\n",
       "  6: array([0., 0., 0., 1., 0.]),\n",
       "  7: array([0., 0., 1.]),\n",
       "  8: array([0., 0., 1.]),\n",
       "  9: array([0., 0., 1.]),\n",
       "  10: array([0., 0., 1., 0.])},\n",
       " 'f1_MILDLY UNHAPPY': {0: array([0.        , 0.        , 0.        , 0.45270953, 0.        ]),\n",
       "  1: array([0.      , 0.      , 0.      , 0.851629, 0.      ]),\n",
       "  2: array([0.        , 0.        , 0.        , 0.91232273, 0.        ]),\n",
       "  3: array([0.        , 0.        , 0.        , 0.96360099, 0.        ]),\n",
       "  4: array([0.        , 0.        , 0.        , 0.97061742, 0.        ]),\n",
       "  5: array([0.       , 0.       , 0.       , 0.9685812, 0.       ]),\n",
       "  6: array([0.        , 0.        , 0.        , 0.98023986, 0.        ]),\n",
       "  7: array([0.        , 0.        , 0.98556328]),\n",
       "  8: array([0.        , 0.        , 0.98835263]),\n",
       "  9: array([0.        , 0.        , 0.98974399]),\n",
       "  10: array([0.        , 0.        , 0.98382649, 0.        ])},\n",
       " 'precision_MEDIUM UNHAPPY': {0: array([0.        , 0.        , 0.09694619, 0.        , 0.        ]),\n",
       "  1: array([0.        , 0.        , 0.25238745, 0.        , 0.        ]),\n",
       "  2: array([0.        , 0.        , 0.33953917, 0.        , 0.        ]),\n",
       "  3: array([0.        , 0.        , 0.41401649, 0.        , 0.        ]),\n",
       "  4: array([0.        , 0.        , 0.45472933, 0.        , 0.        ]),\n",
       "  5: array([0.        , 0.84839065, 0.        , 0.        ]),\n",
       "  6: array([0.        , 0.85752001, 0.        , 0.        ]),\n",
       "  7: array([0.        , 0.86311118, 0.        , 0.        ]),\n",
       "  8: array([0.       , 0.8804899, 0.       , 0.       ]),\n",
       "  9: array([0.        , 0.88830987, 0.        ]),\n",
       "  10: array([0.        , 0.        , 0.85386887, 0.        , 0.        ])},\n",
       " 'recall_MEDIUM UNHAPPY': {0: array([0., 0., 1., 0., 0.]),\n",
       "  1: array([0., 0., 1., 0., 0.]),\n",
       "  2: array([0., 0., 1., 0., 0.]),\n",
       "  3: array([0., 0., 1., 0., 0.]),\n",
       "  4: array([0., 0., 1., 0., 0.]),\n",
       "  5: array([0., 1., 0., 0.]),\n",
       "  6: array([0., 1., 0., 0.]),\n",
       "  7: array([0., 1., 0., 0.]),\n",
       "  8: array([0., 1., 0., 0.]),\n",
       "  9: array([0., 1., 0.]),\n",
       "  10: array([0., 0., 1., 0., 0.])},\n",
       " 'f1_MEDIUM UNHAPPY': {0: array([0.        , 0.        , 0.17675652, 0.        , 0.        ]),\n",
       "  1: array([0.        , 0.        , 0.40305011, 0.        , 0.        ]),\n",
       "  2: array([0.        , 0.        , 0.50694922, 0.        , 0.        ]),\n",
       "  3: array([0.        , 0.        , 0.58558934, 0.        , 0.        ]),\n",
       "  4: array([0.       , 0.       , 0.6251738, 0.       , 0.       ]),\n",
       "  5: array([0.        , 0.91797765, 0.        , 0.        ]),\n",
       "  6: array([0.        , 0.92329558, 0.        , 0.        ]),\n",
       "  7: array([0.        , 0.92652676, 0.        , 0.        ]),\n",
       "  8: array([0.        , 0.93644736, 0.        , 0.        ]),\n",
       "  9: array([0.       , 0.9408518, 0.       ]),\n",
       "  10: array([0.        , 0.        , 0.92117505, 0.        , 0.        ])},\n",
       " 'precision_HEAVILY UNHAPPY': {0: array([0.29169797, 0.        , 0.        ]),\n",
       "  1: array([1.]),\n",
       "  2: array([1.]),\n",
       "  3: array([0.99933555, 0.        ]),\n",
       "  4: array([0.99939541, 0.        ]),\n",
       "  5: array([0.99677939, 0.        ]),\n",
       "  6: array([1.]),\n",
       "  7: array([1.]),\n",
       "  8: array([1.]),\n",
       "  9: array([0.99798682, 0.        , 0.        ]),\n",
       "  10: array([0.90319662, 0.        , 0.        , 0.        ])},\n",
       " 'recall_HEAVILY UNHAPPY': {0: array([1., 0., 0.]),\n",
       "  1: array([1.]),\n",
       "  2: array([1.]),\n",
       "  3: array([1., 0.]),\n",
       "  4: array([1., 0.]),\n",
       "  5: array([1., 0.]),\n",
       "  6: array([1.]),\n",
       "  7: array([1.]),\n",
       "  8: array([1.]),\n",
       "  9: array([1., 0., 0.]),\n",
       "  10: array([1., 0., 0., 0.])},\n",
       " 'f1_HEAVILY UNHAPPY': {0: array([0.45165043, 0.        , 0.        ]),\n",
       "  1: array([1.]),\n",
       "  2: array([1.]),\n",
       "  3: array([0.99966766, 0.        ]),\n",
       "  4: array([0.99969761, 0.        ]),\n",
       "  5: array([0.9983871, 0.       ]),\n",
       "  6: array([1.]),\n",
       "  7: array([1.]),\n",
       "  8: array([1.]),\n",
       "  9: array([0.9989924, 0.       , 0.       ]),\n",
       "  10: array([0.94913643, 0.        , 0.        , 0.        ])},\n",
       " 'leaf_improve': {1: 0.009935820977027254,\n",
       "  2: 0.012440643349502128,\n",
       "  3: 0.008080843150487198,\n",
       "  4: 0.005526101141924957,\n",
       "  5: 0.013058116011421048,\n",
       "  6: 0.0030853344768439223,\n",
       "  7: 0.00234455218420762,\n",
       "  8: 0.0016216162440184426,\n",
       "  9: 0.0011157236237164462,\n",
       "  10: 0.0011618254317378868},\n",
       " 'cum%classified': {0: 0.48227511287568486,\n",
       "  1: 0.610714547606826,\n",
       "  2: 0.724976167778837,\n",
       "  3: 0.7751872531662808,\n",
       "  4: 0.8090331974984024,\n",
       "  5: 0.8324484857373322,\n",
       "  6: 0.8408751401125091,\n",
       "  7: 0.8478959553316083,\n",
       "  8: 0.8541928995694487,\n",
       "  9: 0.8579557715878021,\n",
       "  10: 1.0}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Bugfixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T16:44:30.133584Z",
     "iopub.status.busy": "2021-03-02T16:44:30.133329Z",
     "iopub.status.idle": "2021-03-02T16:44:57.490672Z",
     "shell.execute_reply": "2021-03-02T16:44:57.489969Z",
     "shell.execute_reply.started": "2021-03-02T16:44:30.133560Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, 10)\n",
    "\n",
    "X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "X_test = X.iloc[int(0.8*len(X)):]\n",
    "y_test = y.iloc[int(0.8*len(y)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T16:44:57.492631Z",
     "iopub.status.busy": "2021-03-02T16:44:57.492108Z",
     "iopub.status.idle": "2021-03-02T16:45:20.026791Z",
     "shell.execute_reply": "2021-03-02T16:45:20.025540Z",
     "shell.execute_reply.started": "2021-03-02T16:44:57.492597Z"
    }
   },
   "outputs": [],
   "source": [
    "Tree = ClassHierarchy('ORDERS')\n",
    "Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "                       '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "                       '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "                       '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                       '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "\n",
    "OPTION = 2\n",
    "CERTAINTY = 0.7\n",
    "DAYS = 10\n",
    "\n",
    "HC = HierarchicalClassifier(Tree)\n",
    "HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "                    'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "                    'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "\n",
    "HC = HC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T16:52:11.689394Z",
     "iopub.status.busy": "2021-03-02T16:52:11.689122Z",
     "iopub.status.idle": "2021-03-02T16:52:21.855649Z",
     "shell.execute_reply": "2021-03-02T16:52:21.854700Z",
     "shell.execute_reply.started": "2021-03-02T16:52:11.689369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowerbound: 0.9933733291347455\n",
      "lowerbound: 0.8421211147061107\n",
      "lowerbound: 0.6043991631489433\n",
      "lowerbound: 0.6178093355709303\n",
      "lowerbound: 0.616404957523803\n",
      "lowerbound: 0.5189103377173029\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = HC.get_probabilities(X_train, y_train)\n",
    "probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "\n",
    "THRESHOLDS = {}\n",
    "for node in range(1,8):\n",
    "    name, threshold = opt_threshold(probs, node, DAYS, CERTAINTY, OPTION)\n",
    "    THRESHOLDS[name] = threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Base Case 1 (Static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T09:48:37.643918Z",
     "iopub.status.busy": "2021-03-02T09:48:37.643494Z",
     "iopub.status.idle": "2021-03-02T09:48:37.665784Z",
     "shell.execute_reply": "2021-03-02T09:48:37.664494Z",
     "shell.execute_reply.started": "2021-03-02T09:48:37.643872Z"
    }
   },
   "outputs": [],
   "source": [
    "def staticHierarchicalClassifier(START, END, threshold = None, threshold_type = None):\n",
    "    \n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "    \n",
    "    hypers = pd.DataFrame({'1_penalty'     : ['l1','l1','l2','l2','l2','l2','l1','l1','l1','l1','l1'],\n",
    "                           '2_max_depth'   : [ 9,10,12,12,12,12,10,10,10,10,10], \n",
    "                           '2_n_estimators': [35,45,30,30,30,30,45,45,45,45,45],\n",
    "                           '3_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           '3_n_estimators': [20,45,30,30,30,30,45,45,45,45,45]})\n",
    "    \n",
    "    statistics = {'accuracy':{},\n",
    "                  'precision':{},\n",
    "                  'recall':{},\n",
    "                  'f1':{}}\n",
    "    for leaf in Tree._get_leaf_nodes(): \n",
    "        statistics['precision_'+leaf] = {}\n",
    "        statistics['recall_'+leaf]    = {}\n",
    "        statistics['f1_'+leaf]        = {}\n",
    "    \n",
    "    for DAYS in range(START, END+1):\n",
    "\n",
    "        X, y = functions.dataX(df, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "        X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "        y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "        X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "        y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "        X_test = X.iloc[int(0.8*len(X)):]\n",
    "        y_test = y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "        HC = HierarchicalClassifier(Tree)\n",
    "        HC.fit_classifiers({'ORDERS'  : LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, '1_penalty']),\n",
    "                            'KNOWN'   : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '2_max_depth'], n_estimators = hypers.loc[DAYS, '2_n_estimators']),\n",
    "                            'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, '3_max_depth'], n_estimators = hypers.loc[DAYS, '3_n_estimators'])})\n",
    "\n",
    "        HC = HC.fit(X_train,y_train)\n",
    "        pred = HC.predict(X_test)\n",
    "        \n",
    "        y_test = y_test['detailedMatchClassification']\n",
    "        \n",
    "        statistics['accuracy'][DAYS] = metrics.accuracy_score(y_test, pred)\n",
    "        statistics['precision'][DAYS] = precision_score_ancestors(Tree, y_test, pred)\n",
    "        statistics['recall'][DAYS] = recall_score_ancestors(Tree, y_test, pred)\n",
    "        statistics['f1'][DAYS] = f1_score_ancestors(Tree, y_test, pred, beta = 1)\n",
    "        \n",
    "        for leaf in Tree._get_leaf_nodes():\n",
    "            leaf_ix = pred.loc[pred == leaf].index\n",
    "            statistics['precision_'+leaf][DAYS] = precision_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "            statistics['recall_'+leaf][DAYS]    = recall_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "            statistics['f1_'+leaf][DAYS]        = f1_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix], beta = 1)\n",
    "            \n",
    "        print('DAY ',DAYS)\n",
    "            \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T09:48:47.909157Z",
     "iopub.status.busy": "2021-03-02T09:48:47.908895Z",
     "iopub.status.idle": "2021-03-02T11:08:35.755833Z",
     "shell.execute_reply": "2021-03-02T11:08:35.751180Z",
     "shell.execute_reply.started": "2021-03-02T09:48:47.909133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY  6\n",
      "DAY  7\n",
      "DAY  8\n"
     ]
    }
   ],
   "source": [
    "stats = staticHierarchicalClassifier(6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:26:45.494490Z",
     "iopub.status.busy": "2021-03-02T11:26:45.493474Z",
     "iopub.status.idle": "2021-03-02T11:26:45.545627Z",
     "shell.execute_reply": "2021-03-02T11:26:45.544593Z",
     "shell.execute_reply.started": "2021-03-02T11:26:45.494441Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_35 = {'accuracy': {3: 0.9103269466472517,\n",
    "  4: 0.9357986151122472,\n",
    "  5: 0.9545082181879131},\n",
    " 'precision': {3: 0.9288946029914686,\n",
    "  4: 0.955768017729528,\n",
    "  5: 0.9721027885169434},\n",
    " 'recall': {3: 0.9043605128064413,\n",
    "  4: 0.9235396698716583,\n",
    "  5: 0.9425898021366741},\n",
    " 'f1': {3: 0.9164633904636592, 4: 0.939377500971662, 5: 0.9571188393975034},\n",
    " 'precision_UNKNOWN': {3: 0.9008640954075591,\n",
    "  4: 0.9092636776450946,\n",
    "  5: 0.9305363496410377},\n",
    " 'recall_UNKNOWN': {3: 0.764873959770202,\n",
    "  4: 0.7819209327189879,\n",
    "  5: 0.8251461300905099},\n",
    " 'f1_UNKNOWN': {3: 0.8273179396092362,\n",
    "  4: 0.8407979809592633,\n",
    "  5: 0.8746780544649013},\n",
    " 'precision_HAPPY': {3: 0.9804231956077426,\n",
    "  4: 0.9857077197261045,\n",
    "  5: 0.9882203444853589},\n",
    " 'recall_HAPPY': {3: 0.9643788328443436,\n",
    "  4: 0.9725926350978643,\n",
    "  5: 0.9769648553804453},\n",
    " 'f1_HAPPY': {3: 0.9723348322772593,\n",
    "  4: 0.9791062603886375,\n",
    "  5: 0.9825603673384882},\n",
    " 'precision_MILDLY UNHAPPY': {3: 0.7620270901447922,\n",
    "  4: 0.8904332967167093,\n",
    "  5: 0.9656225092861332},\n",
    " 'recall_MILDLY UNHAPPY': {3: 0.8664849755415793,\n",
    "  4: 0.938710490964584,\n",
    "  5: 0.9766228630528685},\n",
    " 'f1_MILDLY UNHAPPY': {3: 0.810905904203835,\n",
    "  4: 0.9139347958989367,\n",
    "  5: 0.9710915346515937},\n",
    " 'precision_MEDIUM UNHAPPY': {3: 0.7930544350966156,\n",
    "  4: 0.8809708737864078,\n",
    "  5: 0.9170888213441405},\n",
    " 'recall_MEDIUM UNHAPPY': {3: 0.8657217143336409,\n",
    "  4: 0.9105565962001606,\n",
    "  5: 0.9312946556158902},\n",
    " 'f1_MEDIUM UNHAPPY': {3: 0.8277963790925676,\n",
    "  4: 0.8955194420685572,\n",
    "  5: 0.9241371486911886},\n",
    " 'precision_HEAVILY UNHAPPY': {3: 0.9051029543419875,\n",
    "  4: 0.9224098880476282,\n",
    "  5: 0.9510307643514113},\n",
    " 'recall_HEAVILY UNHAPPY': {3: 0.9285878300803674,\n",
    "  4: 0.9282365199270644,\n",
    "  5: 0.9525412960609911},\n",
    " 'f1_HEAVILY UNHAPPY': {3: 0.9166950017001021,\n",
    "  4: 0.9253140316141387,\n",
    "  5: 0.9517854308839867}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:27:20.168726Z",
     "iopub.status.busy": "2021-03-02T11:27:20.168451Z",
     "iopub.status.idle": "2021-03-02T11:27:20.179287Z",
     "shell.execute_reply": "2021-03-02T11:27:20.177224Z",
     "shell.execute_reply.started": "2021-03-02T11:27:20.168698Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_68 = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:27:47.088180Z",
     "iopub.status.busy": "2021-03-02T11:27:47.065981Z",
     "iopub.status.idle": "2021-03-02T11:27:47.110301Z",
     "shell.execute_reply": "2021-03-02T11:27:47.109116Z",
     "shell.execute_reply.started": "2021-03-02T11:27:47.088111Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_910 = {'accuracy': {9: 0.9798615112247143, 10: 0.9823044448401932},\n",
    " 'precision': {9: 0.9885632839696289, 10: 0.9900067286218827},\n",
    " 'recall': {9: 0.9766856272794625, 10: 0.9801185043164926},\n",
    " 'f1': {9: 0.9825885622759623, 10: 0.9850378015543084},\n",
    " 'precision_UNKNOWN': {9: 0.9777753922221766, 10: 0.9823523627978673},\n",
    " 'recall_UNKNOWN': {9: 0.9371296806250718, 10: 0.9493739175747544},\n",
    " 'f1_UNKNOWN': {9: 0.9570211641601474, 10: 0.9655816360569773},\n",
    " 'precision_HAPPY': {9: 0.9935202273356639, 10: 0.9942228581316295},\n",
    " 'recall_HAPPY': {9: 0.987123888943773, 10: 0.9885120835861538},\n",
    " 'f1_HAPPY': {9: 0.9903117298973837, 10: 0.9913592466264884},\n",
    " 'precision_MILDLY UNHAPPY': {9: 0.9883924660534384, 10: 0.9895021782345726},\n",
    " 'recall_MILDLY UNHAPPY': {9: 0.9887491300873779, 10: 0.989631935837292},\n",
    " 'f1_MILDLY UNHAPPY': {9: 0.9885707659004226, 10: 0.9895670527822955},\n",
    " 'precision_MEDIUM UNHAPPY': {9: 0.9548252477829943, 10: 0.9572140512945181},\n",
    " 'recall_MEDIUM UNHAPPY': {9: 0.9557026795597419, 10: 0.9576602687529135},\n",
    " 'f1_MEDIUM UNHAPPY': {9: 0.9552637621860844, 10: 0.9574371080333532},\n",
    " 'precision_HEAVILY UNHAPPY': {9: 0.9745694511508128, 10: 0.9707193515704154},\n",
    " 'recall_HEAVILY UNHAPPY': {9: 0.9746740355207383, 10: 0.9707193515704154},\n",
    " 'f1_HEAVILY UNHAPPY': {9: 0.9746217405300999, 10: 0.9707193515704154}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:32:28.759479Z",
     "iopub.status.busy": "2021-03-02T11:32:28.759238Z",
     "iopub.status.idle": "2021-03-02T11:32:28.786889Z",
     "shell.execute_reply": "2021-03-02T11:32:28.785577Z",
     "shell.execute_reply.started": "2021-03-02T11:32:28.759457Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_02 = {'accuracy': {0: 0.8173152871913596,\n",
    "  1: 0.8359327040928566,\n",
    "  2: 0.8777391340785049},\n",
    " 'precision': {0: 0.8499370720856377,\n",
    "  1: 0.8613588547588565,\n",
    "  2: 0.8968386013389915},\n",
    " 'recall': {0: 0.818899973085777,\n",
    "  1: 0.8425541305742654,\n",
    "  2: 0.8795976761524221},\n",
    " 'f1': {0: 0.83412990797318, 1: 0.8518527263197162, 2: 0.8881344741907056},\n",
    " 'precision_UNKNOWN': {0: 0.8795418054008444,\n",
    "  1: 0.8811734839494675,\n",
    "  2: 0.8920568864334167},\n",
    " 'recall_UNKNOWN': {0: 0.724613037933535,\n",
    "  1: 0.7308493513871792,\n",
    "  2: 0.7484755065131178},\n",
    " 'f1_UNKNOWN': {0: 0.794595935983723,\n",
    "  1: 0.7990024149621412,\n",
    "  2: 0.8139829884279844},\n",
    " 'precision_HAPPY': {0: 0.9186210067894722,\n",
    "  1: 0.9430937323600042,\n",
    "  2: 0.9702039555846461},\n",
    " 'recall_HAPPY': {0: 0.8767846539126842,\n",
    "  1: 0.9107136917806448,\n",
    "  2: 0.9492838933246677},\n",
    " 'f1_HAPPY': {0: 0.8972153972153972,\n",
    "  1: 0.9266209245989108,\n",
    "  2: 0.9596299229502426},\n",
    " 'precision_MILDLY UNHAPPY': {0: 0.45632014014342803,\n",
    "  1: 0.5425416358287215,\n",
    "  2: 0.6535517490712345},\n",
    " 'recall_MILDLY UNHAPPY': {0: 0.6293631318660576,\n",
    "  1: 0.7086605841697969,\n",
    "  2: 0.7946332675051103},\n",
    " 'f1_MILDLY UNHAPPY': {0: 0.5290512987322089,\n",
    "  1: 0.6145735140771638,\n",
    "  2: 0.7172204599601684},\n",
    " 'precision_MEDIUM UNHAPPY': {0: 0.364867042707494,\n",
    "  1: 0.5477867793824116,\n",
    "  2: 0.6562103124206249},\n",
    " 'recall_MEDIUM UNHAPPY': {0: 0.55404192837915,\n",
    "  1: 0.7096357137424899,\n",
    "  2: 0.7783189395460935},\n",
    " 'f1_MEDIUM UNHAPPY': {0: 0.4399818617607048,\n",
    "  1: 0.6182950667594341,\n",
    "  2: 0.7120676190913684},\n",
    " 'precision_HEAVILY UNHAPPY': {0: 0.37303177784139707,\n",
    "  1: 0.85002849002849,\n",
    "  2: 0.9003090507726269},\n",
    " 'recall_HEAVILY UNHAPPY': {0: 0.6259407526020817,\n",
    "  1: 0.9218885181065382,\n",
    "  2: 0.9315669255367748},\n",
    " 'f1_HEAVILY UNHAPPY': {0: 0.4674718966754365,\n",
    "  1: 0.8845013636902644,\n",
    "  2: 0.9156713066906151}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:32:42.205731Z",
     "iopub.status.busy": "2021-03-02T11:32:42.205476Z",
     "iopub.status.idle": "2021-03-02T11:32:42.223275Z",
     "shell.execute_reply": "2021-03-02T11:32:42.222104Z",
     "shell.execute_reply.started": "2021-03-02T11:32:42.205708Z"
    }
   },
   "outputs": [],
   "source": [
    "df_02 = pd.DataFrame.from_dict(stats_02)\n",
    "df_35 = pd.DataFrame.from_dict(stats_35)\n",
    "df_68 = pd.DataFrame.from_dict(stats_68)\n",
    "df_910 = pd.DataFrame.from_dict(stats_910)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:33:08.448022Z",
     "iopub.status.busy": "2021-03-02T11:33:08.447743Z",
     "iopub.status.idle": "2021-03-02T11:33:08.458418Z",
     "shell.execute_reply": "2021-03-02T11:33:08.456733Z",
     "shell.execute_reply.started": "2021-03-02T11:33:08.447996Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_02,df_35,df_68,df_910])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:33:41.676976Z",
     "iopub.status.busy": "2021-03-02T11:33:41.676674Z",
     "iopub.status.idle": "2021-03-02T11:33:41.705086Z",
     "shell.execute_reply": "2021-03-02T11:33:41.703815Z",
     "shell.execute_reply.started": "2021-03-02T11:33:41.676948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 81.73)(1, 83.59)(2, 87.77)(3, 91.03)(4, 93.58)(5, 95.45)(6, 96.54)(7, 97.22)(8, 97.66)(9, 97.99)(10, 98.23)"
     ]
    }
   ],
   "source": [
    "col = df_all['accuracy']\n",
    "for i in range(11):\n",
    "    print((i,round(col[i]*100,2)), end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Base Case 2 (Flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T14:05:13.608547Z",
     "iopub.status.busy": "2021-03-11T14:05:13.608290Z",
     "iopub.status.idle": "2021-03-11T14:05:13.637022Z",
     "shell.execute_reply": "2021-03-11T14:05:13.635000Z",
     "shell.execute_reply.started": "2021-03-11T14:05:13.608523Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamicFlatClassifier(START, END):  \n",
    "\n",
    "    hypers = pd.DataFrame({'LR_penalty'     : ['l1','l1','l1','l1','l1','l1','l2','l1','l1','l1','l1'],\n",
    "                           'RF_max_depth'   : [14,14,14,14,14,14,14,14,14,14,14], \n",
    "                           'RF_n_estimators': [45,45,40,45,40,45,40,45,45,45,45]})\n",
    "    \n",
    "\n",
    "    certainties = [0.7]\n",
    "    \n",
    "    statistics = {'accuracy'  :{},\n",
    "                  'classified':{},\n",
    "                  'thresholds':{},\n",
    "                  'precision' :{},\n",
    "                  'recall'    :{},\n",
    "                  'f1'        :{}}\n",
    "    for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']: \n",
    "        statistics['precision_'+leaf] = {}\n",
    "        statistics['recall_'+leaf]    = {}\n",
    "        statistics['f1_'+leaf]        = {}\n",
    "    \n",
    "    for CERTAINTY in certainties:  \n",
    "        for DAYS in range(START, END+1):\n",
    "\n",
    "            X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "\n",
    "            X_train_preburn = X.iloc[:int(0.8*len(X))]\n",
    "            y_train_preburn = y.iloc[:int(0.8*len(y))]\n",
    "\n",
    "            X_train = X_train_preburn.iloc[int(0.1*len(X_train_preburn)):]\n",
    "            y_train = y_train_preburn.iloc[int(0.1*len(y_train_preburn)):]\n",
    "\n",
    "            X_test = X.iloc[int(0.8*len(X)):]\n",
    "            y_test = y.iloc[int(0.8*len(y)):]\n",
    "\n",
    "            if DAYS < 5:\n",
    "                clf = LogisticRegression(random_state=0, class_weight='balanced', solver = 'liblinear', penalty = hypers.loc[DAYS, 'LR_penalty'])\n",
    "            else:\n",
    "                clf = RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[DAYS, 'RF_max_depth'], n_estimators = hypers.loc[DAYS, 'RF_n_estimators'])\n",
    "                \n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_train_hat = clf.predict_proba(X_train) \n",
    "            y_classes = clf.classes_\n",
    "            y_train_hat = pd.DataFrame(y_train_hat, index = X_train.index, columns = y_classes)\n",
    "            probs = pd.concat([y_train, y_train_hat], axis=1)\n",
    "            \n",
    "            THRESHOLDS = {}\n",
    "            for node in range(1,6):\n",
    "                name, threshold = flat_thresholds(probs, node, DAYS, CERTAINTY, steps = 100)\n",
    "                THRESHOLDS[name] = threshold\n",
    "\n",
    "            if DAYS == START: #create dataframe to save predictions\n",
    "                y_hat = pd.DataFrame(['ORDERS'] * len(X_test),\n",
    "                                        columns=[DAYS],\n",
    "                                        index=X_test.index)\n",
    "                index_no_leaf = X_test.index\n",
    "            else:\n",
    "                y_hat[DAYS] = y_hat[DAYS - 1]\n",
    "\n",
    "            if DAYS < END:\n",
    "                X_test_ = X_test.loc[index_no_leaf]\n",
    "                y_proba = clf.predict_proba(X_test_)\n",
    "                y_classes = clf.classes_\n",
    "            \n",
    "                max_prob = np.amax(y_proba, axis=1)              #max probability of classes\n",
    "                max_class = np.argmax(y_proba, axis=1)           #class number with max probability\n",
    "                max_class_thresholds = np.vectorize(lambda x: THRESHOLDS[y_classes[x]])(max_class)  #get node specific threshold\n",
    "\n",
    "                accept_index = np.where(max_prob >= max_class_thresholds)[0]\n",
    "                accept_class = np.take(max_class, accept_index)  #filtered list of orders which are above threshold\n",
    "\n",
    "                if len(accept_class) > 0: #check if samples reach threshold\n",
    "                    accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             #convert class number into label\n",
    "                    y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test_.index.values, accept_index))  #set labels to correct position\n",
    "                else:\n",
    "                    y_hat_stage = pd.DataFrame(columns = [0], index = X_test_.index)\n",
    "                    \n",
    "                index_leaf = y_hat_stage.index\n",
    "\n",
    "            else:\n",
    "                pred        = clf.predict(X_test.loc[index_no_leaf]) #last day you want a label for each order\n",
    "                y_hat_stage = pd.DataFrame(pred, index = index_no_leaf)\n",
    "                index_leaf  = index_no_leaf\n",
    "\n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[DAYS]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(DAYS, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': DAYS})\n",
    "\n",
    "            current_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "            check_no_leaf = (current_pred == 'ORDERS')    #from current non_leaf predictions which are now leaf\n",
    "            index_no_leaf = check_no_leaf[check_no_leaf].index\n",
    "            \n",
    "            statistics['accuracy'][DAYS]   = metrics.accuracy_score(y_test.loc[index_leaf], current_pred.loc[index_leaf])\n",
    "            statistics['classified'][DAYS] = (current_pred != 'ORDERS').sum() / len(y_test)\n",
    "            statistics['thresholds'][DAYS] = THRESHOLDS\n",
    "            \n",
    "            precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test.loc[index_leaf], current_pred.loc[index_leaf], average = 'weighted', beta = 1)\n",
    "            \n",
    "            statistics['precision'][DAYS] = precision\n",
    "            statistics['recall'][DAYS]    = recall\n",
    "            statistics['f1'][DAYS]        = f1\n",
    "            \n",
    "            for leaf in ['HAPPY','UNKNOWN','MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY']:\n",
    "                leaf_ix = current_pred.loc[current_pred == leaf].index\n",
    "                precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test.loc[leaf_ix], current_pred.loc[leaf_ix], average = 'weighted')\n",
    "                statistics['precision_'+leaf][DAYS] = precision\n",
    "                statistics['recall_'+leaf][DAYS]    = recall\n",
    "                statistics['f1_'+leaf][DAYS]        = f1\n",
    "            \n",
    "#             file_name = 'flat_statistics_'+str(CERTAINTY)+'.json'\n",
    "#             path_name = '/Users/LV/Desktop/' + file_name\n",
    "#             with open(path_name, 'w') as f:\n",
    "#                 json.dump(statistics, f, cls = NumpyEncoder)\n",
    "\n",
    "            print('DAYS: ',DAYS)\n",
    "     \n",
    "        final_pred = y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "        accuracy = metrics.accuracy_score(y_test, final_pred)\n",
    "        precision, recall, f1, support = metrics.precision_recall_fscore_support(y_test, final_pred, average = 'weighted', beta = 1)\n",
    "    \n",
    "    return final_pred, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T14:05:27.447366Z",
     "iopub.status.busy": "2021-03-11T14:05:27.447117Z",
     "iopub.status.idle": "2021-03-11T15:37:53.442500Z",
     "shell.execute_reply": "2021-03-11T15:37:53.432651Z",
     "shell.execute_reply.started": "2021-03-11T14:05:27.447343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-f14609ad9400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamicFlatClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-193-f8df64e86069>\u001b[0m in \u001b[0;36mdynamicFlatClassifier\u001b[0;34m(START, END)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDAYS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RF_max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDAYS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RF_n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0my_train_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1354\u001b[0m                               \u001b[0;34m\" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m                               \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n\u001b[0;32m-> 1356\u001b[0;31m             self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m   1357\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred, stats = dynamicFlatClassifier(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-11T14:04:19.401050Z",
     "iopub.status.busy": "2021-03-11T14:04:19.400751Z",
     "iopub.status.idle": "2021-03-11T14:04:19.426114Z",
     "shell.execute_reply": "2021-03-11T14:04:19.424536Z",
     "shell.execute_reply.started": "2021-03-11T14:04:19.401016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {0: 0.8777319063178697,\n",
       "  1: 0.8966577648296512,\n",
       "  2: 0.9207625856419422,\n",
       "  3: 0.916709248850281,\n",
       "  4: 0.893875998478509,\n",
       "  5: 0.9356879283078545,\n",
       "  6: 0.9609929078014184,\n",
       "  7: 0.9708502024291498,\n",
       "  8: 0.9786184210526315,\n",
       "  9: 0.9702479338842975,\n",
       "  10: 0.9692711550339715},\n",
       " 'classified': {0: 0.51109,\n",
       "  1: 0.63466,\n",
       "  2: 0.73537,\n",
       "  3: 0.77451,\n",
       "  4: 0.8008,\n",
       "  5: 0.81977,\n",
       "  6: 0.83387,\n",
       "  7: 0.84622,\n",
       "  8: 0.85838,\n",
       "  9: 0.87048,\n",
       "  10: 1.0},\n",
       " 'thresholds': {0: {'UNKNOWN': 0.5663331114247794,\n",
       "   'HAPPY': 0.49818889690479656,\n",
       "   'MILDLY UNHAPPY': 0.39007173071934775,\n",
       "   'MEDIUM UNHAPPY': 0.41154602462722334,\n",
       "   'HEAVILY UNHAPPY': 0.7527906537893481},\n",
       "  1: {'UNKNOWN': 0.5887901143603879,\n",
       "   'HAPPY': 0.525730600016601,\n",
       "   'MILDLY UNHAPPY': 0.3974645685599487,\n",
       "   'MEDIUM UNHAPPY': 0.39805080810752624,\n",
       "   'HEAVILY UNHAPPY': 0.7383181336241565},\n",
       "  2: {'UNKNOWN': 0.6236336159723789,\n",
       "   'HAPPY': 0.6277979970098212,\n",
       "   'MILDLY UNHAPPY': 0.41506186574658516,\n",
       "   'MEDIUM UNHAPPY': 0.4147943391864831,\n",
       "   'HEAVILY UNHAPPY': 0.7216634265994932},\n",
       "  3: {'UNKNOWN': 0.6672937682903765,\n",
       "   'HAPPY': 0.6741964373542796,\n",
       "   'MILDLY UNHAPPY': 0.401423983992777,\n",
       "   'MEDIUM UNHAPPY': 0.4013892439990498,\n",
       "   'HEAVILY UNHAPPY': 0.7054000220350795},\n",
       "  4: {'UNKNOWN': 0.7077407046645823,\n",
       "   'HAPPY': 0.7000888308215981,\n",
       "   'MILDLY UNHAPPY': 0.378169696823101,\n",
       "   'MEDIUM UNHAPPY': 0.4200796026177483,\n",
       "   'HEAVILY UNHAPPY': 0.6146916966921225},\n",
       "  5: {'UNKNOWN': 0.7354378338669361,\n",
       "   'HAPPY': 0.7227651492716392,\n",
       "   'MILDLY UNHAPPY': 0.3729703142093207,\n",
       "   'MEDIUM UNHAPPY': 0.44923291196819215,\n",
       "   'HEAVILY UNHAPPY': 0.6245848805997407},\n",
       "  6: {'UNKNOWN': 0.762528183649753,\n",
       "   'HAPPY': 0.7450207438851064,\n",
       "   'MILDLY UNHAPPY': 0.3796448076574704,\n",
       "   'MEDIUM UNHAPPY': 0.5398784412880694,\n",
       "   'HEAVILY UNHAPPY': 0.5323329175418241},\n",
       "  7: {'UNKNOWN': 0.777364368730848,\n",
       "   'HAPPY': 0.7474816824364049,\n",
       "   'MILDLY UNHAPPY': 0.5370396269297788,\n",
       "   'MEDIUM UNHAPPY': 0.526079927096279,\n",
       "   'HEAVILY UNHAPPY': 0.5367190485266972},\n",
       "  8: {'UNKNOWN': 0.7768376851234946,\n",
       "   'HAPPY': 0.7682593953398702,\n",
       "   'MILDLY UNHAPPY': 0.5853905881936531,\n",
       "   'MEDIUM UNHAPPY': 0.537267162563119,\n",
       "   'HEAVILY UNHAPPY': 0.48422439708702647},\n",
       "  9: {'UNKNOWN': 0.7872114399104538,\n",
       "   'HAPPY': 0.7876408338528321,\n",
       "   'MILDLY UNHAPPY': 0.6024004372015332,\n",
       "   'MEDIUM UNHAPPY': 0.562356225386223,\n",
       "   'HEAVILY UNHAPPY': 0.4666160015249014},\n",
       "  10: {'UNKNOWN': 0.7905101853964747,\n",
       "   'HAPPY': 0.7914476184763013,\n",
       "   'MILDLY UNHAPPY': 0.6154231882001899,\n",
       "   'MEDIUM UNHAPPY': 0.5680807324634619,\n",
       "   'HEAVILY UNHAPPY': 0.42155109150191716}},\n",
       " 'precision': {0: 0.8429708929666975,\n",
       "  1: 0.894094735166253,\n",
       "  2: 0.9171818042143435,\n",
       "  3: 0.9152539974493137,\n",
       "  4: 0.8992039787199773,\n",
       "  5: 0.9336179875524949,\n",
       "  6: 0.9603243720181611,\n",
       "  7: 0.9705438392034439,\n",
       "  8: 0.979374139721293,\n",
       "  9: 0.9707458146166446,\n",
       "  10: 0.9652692506608838},\n",
       " 'recall': {0: 0.8777319063178697,\n",
       "  1: 0.8966577648296512,\n",
       "  2: 0.9207625856419422,\n",
       "  3: 0.916709248850281,\n",
       "  4: 0.893875998478509,\n",
       "  5: 0.9356879283078545,\n",
       "  6: 0.9609929078014184,\n",
       "  7: 0.9708502024291498,\n",
       "  8: 0.9786184210526315,\n",
       "  9: 0.9702479338842975,\n",
       "  10: 0.9692711550339715},\n",
       " 'f1': {0: 0.8556385673728834,\n",
       "  1: 0.8926909185646739,\n",
       "  2: 0.9169502628865702,\n",
       "  3: 0.9137348876533391,\n",
       "  4: 0.8925739594538414,\n",
       "  5: 0.9333022636204152,\n",
       "  6: 0.9580862763171696,\n",
       "  7: 0.9685144907949742,\n",
       "  8: 0.9766207375884811,\n",
       "  9: 0.9672032480617384,\n",
       "  10: 0.9619995579167887},\n",
       " 'precision_HAPPY': {0: 0.7900690995360048,\n",
       "  1: 0.8115041801801368,\n",
       "  2: 0.8299973691037239,\n",
       "  3: 0.8355090440611511,\n",
       "  4: 0.8384706183733388,\n",
       "  5: 0.8408865400310277,\n",
       "  6: 0.8429014816358242,\n",
       "  7: 0.8440643995449801,\n",
       "  8: 0.8449741285574486,\n",
       "  9: 0.8462606544505087,\n",
       "  10: 0.8557808655613602},\n",
       " 'recall_HAPPY': {0: 0.888858312407554,\n",
       "  1: 0.9008352680596696,\n",
       "  2: 0.9110419140213715,\n",
       "  3: 0.9140618382041508,\n",
       "  4: 0.9156804127933167,\n",
       "  5: 0.9169986586855118,\n",
       "  6: 0.9180966624685138,\n",
       "  7: 0.9187297750399626,\n",
       "  8: 0.9192247432252074,\n",
       "  9: 0.9199242656058751,\n",
       "  10: 0.9250842478181975},\n",
       " 'f1_HAPPY': {0: 0.8365572942620312,\n",
       "  1: 0.85383956602247,\n",
       "  2: 0.8686333491840326,\n",
       "  3: 0.8730219968703405,\n",
       "  4: 0.8753763026169247,\n",
       "  5: 0.8772948653053566,\n",
       "  6: 0.8788936429836061,\n",
       "  7: 0.8798158141131681,\n",
       "  8: 0.8805369267358355,\n",
       "  9: 0.8815562880376975,\n",
       "  10: 0.8890840663532136},\n",
       " 'precision_UNKNOWN': {0: 0.8553016039904151,\n",
       "  1: 0.8531107275857053,\n",
       "  2: 0.8517456396461348,\n",
       "  3: 0.8513125455536366,\n",
       "  4: 0.851250393715561,\n",
       "  5: 0.8520420241566014,\n",
       "  6: 0.8527541955654069,\n",
       "  7: 0.8550060591831256,\n",
       "  8: 0.8583540347880637,\n",
       "  9: 0.8598537575494861,\n",
       "  10: 0.8770621016253975},\n",
       " 'recall_UNKNOWN': {0: 0.9248251748251748,\n",
       "  1: 0.9236399339492123,\n",
       "  2: 0.9229006661857683,\n",
       "  3: 0.9226659989149034,\n",
       "  4: 0.9226323177276856,\n",
       "  5: 0.9230612244897959,\n",
       "  6: 0.9234469099874701,\n",
       "  7: 0.9246653768705334,\n",
       "  8: 0.9264739795526175,\n",
       "  9: 0.9272829975522501,\n",
       "  10: 0.9365159377316531},\n",
       " 'f1_UNKNOWN': {0: 0.8887057538283697,\n",
       "  1: 0.886975480732798,\n",
       "  2: 0.8858966608354685,\n",
       "  3: 0.8855542731125349,\n",
       "  4: 0.8855051336301618,\n",
       "  5: 0.8861309388448153,\n",
       "  6: 0.8866937695420581,\n",
       "  7: 0.8884724269039929,\n",
       "  8: 0.8911140704712744,\n",
       "  9: 0.8922963141806837,\n",
       "  10: 0.9058144934791997},\n",
       " 'precision_MILDLY UNHAPPY': {0: 0.03566884955648447,\n",
       "  1: 0.13934111761388965,\n",
       "  2: 0.2576045485887579,\n",
       "  3: 0.3018302680131297,\n",
       "  4: 0.3217207191582842,\n",
       "  5: 0.3429769239066297,\n",
       "  6: 0.3579299430054575,\n",
       "  7: 0.3645663605226609,\n",
       "  8: 0.3699020760557583,\n",
       "  9: 0.37394287786870906,\n",
       "  10: 0.38062865619903813},\n",
       " 'recall_MILDLY UNHAPPY': {0: 0.18886198547215496,\n",
       "  1: 0.3732842316705725,\n",
       "  2: 0.5075475825858674,\n",
       "  3: 0.5493908153701968,\n",
       "  4: 0.5672043010752689,\n",
       "  5: 0.5856423173803527,\n",
       "  6: 0.5982724655250795,\n",
       "  7: 0.6037933094384708,\n",
       "  8: 0.6081957547169812,\n",
       "  9: 0.6115086899371988,\n",
       "  10: 0.6169510970887709},\n",
       " 'f1_MILDLY UNHAPPY': {0: 0.06000503000744638,\n",
       "  1: 0.2029312132192532,\n",
       "  2: 0.3417531248292592,\n",
       "  3: 0.38961153637794504,\n",
       "  4: 0.41056640661022886,\n",
       "  5: 0.4326031415120952,\n",
       "  6: 0.44789602614829127,\n",
       "  7: 0.4546301052350754,\n",
       "  8: 0.4600212069591685,\n",
       "  9: 0.4640904268202014,\n",
       "  10: 0.4707979813172315},\n",
       " 'precision_MEDIUM UNHAPPY': {0: 0.19463667820069203,\n",
       "  1: 0.3804008748969127,\n",
       "  2: 0.3779618162273464,\n",
       "  3: 0.416025,\n",
       "  4: 0.4632690706411528,\n",
       "  5: 0.4811248929823054,\n",
       "  6: 0.48664576,\n",
       "  7: 0.4998448775595203,\n",
       "  8: 0.4988507995501002,\n",
       "  9: 0.4994034867641065,\n",
       "  10: 0.4969094329481322},\n",
       " 'recall_MEDIUM UNHAPPY': {0: 0.4411764705882353,\n",
       "  1: 0.6167664670658682,\n",
       "  2: 0.6147859922178989,\n",
       "  3: 0.645,\n",
       "  4: 0.6806387225548902,\n",
       "  5: 0.693631669535284,\n",
       "  6: 0.6976,\n",
       "  7: 0.706997084548105,\n",
       "  8: 0.7062937062937062,\n",
       "  9: 0.7066848567530696,\n",
       "  10: 0.7049180327868853},\n",
       " 'f1_MEDIUM UNHAPPY': {0: 0.27010804321728693,\n",
       "  1: 0.47056997116877347,\n",
       "  2: 0.4681262013032676,\n",
       "  3: 0.50580547112462,\n",
       "  4: 0.5513011980789015,\n",
       "  5: 0.5681576480136574,\n",
       "  6: 0.57333383600377,\n",
       "  7: 0.5856423330586352,\n",
       "  8: 0.5847185601283962,\n",
       "  9: 0.5852322234981456,\n",
       "  10: 0.5829129886506935},\n",
       " 'precision_HEAVILY UNHAPPY': {0: 0.29918697355974955,\n",
       "  1: 0.3877368398491084,\n",
       "  2: 0.39717559454406764,\n",
       "  3: 0.4086435496549917,\n",
       "  4: 0.41667366535091405,\n",
       "  5: 0.4171460746369249,\n",
       "  6: 0.42701695912165477,\n",
       "  7: 0.4315314958027629,\n",
       "  8: 0.43661924504502636,\n",
       "  9: 0.43877375999999996,\n",
       "  10: 0.4314286678754678},\n",
       " 'recall_HEAVILY UNHAPPY': {0: 0.5469798657718121,\n",
       "  1: 0.6226851851851852,\n",
       "  2: 0.6302186878727635,\n",
       "  3: 0.6392523364485981,\n",
       "  4: 0.6455026455026455,\n",
       "  5: 0.6458684654300169,\n",
       "  6: 0.6534653465346535,\n",
       "  7: 0.656910569105691,\n",
       "  8: 0.6607717041800643,\n",
       "  9: 0.6624,\n",
       "  10: 0.656832298136646},\n",
       " 'f1_HEAVILY UNHAPPY': {0: 0.38680138013364584,\n",
       "  1: 0.4778953347070323,\n",
       "  2: 0.48726664403820985,\n",
       "  3: 0.4985730879485075,\n",
       "  4: 0.5064393746065771,\n",
       "  5: 0.5069008652862632,\n",
       "  6: 0.5165115313926603,\n",
       "  7: 0.5208868889473979,\n",
       "  8: 0.5258028468886862,\n",
       "  9: 0.5278798845043311,\n",
       "  10: 0.5207873704063752}}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T15:37:11.491368Z",
     "iopub.status.busy": "2021-03-09T15:37:11.490427Z",
     "iopub.status.idle": "2021-03-09T15:37:11.530476Z",
     "shell.execute_reply": "2021-03-09T15:37:11.527756Z",
     "shell.execute_reply.started": "2021-03-09T15:37:11.491309Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/LV/Desktop/flat_statistics_0.7.json') as f:\n",
    "    stats = json.load(f)\n",
    "stats = pd.DataFrame.from_dict(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-03-09T15:38:50.011243Z",
     "iopub.status.busy": "2021-03-09T15:38:50.010865Z",
     "iopub.status.idle": "2021-03-09T15:38:50.197911Z",
     "shell.execute_reply": "2021-03-09T15:38:50.196362Z",
     "shell.execute_reply.started": "2021-03-09T15:38:50.011203Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.88886</td>\n",
       "      <td>0.796827</td>\n",
       "      <td>0.716593</td>\n",
       "      <td>0.668273</td>\n",
       "      <td>0.631626</td>\n",
       "      <td>0.616166</td>\n",
       "      <td>0.605609</td>\n",
       "      <td>0.598626</td>\n",
       "      <td>0.593323</td>\n",
       "      <td>0.58968</td>\n",
       "      <td>0.713522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classified</th>\n",
       "      <td>0.482275</td>\n",
       "      <td>0.543881</td>\n",
       "      <td>0.605584</td>\n",
       "      <td>0.637946</td>\n",
       "      <td>0.656436</td>\n",
       "      <td>0.665874</td>\n",
       "      <td>0.671902</td>\n",
       "      <td>0.676045</td>\n",
       "      <td>0.678852</td>\n",
       "      <td>0.680275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thresholds</th>\n",
       "      <td>{'UNKNOWN': 0.6203176205097817, 'HAPPY': 0.671...</td>\n",
       "      <td>{'UNKNOWN': 0.6447920086645453, 'HAPPY': 0.660...</td>\n",
       "      <td>{'UNKNOWN': 0.6896234278327615, 'HAPPY': 0.827...</td>\n",
       "      <td>{'UNKNOWN': 0.722608639670453, 'HAPPY': 0.8678...</td>\n",
       "      <td>{'UNKNOWN': 0.7412302863956985, 'HAPPY': 0.892...</td>\n",
       "      <td>{'UNKNOWN': 0.7353972080354397, 'HAPPY': 0.737...</td>\n",
       "      <td>{'UNKNOWN': 0.7574671586806636, 'HAPPY': 0.753...</td>\n",
       "      <td>{'UNKNOWN': 0.7734701709023687, 'HAPPY': 0.755...</td>\n",
       "      <td>{'UNKNOWN': 0.7939619503848282, 'HAPPY': 0.786...</td>\n",
       "      <td>{'UNKNOWN': 0.8052583339051729, 'HAPPY': 0.792...</td>\n",
       "      <td>{'UNKNOWN': 0.8048212987354059, 'HAPPY': 0.801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.851266</td>\n",
       "      <td>0.762079</td>\n",
       "      <td>0.695008</td>\n",
       "      <td>0.654121</td>\n",
       "      <td>0.626018</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0.628083</td>\n",
       "      <td>0.628137</td>\n",
       "      <td>0.621071</td>\n",
       "      <td>0.619736</td>\n",
       "      <td>0.728074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.88886</td>\n",
       "      <td>0.796827</td>\n",
       "      <td>0.716593</td>\n",
       "      <td>0.668273</td>\n",
       "      <td>0.631626</td>\n",
       "      <td>0.616166</td>\n",
       "      <td>0.605609</td>\n",
       "      <td>0.598626</td>\n",
       "      <td>0.593323</td>\n",
       "      <td>0.58968</td>\n",
       "      <td>0.713522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.862408</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.695205</td>\n",
       "      <td>0.654024</td>\n",
       "      <td>0.626336</td>\n",
       "      <td>0.615695</td>\n",
       "      <td>0.608955</td>\n",
       "      <td>0.603084</td>\n",
       "      <td>0.598717</td>\n",
       "      <td>0.596845</td>\n",
       "      <td>0.716326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_HAPPY</th>\n",
       "      <td>[0.9006178936819109, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.800657203176482, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.7328824424710969, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.7128736412202208, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.7088178870785093, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.698390118135216, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.6941628478680383, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.6891918150892995, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.6887529942649266, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.6901528290568472, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.7785420355461998, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_HAPPY</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_HAPPY</th>\n",
       "      <td>[0.9477106331322788, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8892944217967397, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8458536188132921, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8323715469313688, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8296002662874088, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8224142506222639, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8194759420460481, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8160018405640513, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8156941797929711, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8166750570621142, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8754834240475012, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_UNKNOWN</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.92394071057336]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.860160997014666]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8031507695613634]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.724507495188899]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6517738265779052]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6698853612771714]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6837790161568376]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6927303674720494]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6732914284939346]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6679179882496219]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.7864403154218582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_UNKNOWN</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_UNKNOWN</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.9604669265489094]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.9248242473582885]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8908304098794121]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8402485894786302]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.7891804750632602]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8023129932282607]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8121956736550114]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8184769184552222]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8047509441913994]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8009002756191401]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.8804551807667245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_MILDLY UNHAPPY</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.2925821187731129, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.19760900140646975, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.11358188402101291, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.09663419223648669, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.09020484332957208, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.08817052327110177, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.08664471481192097, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.08571130471073087, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.08575695645338784, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.08563631917002407, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.3464798948275081, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_MILDLY UNHAPPY</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_MILDLY UNHAPPY</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.45270952541231907, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.3300058719906048, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.2039937711825593, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.1762377881714776, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.16548237495272786, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.1620527690936825, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.15947202177653375, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.15788967903132806, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.15796713241149643, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.15776244338526477, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5146454784189617, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_MEDIUM UNHAPPY</th>\n",
       "      <td>[0.0, 0.0, 0.09694619486185167, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.06872370266479663, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.05196920343500148, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.04419889502762431, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.03883815601276268, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.03296995479925552, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.030495928941524798, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.028003434383462124, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.026958452267681572, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.026307868280055383, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.2642994652406417, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_MEDIUM UNHAPPY</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_MEDIUM UNHAPPY</th>\n",
       "      <td>[0.0, 0.0, 0.17675651789659744, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.12860892388451442, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0988036593947924, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.08465608465608467, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0747722940055073, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.06383526383526385, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.05918689843413303, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0544812078380983, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.052501544163063615, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.051267010793054894, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.4180963015599093, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_HEAVILY UNHAPPY</th>\n",
       "      <td>[0.29169797145003756, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.24737870979207394, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.20643971155458662, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.18095689246802463, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.16604169791510426, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.18235592360993746, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.19359560841720036, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.19472804900686838, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.17339983374896092, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.1459227467811159, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.3318487830139824, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_HEAVILY UNHAPPY</th>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_HEAVILY UNHAPPY</th>\n",
       "      <td>[0.4516504289661189, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.3966376976777319, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.34222963580761745, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.3064580826313678, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.284795472086442, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.308461978273299, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.3243906178138893, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.3259788688626476, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.2955511476338906, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.2546816479400749, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.4983280192861031, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           0  \\\n",
       "accuracy                                                             0.88886   \n",
       "classified                                                          0.482275   \n",
       "thresholds                 {'UNKNOWN': 0.6203176205097817, 'HAPPY': 0.671...   \n",
       "precision                                                           0.851266   \n",
       "recall                                                               0.88886   \n",
       "f1                                                                  0.862408   \n",
       "precision_HAPPY                     [0.9006178936819109, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.9477106331322788, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                     [0.0, 0.0, 0.0, 0.0, 0.92394071057336]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.9604669265489094]   \n",
       "precision_MILDLY UNHAPPY            [0.0, 0.0, 0.0, 0.2925821187731129, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                  [0.0, 0.0, 0.0, 0.45270952541231907, 0.0]   \n",
       "precision_MEDIUM UNHAPPY           [0.0, 0.0, 0.09694619486185167, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                  [0.0, 0.0, 0.17675651789659744, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY                    [0.29169797145003756, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                                       [1.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                            [0.4516504289661189, 0.0, 0.0]   \n",
       "\n",
       "                                                                           1  \\\n",
       "accuracy                                                            0.796827   \n",
       "classified                                                          0.543881   \n",
       "thresholds                 {'UNKNOWN': 0.6447920086645453, 'HAPPY': 0.660...   \n",
       "precision                                                           0.762079   \n",
       "recall                                                              0.796827   \n",
       "f1                                                                  0.771199   \n",
       "precision_HAPPY                      [0.800657203176482, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8892944217967397, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                    [0.0, 0.0, 0.0, 0.0, 0.860160997014666]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.9248242473582885]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.19760900140646975, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                   [0.0, 0.0, 0.0, 0.3300058719906048, 0.0]   \n",
       "precision_MEDIUM UNHAPPY           [0.0, 0.0, 0.06872370266479663, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                  [0.0, 0.0, 0.12860892388451442, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.24737870979207394, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.3966376976777319, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           2  \\\n",
       "accuracy                                                            0.716593   \n",
       "classified                                                          0.605584   \n",
       "thresholds                 {'UNKNOWN': 0.6896234278327615, 'HAPPY': 0.827...   \n",
       "precision                                                           0.695008   \n",
       "recall                                                              0.716593   \n",
       "f1                                                                  0.695205   \n",
       "precision_HAPPY                     [0.7328824424710969, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8458536188132921, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.8031507695613634]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8908304098794121]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.11358188402101291, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                   [0.0, 0.0, 0.0, 0.2039937711825593, 0.0]   \n",
       "precision_MEDIUM UNHAPPY           [0.0, 0.0, 0.05196920343500148, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                   [0.0, 0.0, 0.0988036593947924, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.20643971155458662, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                 [0.0, 0.34222963580761745, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           3  \\\n",
       "accuracy                                                            0.668273   \n",
       "classified                                                          0.637946   \n",
       "thresholds                 {'UNKNOWN': 0.722608639670453, 'HAPPY': 0.8678...   \n",
       "precision                                                           0.654121   \n",
       "recall                                                              0.668273   \n",
       "f1                                                                  0.654024   \n",
       "precision_HAPPY                     [0.7128736412202208, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8323715469313688, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                    [0.0, 0.0, 0.0, 0.0, 0.724507495188899]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8402485894786302]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.09663419223648669, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                   [0.0, 0.0, 0.0, 0.1762377881714776, 0.0]   \n",
       "precision_MEDIUM UNHAPPY           [0.0, 0.0, 0.04419889502762431, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                  [0.0, 0.0, 0.08465608465608467, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.18095689246802463, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.3064580826313678, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           4  \\\n",
       "accuracy                                                            0.631626   \n",
       "classified                                                          0.656436   \n",
       "thresholds                 {'UNKNOWN': 0.7412302863956985, 'HAPPY': 0.892...   \n",
       "precision                                                           0.626018   \n",
       "recall                                                              0.631626   \n",
       "f1                                                                  0.626336   \n",
       "precision_HAPPY                     [0.7088178870785093, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8296002662874088, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.6517738265779052]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.7891804750632602]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.09020484332957208, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                  [0.0, 0.0, 0.0, 0.16548237495272786, 0.0]   \n",
       "precision_MEDIUM UNHAPPY           [0.0, 0.0, 0.03883815601276268, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                   [0.0, 0.0, 0.0747722940055073, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.16604169791510426, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                   [0.0, 0.284795472086442, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           5  \\\n",
       "accuracy                                                            0.616166   \n",
       "classified                                                          0.665874   \n",
       "thresholds                 {'UNKNOWN': 0.7353972080354397, 'HAPPY': 0.737...   \n",
       "precision                                                           0.625954   \n",
       "recall                                                              0.616166   \n",
       "f1                                                                  0.615695   \n",
       "precision_HAPPY                      [0.698390118135216, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8224142506222639, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.6698853612771714]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8023129932282607]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.08817052327110177, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                   [0.0, 0.0, 0.0, 0.1620527690936825, 0.0]   \n",
       "precision_MEDIUM UNHAPPY           [0.0, 0.0, 0.03296995479925552, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                  [0.0, 0.0, 0.06383526383526385, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.18235592360993746, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                   [0.0, 0.308461978273299, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           6  \\\n",
       "accuracy                                                            0.605609   \n",
       "classified                                                          0.671902   \n",
       "thresholds                 {'UNKNOWN': 0.7574671586806636, 'HAPPY': 0.753...   \n",
       "precision                                                           0.628083   \n",
       "recall                                                              0.605609   \n",
       "f1                                                                  0.608955   \n",
       "precision_HAPPY                     [0.6941628478680383, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8194759420460481, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.6837790161568376]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8121956736550114]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.08664471481192097, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                  [0.0, 0.0, 0.0, 0.15947202177653375, 0.0]   \n",
       "precision_MEDIUM UNHAPPY          [0.0, 0.0, 0.030495928941524798, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                  [0.0, 0.0, 0.05918689843413303, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.19359560841720036, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.3243906178138893, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           7  \\\n",
       "accuracy                                                            0.598626   \n",
       "classified                                                          0.676045   \n",
       "thresholds                 {'UNKNOWN': 0.7734701709023687, 'HAPPY': 0.755...   \n",
       "precision                                                           0.628137   \n",
       "recall                                                              0.598626   \n",
       "f1                                                                  0.603084   \n",
       "precision_HAPPY                     [0.6891918150892995, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8160018405640513, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.6927303674720494]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8184769184552222]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.08571130471073087, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                  [0.0, 0.0, 0.0, 0.15788967903132806, 0.0]   \n",
       "precision_MEDIUM UNHAPPY          [0.0, 0.0, 0.028003434383462124, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                   [0.0, 0.0, 0.0544812078380983, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.19472804900686838, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.3259788688626476, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           8  \\\n",
       "accuracy                                                            0.593323   \n",
       "classified                                                          0.678852   \n",
       "thresholds                 {'UNKNOWN': 0.7939619503848282, 'HAPPY': 0.786...   \n",
       "precision                                                           0.621071   \n",
       "recall                                                              0.593323   \n",
       "f1                                                                  0.598717   \n",
       "precision_HAPPY                     [0.6887529942649266, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8156941797929711, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.6732914284939346]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8047509441913994]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.08575695645338784, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                  [0.0, 0.0, 0.0, 0.15796713241149643, 0.0]   \n",
       "precision_MEDIUM UNHAPPY          [0.0, 0.0, 0.026958452267681572, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                 [0.0, 0.0, 0.052501544163063615, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY          [0.0, 0.17339983374896092, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.2955511476338906, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                           9  \\\n",
       "accuracy                                                             0.58968   \n",
       "classified                                                          0.680275   \n",
       "thresholds                 {'UNKNOWN': 0.8052583339051729, 'HAPPY': 0.792...   \n",
       "precision                                                           0.619736   \n",
       "recall                                                               0.58968   \n",
       "f1                                                                  0.596845   \n",
       "precision_HAPPY                     [0.6901528290568472, 0.0, 0.0, 0.0, 0.0]   \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "f1_HAPPY                            [0.8166750570621142, 0.0, 0.0, 0.0, 0.0]   \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.6679179882496219]   \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8009002756191401]   \n",
       "precision_MILDLY UNHAPPY           [0.0, 0.0, 0.0, 0.08563631917002407, 0.0]   \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "f1_MILDLY UNHAPPY                  [0.0, 0.0, 0.0, 0.15776244338526477, 0.0]   \n",
       "precision_MEDIUM UNHAPPY          [0.0, 0.0, 0.026307868280055383, 0.0, 0.0]   \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "f1_MEDIUM UNHAPPY                 [0.0, 0.0, 0.051267010793054894, 0.0, 0.0]   \n",
       "precision_HEAVILY UNHAPPY           [0.0, 0.1459227467811159, 0.0, 0.0, 0.0]   \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.2546816479400749, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                                                          10  \n",
       "accuracy                                                            0.713522  \n",
       "classified                                                                 1  \n",
       "thresholds                 {'UNKNOWN': 0.8048212987354059, 'HAPPY': 0.801...  \n",
       "precision                                                           0.728074  \n",
       "recall                                                              0.713522  \n",
       "f1                                                                  0.716326  \n",
       "precision_HAPPY                     [0.7785420355461998, 0.0, 0.0, 0.0, 0.0]  \n",
       "recall_HAPPY                                       [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "f1_HAPPY                            [0.8754834240475012, 0.0, 0.0, 0.0, 0.0]  \n",
       "precision_UNKNOWN                   [0.0, 0.0, 0.0, 0.0, 0.7864403154218582]  \n",
       "recall_UNKNOWN                                     [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "f1_UNKNOWN                          [0.0, 0.0, 0.0, 0.0, 0.8804551807667245]  \n",
       "precision_MILDLY UNHAPPY            [0.0, 0.0, 0.0, 0.3464798948275081, 0.0]  \n",
       "recall_MILDLY UNHAPPY                              [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "f1_MILDLY UNHAPPY                   [0.0, 0.0, 0.0, 0.5146454784189617, 0.0]  \n",
       "precision_MEDIUM UNHAPPY            [0.0, 0.0, 0.2642994652406417, 0.0, 0.0]  \n",
       "recall_MEDIUM UNHAPPY                              [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "f1_MEDIUM UNHAPPY                   [0.0, 0.0, 0.4180963015599093, 0.0, 0.0]  \n",
       "precision_HEAVILY UNHAPPY           [0.0, 0.3318487830139824, 0.0, 0.0, 0.0]  \n",
       "recall_HEAVILY UNHAPPY                             [0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "f1_HEAVILY UNHAPPY                  [0.0, 0.4983280192861031, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T15:42:07.209669Z",
     "iopub.status.busy": "2021-03-09T15:42:07.209404Z",
     "iopub.status.idle": "2021-03-09T15:42:07.220127Z",
     "shell.execute_reply": "2021-03-09T15:42:07.218087Z",
     "shell.execute_reply.started": "2021-03-09T15:42:07.209645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 48.23)(1, 54.39)(2, 60.56)(3, 63.79)(4, 65.64)(5, 66.59)(6, 67.19)(7, 67.6)(8, 67.89)(9, 68.03)(10, 100.0)"
     ]
    }
   ],
   "source": [
    "# LATEX COORDINATES GENERATOR\n",
    "col = stats['classified']\n",
    "for i in range(11):\n",
    "    print((i,round(col[i]*100,2)), end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Non-mandatory predictions 0,1,2,... days after order date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-12T09:31:38.310871Z",
     "iopub.status.busy": "2021-02-12T09:31:38.310537Z",
     "iopub.status.idle": "2021-02-12T09:34:19.938146Z",
     "shell.execute_reply": "2021-02-12T09:34:19.936876Z",
     "shell.execute_reply.started": "2021-02-12T09:31:38.310843Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n"
     ]
    }
   ],
   "source": [
    "PREDICT_DAYS = 10\n",
    "threshold = 0.8\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "results = {}\n",
    "\n",
    "dynamic_threshold = np.linspace(0.95,threshold,PREDICT_DAYS+1)\n",
    "dynamic_count = 0\n",
    "\n",
    "for DAYS in range(PREDICT_DAYS+1):\n",
    "    \n",
    "    X, y = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, DAYS)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "    Tree = ClassHierarchy('ORDERS')\n",
    "    Tree.add_node(['UNKNOWN','KNOWN'], 'ORDERS')\n",
    "    Tree.add_node(['HAPPY','UNHAPPY'], 'KNOWN')\n",
    "    Tree.add_node(['MILDLY UNHAPPY','MEDIUM UNHAPPY','HEAVILY UNHAPPY'], 'UNHAPPY')\n",
    "\n",
    "    HC = HierarchicalClassifier(Tree)\n",
    "    HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "                        'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth = 10),\n",
    "                        'UNHAPPY' : KerasClassifier(build_fn = functions.neuralNetwork, epochs = 15, verbose = 0)})\n",
    "    \n",
    "    HC = HC.fit(X_train,y_train['detailedMatchClassification'])\n",
    "    pred = HC.predict_proba(X_test, threshold = dynamic_threshold[dynamic_count])\n",
    "    \n",
    "    fraction_label, fraction_leaf, accuracy_leaf = day_block_scores(HC, y_test['detailedMatchClassification'], pred)\n",
    "    \n",
    "    predictions[DAYS] = pred\n",
    "    results['DAY '+str(DAYS)] = (fraction_label, fraction_leaf, accuracy_leaf)\n",
    "    \n",
    "    dynamic_count += 1\n",
    "    \n",
    "    print('DAYS: ',DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T09:34:19.942295Z",
     "iopub.status.busy": "2021-02-12T09:34:19.941636Z",
     "iopub.status.idle": "2021-02-12T09:34:20.006608Z",
     "shell.execute_reply": "2021-02-12T09:34:20.002309Z",
     "shell.execute_reply.started": "2021-02-12T09:34:19.942247Z"
    }
   },
   "outputs": [],
   "source": [
    "changes = {}\n",
    "for i in range(0,predictions.shape[1]-1):\n",
    "    col_t0 = predictions.iloc[:,i]\n",
    "    col_t1 = predictions.iloc[:,i+1]\n",
    "    \n",
    "    check_leaf_t0 = col_t0.isin(Tree._get_leaf_nodes())\n",
    "    index_leaf_t0 = check_leaf_t0[check_leaf_t0].index\n",
    "    \n",
    "    col_t0_leaf = col_t0.loc[index_leaf_t0]\n",
    "    col_t1_leaf = col_t1.loc[index_leaf_t0]\n",
    "    \n",
    "    check_similarity = (col_t0_leaf == col_t1_leaf)\n",
    "    if i == 0:\n",
    "        ix = check_similarity[check_similarity == False].index\n",
    "    \n",
    "    changes['DAY '+str(i+1)] = 1 - (check_similarity.sum() / col_t0_leaf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-12T09:34:20.020310Z",
     "iopub.status.busy": "2021-02-12T09:34:20.019700Z",
     "iopub.status.idle": "2021-02-12T09:34:20.069459Z",
     "shell.execute_reply": "2021-02-12T09:34:20.054155Z",
     "shell.execute_reply.started": "2021-02-12T09:34:20.020250Z"
    }
   },
   "outputs": [],
   "source": [
    "days0, stats = zip(*results.items())\n",
    "fraction_label, fraction_leaf, accuracy_leaf = zip(*stats)\n",
    "days1, change = zip(*changes.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-12T15:17:44.732108Z",
     "iopub.status.busy": "2021-02-12T15:17:44.731830Z",
     "iopub.status.idle": "2021-02-12T15:17:44.918889Z",
     "shell.execute_reply": "2021-02-12T15:17:44.917573Z",
     "shell.execute_reply.started": "2021-02-12T15:17:44.732082Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffa756a1310>]"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(days0,fraction_label)\n",
    "plt.plot(days0,fraction_leaf)\n",
    "plt.plot(days0,accuracy_leaf)\n",
    "plt.plot(days1,change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T16:01:20.739645Z",
     "iopub.status.busy": "2021-03-09T16:01:20.739361Z",
     "iopub.status.idle": "2021-03-09T16:01:20.829706Z",
     "shell.execute_reply": "2021-03-09T16:01:20.824052Z",
     "shell.execute_reply.started": "2021-03-09T16:01:20.739614Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_performance(DAYS, END, pred, current_pred, index_leaf, index_no_leaf, previous_pred_block, THRESHOLDS, OPTION, CERTAINTY, y_test, Tree, HC, feature_importances, statistics):\n",
    "    \n",
    "    #Initialize Dictionary at Day 0\n",
    "    \n",
    "    if DAYS == 0:\n",
    "        statistics = {'%classified'     :{}, 'N_classified'         :{},  'N_predicted' : {},\n",
    "                      'leaf_accuracy'   :{}, 'total_leaf_accuracy'  :{},\n",
    "                      'leaf_precision'  :{}, 'total_leaf_precision' :{},\n",
    "                      'leaf_recall'     :{}, 'total_leaf_recall'    :{},\n",
    "                      'label_precision' :{}, \n",
    "                      'label_recall'    :{}, \n",
    "                      'block_precision' :{},\n",
    "                      'block_recall'    :{},\n",
    "                      'block_Nchange'   :{}, 'block_Pchange'        :{},\n",
    "                      '%blocking'       :{}, '%Tblocking'           :{},\n",
    "                      'tree_error'      :{},\n",
    "                      'thresholds'      :{},\n",
    "                      'option'          :{},\n",
    "                      'certainty'       :{}}\n",
    "\n",
    "        for leaf in Tree._get_leaf_nodes()+Tree._get_internal_nodes(): \n",
    "            statistics['precision_'+leaf] = {}\n",
    "            statistics['recall_'+leaf]    = {}\n",
    "            statistics['f1_'+leaf]        = {}\n",
    "            \n",
    "        feature_importances = pd.DataFrame(index = X_col)\n",
    "        decision_trees = {}\n",
    "    \n",
    "    #Get Daily information\n",
    "    \n",
    "    check_block = pred.isin(Tree._get_internal_nodes())\n",
    "    index_block = check_block[check_block].index        \n",
    "        \n",
    "    total_check_leaf = current_pred.isin(Tree._get_leaf_nodes())   #of all predictions which are now leaf\n",
    "    total_index_leaf = total_check_leaf[total_check_leaf].index\n",
    "        \n",
    "    if DAYS > 0:\n",
    "        block = pd.concat([previous_pred_block, pred.loc[previous_pred_block.index]], axis=1, keys = [0,1])\n",
    "        block['Nchange'] = block.apply(lambda row: 0 if row[1] in Tree._get_descendants(row[0])+[row[0]] else 1, axis = 1)\n",
    "        block['Pchange'] = block.apply(lambda row: 1 if row[1] in Tree._get_descendants(row[0]) else 0, axis = 1)\n",
    "    previous_pred_block = pred.loc[index_block]\n",
    "    #previous_index_block = index_block\n",
    "\n",
    "    y_test = y_test['detailedMatchClassification']\n",
    "    test_pred = pd.concat([y_test.loc[index_leaf], current_pred[index_leaf]], axis=1, keys = [0,1])\n",
    "    test_pred['TE'] = test_pred.apply(lambda row: Tree._tree_distance(row[0], row[1]), axis = 1)\n",
    "    \n",
    "    #Update Dictionary\n",
    "    \n",
    "    statistics['option'][DAYS]          = OPTION\n",
    "    statistics['certainty'][DAYS]       = CERTAINTY\n",
    "    statistics['thresholds'][DAYS]      = THRESHOLDS\n",
    "    statistics['%classified'][DAYS]     = current_pred.isin(Tree._get_leaf_nodes()).sum() / len(y_test)\n",
    "    statistics['N_classified'][DAYS]    = int(len(index_leaf))\n",
    "    statistics['N_predicted'][DAYS]     = int(len(pred))\n",
    "\n",
    "    statistics['leaf_accuracy'][DAYS]   = metrics.accuracy_score(y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "    statistics['leaf_precision'][DAYS]  = precision_score_ancestors(Tree, y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "    statistics['leaf_recall'][DAYS]     = recall_score_ancestors(Tree, y_test.loc[index_leaf], pred.loc[index_leaf])\n",
    "\n",
    "    for leaf in Tree._get_leaf_nodes()+Tree._get_internal_nodes():\n",
    "        leaf_ix = pred.loc[pred == leaf].index\n",
    "        statistics['precision_'+leaf][DAYS] = precision_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "        statistics['recall_'+leaf][DAYS]    = recall_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix])\n",
    "        statistics['f1_'+leaf][DAYS]        = f1_score_ancestors(Tree, y_test.loc[leaf_ix], pred.loc[leaf_ix], beta = 1)\n",
    "        \n",
    "    for clf in list(HC.stages.keys()):\n",
    "        if isinstance(HC.stages[clf]['classifier'],RandomForestClassifier):\n",
    "            feature_importances[clf+'_'+str(DAYS)] = HC.stages[clf]['classifier'].feature_importances_ \n",
    "        elif isinstance(HC.stages[clf]['classifier'],LogisticRegression):\n",
    "            feature_importances[clf+'_'+str(DAYS)] = HC.stages[clf]['classifier'].coef_[0] \n",
    "\n",
    "    statistics['total_leaf_accuracy'][DAYS]  = metrics.accuracy_score(y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "    statistics['total_leaf_precision'][DAYS] = precision_score_ancestors(Tree, y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "    statistics['total_leaf_recall'][DAYS]    = recall_score_ancestors(Tree, y_test.loc[total_index_leaf], current_pred.loc[total_index_leaf])\n",
    "\n",
    "    statistics['label_precision'][DAYS]  = precision_score_ancestors(Tree, y_test.loc[index_leaf.union(index_block)], pred.loc[index_leaf.union(index_block)]) \n",
    "    statistics['label_recall'][DAYS]     = recall_score_ancestors(Tree, y_test.loc[index_leaf.union(index_block)], pred.loc[index_leaf.union(index_block)])  \n",
    "\n",
    "    statistics['block_precision'][DAYS] = precision_score_ancestors(Tree, y_test.loc[index_block], pred.loc[index_block]) if DAYS < END else None\n",
    "    statistics['block_recall'][DAYS]    = recall_score_ancestors(Tree, y_test.loc[index_block], pred.loc[index_block]) if DAYS < END else None\n",
    "    statistics['block_Nchange'][DAYS]   = block['Nchange'].sum() / block['Nchange'].count() if DAYS > 0 else None\n",
    "    statistics['block_Pchange'][DAYS]   = block['Pchange'].sum() / block['Pchange'].count() if DAYS > 0 else None\n",
    "    statistics['%blocking'][DAYS]       = HC.blocking  if len(total_index_leaf) != len(y_test) else {'ORDERS':None,'KNOWN':None,'UNHAPPY':None}\n",
    "    statistics['%Tblocking'][DAYS]      = HC.Tblocking if len(total_index_leaf) != len(y_test) else {'ORDERS':None,'KNOWN':None,'UNHAPPY':None}\n",
    "\n",
    "    statistics['tree_error'][DAYS]      = np.mean(test_pred['TE'])\n",
    "        \n",
    "    return statistics, feature_importances, previous_pred_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T16:01:21.413014Z",
     "iopub.status.busy": "2021-03-09T16:01:21.412745Z",
     "iopub.status.idle": "2021-03-09T16:01:21.438713Z",
     "shell.execute_reply": "2021-03-09T16:01:21.437422Z",
     "shell.execute_reply.started": "2021-03-09T16:01:21.412989Z"
    }
   },
   "outputs": [],
   "source": [
    "def global_scores(y_true, y_pred, average = 'macro'):\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = average)\n",
    "    return accuracy, scores[0], scores[1], scores[2]\n",
    "\n",
    "def local_scores(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = metrics.precision_recall_fscore_support(y_true, y_pred, average = None, labels = labels, beta = 1)\n",
    "    return scores[0], scores[1], scores[2]\n",
    "\n",
    "def class_report(y_true, y_pred):\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "\n",
    "def _aggregate_class_sets(set_function, y_true, y_pred):\n",
    "    intersection_sum = 0\n",
    "    true_sum = 0\n",
    "    predicted_sum = 0\n",
    "    for true, pred in zip(list(y_true), list(y_pred)):\n",
    "        true_set = set([true] + set_function(true))\n",
    "        pred_set = set([pred] + set_function(pred))\n",
    "        intersection_sum += len(true_set.intersection(pred_set))\n",
    "        true_sum += len(true_set)\n",
    "        predicted_sum += len(pred_set)\n",
    "    return (true_sum, predicted_sum, intersection_sum)\n",
    "\n",
    "def precision_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    if predicted_sum == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return intersection_sum / predicted_sum\n",
    "\n",
    "def recall_score_ancestors(class_hierarchy, y_true, y_pred):\n",
    "    true_sum, predicted_sum, intersection_sum = _aggregate_class_sets(\n",
    "        class_hierarchy._get_ancestors, y_true, y_pred)\n",
    "    if true_sum == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return intersection_sum / true_sum\n",
    "\n",
    "def f1_score_ancestors(class_hierarchy, y_true, y_pred, beta):\n",
    "    precision = precision_score_ancestors(class_hierarchy, y_true, y_pred)\n",
    "    recall = recall_score_ancestors(class_hierarchy, y_true, y_pred)\n",
    "    if (precision == None) or (recall == None):\n",
    "        return None\n",
    "    elif (precision == 0) or (recall == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T16:01:21.880318Z",
     "iopub.status.busy": "2021-03-09T16:01:21.880031Z",
     "iopub.status.idle": "2021-03-09T16:01:21.907613Z",
     "shell.execute_reply": "2021-03-09T16:01:21.906100Z",
     "shell.execute_reply.started": "2021-03-09T16:01:21.880292Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassHierarchy:\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.nodes = {}\n",
    "        \n",
    "    def add_node(self, children, parent):\n",
    "        for child in children:\n",
    "            self.nodes[child] = parent\n",
    "            \n",
    "    def _get_leaf_nodes(self):\n",
    "        leaf_nodes = []\n",
    "        for child in self.nodes.keys():\n",
    "            if self._get_children(child) == []:\n",
    "                leaf_nodes.append(child)\n",
    "        return leaf_nodes\n",
    "    \n",
    "    def _get_internal_nodes(self):\n",
    "        internal_nodes = []\n",
    "        leaves = self._get_leaf_nodes()\n",
    "        for child in self.nodes.keys():\n",
    "            if (child != self.root) and (child not in leaves):\n",
    "                internal_nodes.append(child)\n",
    "        return internal_nodes\n",
    "\n",
    "    def _get_children(self, parent):\n",
    "        return sorted([child for child, childs_parent in\n",
    "                       self.nodes.items() if childs_parent == parent])\n",
    "    \n",
    "    def _get_parent(self, child):\n",
    "        return self.nodes[child] if (child in self.nodes and child != self.root) else self.root\n",
    "    \n",
    "    def _get_ancestors(self, child):\n",
    "        # Not including root, not including the child\n",
    "        ancestors = []\n",
    "        while True:\n",
    "            child = self._get_parent(child)\n",
    "            if child == self.root:\n",
    "                break\n",
    "            ancestors.append(child)\n",
    "        return ancestors\n",
    "    \n",
    "    def _get_descendants(self, parent):\n",
    "        # Return a list of the descendants of this node, not including the parent\n",
    "        descendants = []\n",
    "        self._depth_first(parent, descendants)\n",
    "        descendants.remove(parent)\n",
    "        return descendants\n",
    "    \n",
    "    def _depth_first(self, parent, classes):\n",
    "        classes.append(parent)\n",
    "        for node in self._get_children(parent):\n",
    "            self._depth_first(node, classes)\n",
    "            \n",
    "    def _tree_distance(self, y_test, pred):\n",
    "        \n",
    "        y_test_path = [y_test] + self._get_ancestors(y_test) + [self.root] if y_test != self.root else [y_test] + self._get_ancestors(y_test)\n",
    "        pred_path   = [pred] + self._get_ancestors(pred) + [self.root] if pred != self.root else [pred] + self._get_ancestors(pred)\n",
    "        \n",
    "        y_test_edges = []\n",
    "        for ix, node in enumerate(y_test_path):\n",
    "            length = len(y_test_path)\n",
    "            if ix < length - 1:\n",
    "                y_test_edges.append((node, y_test_path[ix+1]))\n",
    "                \n",
    "        pred_edges = []\n",
    "        for ix, node in enumerate(pred_path):\n",
    "            length = len(pred_path)\n",
    "            if ix < length - 1:\n",
    "                pred_edges.append((node, pred_path[ix+1]))        \n",
    "        \n",
    "        tree_distance = len([edge for edge in y_test_edges + pred_edges if edge not in pred_edges or edge not in y_test_edges])\n",
    "        \n",
    "        return tree_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T16:01:22.363543Z",
     "iopub.status.busy": "2021-03-09T16:01:22.363290Z",
     "iopub.status.idle": "2021-03-09T16:01:22.428957Z",
     "shell.execute_reply": "2021-03-09T16:01:22.427288Z",
     "shell.execute_reply.started": "2021-03-09T16:01:22.363519Z"
    }
   },
   "outputs": [],
   "source": [
    "class HierarchicalClassifier:\n",
    "\n",
    "    def __init__(self, class_hierarchy):\n",
    "        self.stages = {}\n",
    "        self.class_hierarchy = class_hierarchy\n",
    "        self._create_stages(self.stages, self.class_hierarchy.root, 0)\n",
    "\n",
    "    def _create_stages(self, stages, parent, depth):\n",
    "        # Get the children of this parent\n",
    "        children = self.class_hierarchy._get_children(parent)\n",
    "        \n",
    "        if len(children) > 0:\n",
    "            stage = {}\n",
    "            stage['depth'] = depth\n",
    "            stage['labels'] = children\n",
    "            stage['classes'] = stage['labels'] + [parent]\n",
    "            stage['target'] = 'target_stage_' + parent\n",
    "            stages[parent] = stage\n",
    "\n",
    "            for node in children:\n",
    "                self._create_stages(stages, node, depth + 1)\n",
    "                \n",
    "    def _recode_label(self, classes, label):\n",
    "\n",
    "        while label != self.class_hierarchy.root and label not in classes:\n",
    "            label = self.class_hierarchy._get_parent(label)\n",
    "        return label\n",
    "                \n",
    "    def _prep_data(self, X, y):\n",
    "        \n",
    "        Xcols = range(0, X.shape[1])\n",
    "        Ycol = X.shape[1]\n",
    "        \n",
    "        df = pd.concat([X, y], axis=1, ignore_index=True)\n",
    "        # Create a target column for each stage with the recoded labels\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            df[stage_info['target']] = pd.DataFrame.apply(df[[Ycol]],\n",
    "                                    lambda row: self._recode_label(stage_info['classes'], row[Ycol]),\n",
    "                                    axis=1)\n",
    "        return df, Xcols\n",
    "    \n",
    "    def _label_mapping(self, y_train, stage_name):\n",
    "        labels = np.unique(y_train)\n",
    "        int_label_mapping = dict(enumerate(labels))\n",
    "        label_int_mapping = {y:x for x,y in int_label_mapping.items()}\n",
    "        self.stages[stage_name]['mapping'] = {'int_label':int_label_mapping,\n",
    "                                              'label_int':label_int_mapping}\n",
    "        \n",
    "    def _class_weights(self, y_train, stage_name):\n",
    "        class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(y_train),y = y_train)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        self.stages[stage_name]['classifier'].set_params(class_weight = class_weights)\n",
    "    \n",
    "    def fit_classifiers(self, classifiers):\n",
    "        \"\"\"\n",
    "        Fit a classifier to each stage\n",
    "        \"\"\"\n",
    "        if classifiers.keys() != self.stages.keys():\n",
    "             raise ValueError('Your assigned classifiers do not match the stages of the hierarchy, fit a classifier to each of: '+self.stages.keys())\n",
    "        else:\n",
    "            for stage, classifier in classifiers.items():\n",
    "                self.stages[stage]['classifier'] = classifier\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a multi-classifier from training data (X, y).\n",
    "        \"\"\"\n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        self.scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_train = dfFilter[Xcols]\n",
    "            y_train = dfFilter[[stage_info['target']]]\n",
    "                        \n",
    "            #warning - no samples to fit for stage\n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                y_train_col = pd.Series(np.ravel(y_train))\n",
    "                \n",
    "                self._class_weights(y_train_col, stage_name)\n",
    "                self._label_mapping(y_train_col, stage_name)\n",
    "\n",
    "                y_encoded = y_train_col.map(stage_info['mapping']['label_int'])\n",
    "\n",
    "                if len(stage_info['labels']) > 2:\n",
    "                    y_dummy = pd.DataFrame(np_utils.to_categorical(y_encoded))\n",
    "                    y_train_NN = y_dummy\n",
    "                else:\n",
    "                    y_train_NN = np.asarray(y_encoded).reshape((-1,1))\n",
    "\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_train))\n",
    "                stage_info['classifier'].fit(X_scaled, y_train_NN)\n",
    "            else:\n",
    "                stage_info['classifier'] = stage_info['classifier'].fit(X_train, y_train)\n",
    "            #print('Stage '+stage_name+' succesfully fitted')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if X_test.empty:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                if len(stage_info['labels']) == 2:\n",
    "                    y_pred = pd.Series(stage_info['classifier'].predict(X_scaled).flatten()).map(stage_info['mapping']['int_label'])\n",
    "                else:\n",
    "                    y_pred = pd.Series(stage_info['classifier'].predict(X_scaled)).map(stage_info['mapping']['int_label'])\n",
    "                y_hat_stage = pd.DataFrame(y_pred.values, index = X_test.index)\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(stage_info['classifier'].predict(X_test), index = X_test.index)\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]     \n",
    "    \n",
    "    def predict_proba(self, X, threshold = 0.5):\n",
    "        \n",
    "        self.blocking = {}\n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            max_prob = np.amax(y_proba, axis=1)              #max probability of classes\n",
    "            max_class = np.argmax(y_proba, axis=1)           #class number with max probability\n",
    "            accept_index = np.where(max_prob >= threshold)[0]#indexes which are above threshold\n",
    "            accept_class = np.take(max_class, accept_index)  #filtered list of orders which are above threshold\n",
    "            \n",
    "            if len(accept_class) > 0: #check if samples reach threshold\n",
    "                accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             #convert class number into label\n",
    "                y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  #set labels to correct position\n",
    "                self.blocking[stage_name] = 1 - (len(accept_class) / len(max_class)) #blocking factor\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "                self.blocking[stage_name] = 1\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "    \n",
    "    def predict_proba2(self, X, THRESHOLDS):\n",
    "        \n",
    "        self.blocking = {}\n",
    "        self.Tblocking = {}\n",
    "        stage_number = 0\n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "            \n",
    "            if stage_name == self.class_hierarchy.root:\n",
    "                y_hat = pd.DataFrame([self.class_hierarchy.root] * len(X),\n",
    "                                        columns=[self.class_hierarchy.root],\n",
    "                                        index=X.index)\n",
    "            else:\n",
    "                y_hat[stage_name] = y_hat[list(self.stages.keys())[stage_number - 1]]\n",
    "            stage_number += 1             \n",
    "                \n",
    "            X_test = X[y_hat[stage_name].isin([stage_name])]  #warning - no samples to fit for stage\n",
    "            \n",
    "            if X_test.empty:\n",
    "                self.blocking[stage_name] = None\n",
    "                self.Tblocking[stage_name] = None\n",
    "                continue\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            max_prob = np.amax(y_proba, axis=1)              #max probability of classes\n",
    "            max_class = np.argmax(y_proba, axis=1)           #class number with max probability\n",
    "            max_class_thresholds = np.vectorize(lambda x: THRESHOLDS[y_classes[x]])(max_class)  #get node specific threshold\n",
    "            \n",
    "            #print(pd.DataFrame({'max_prob':max_prob,'max_class':max_class,'max_class_thresholds':max_class_thresholds}))\n",
    "            \n",
    "            accept_index = np.where(max_prob >= max_class_thresholds)[0]\n",
    "\n",
    "            accept_class = np.take(max_class, accept_index)  #filtered list of orders which are above threshold\n",
    "            \n",
    "            if len(accept_class) > 0: #check if samples reach threshold\n",
    "                accept_label = np.vectorize(lambda x: y_classes[x])(accept_class)                             #convert class number into label\n",
    "                y_hat_stage = pd.DataFrame(accept_label, index = np.take(X_test.index.values, accept_index))  #set labels to correct position\n",
    "                \n",
    "#                 pja = pd.DataFrame({'max_prob':max_prob,'max_class':np.vectorize(lambda x: y_classes[x])(max_class)})\n",
    "#                 pja['accept_class'] = pd.Series(data = accept_class, index = accept_index)\n",
    "#                 print(pja)\n",
    "                \n",
    "                self.blocking[stage_name] = 1 - (len(accept_class) / len(max_class)) #blocking factor\n",
    "                self.Tblocking[stage_name] = len(max_class) - len(accept_class)\n",
    "            else:\n",
    "                y_hat_stage = pd.DataFrame(columns = [0], index = X_test.index)\n",
    "                self.blocking[stage_name] = 1\n",
    "                self.Tblocking[stage_name] = len(max_class)\n",
    "                \n",
    "            y_hat = y_hat.assign(stage_col = y_hat_stage)\n",
    "            y_hat.stage_col = y_hat.stage_col.fillna(y_hat[stage_name]) #fill previously predicted labels\n",
    "            y_hat = y_hat.drop(stage_name, axis=1)\n",
    "            y_hat = y_hat.rename(columns={'stage_col': stage_name})\n",
    "            \n",
    "        return y_hat.iloc[:, y_hat.shape[1] - 1]\n",
    "    \n",
    "    def get_probabilities(self, X, y):\n",
    "        \n",
    "        df, Xcols = self._prep_data(X, y)\n",
    "        \n",
    "        stage_number = 0\n",
    "        \n",
    "        y_hat = pd.DataFrame(columns = [self.class_hierarchy.root], index = X.index)\n",
    "        \n",
    "        for stage_name, stage_info in self.stages.items():\n",
    "                \n",
    "            stage_number += 1             \n",
    "            \n",
    "            dfFilter = df[df[stage_info['target']].isin(stage_info['classes'])]\n",
    "            \n",
    "            X_test = dfFilter[Xcols]\n",
    "            y_test = dfFilter[[stage_info['target']]]\n",
    "            \n",
    "            if isinstance(stage_info['classifier'], KerasClassifier):\n",
    "                X_scaled = pd.DataFrame(self.scaler.transform(X_test))\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_scaled)\n",
    "                y_classes = list(stage_info['mapping']['int_label'].values())\n",
    "            else:\n",
    "                y_proba = stage_info['classifier'].predict_proba(X_test)\n",
    "                y_classes = stage_info['classifier'].classes_\n",
    "            \n",
    "            y_hat_stage = pd.DataFrame(y_proba, index = X_test.index)\n",
    "\n",
    "            for col, label in enumerate(y_classes):\n",
    "                y_hat[label] = y_hat_stage[col]\n",
    "               \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-09T16:01:23.098713Z",
     "iopub.status.busy": "2021-03-09T16:01:23.098401Z",
     "iopub.status.idle": "2021-03-09T16:01:23.141302Z",
     "shell.execute_reply": "2021-03-09T16:01:23.139699Z",
     "shell.execute_reply.started": "2021-03-09T16:01:23.098676Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_probs(day):\n",
    "    HC = HierarchicalClassifier(ch)\n",
    "    HC.fit_classifiers({'ORDERS'  : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '1_criterion'], max_depth = hypers.loc[day, '1_max_depth']),\n",
    "                        'KNOWN'   : DecisionTreeClassifier(random_state=0, class_weight='balanced', criterion = hypers.loc[day, '2_criterion'], max_depth = hypers.loc[day, '2_max_depth']),\n",
    "                        'UNHAPPY' : RandomForestClassifier(random_state=0, class_weight='balanced', max_depth = hypers.loc[day, '3_max_depth'], n_estimators = hypers.loc[day, '3_n_estimators'])})\n",
    "    \n",
    "    X, y  = functions.dataX(df_, DATE, X_col, Y_col, historic_variable, day)\n",
    "    index = range(0, X.shape[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test, ix_train, ix_test = train_test_split(X, y, index, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "    HC.fit(X_train,y_train)\n",
    "    y_hat = HC.get_probabilities(X_train, y_train)\n",
    "\n",
    "    probs = pd.concat([y_train, y_hat], axis=1)\n",
    "    \n",
    "    return(probs)\n",
    "\n",
    "def opt_threshold(probs, node, day, certainty, option, steps = 100):\n",
    "    \n",
    "    if node == 1:\n",
    "        probabilities_for = 'UNKNOWN'\n",
    "        y_pos_filter_list = ['UNKNOWN']\n",
    "        y_neg_filter_list = ['HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[['UNKNOWN', 'KNOWN']]\n",
    "        majority_vote     = level[level['UNKNOWN'] > level['KNOWN']]['UNKNOWN']\n",
    "    elif node == 2:\n",
    "        probabilities_for = 'KNOWN'\n",
    "        y_pos_filter_list = ['HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['UNKNOWN']\n",
    "        level             = probs[['UNKNOWN', 'KNOWN']]\n",
    "        majority_vote     = level[level['KNOWN'] > level['UNKNOWN']]['KNOWN']\n",
    "    elif node == 3:\n",
    "        probabilities_for = 'HAPPY'\n",
    "        y_pos_filter_list = ['HAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY', 'HAPPY'])][['UNHAPPY', 'HAPPY']]\n",
    "        majority_vote     = level[level['HAPPY'] > level['UNHAPPY']]['HAPPY']\n",
    "    elif node == 4:\n",
    "        probabilities_for = 'UNHAPPY'\n",
    "        y_pos_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['HAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY', 'HAPPY'])][['UNHAPPY', 'HAPPY']]\n",
    "        majority_vote     = level[level['UNHAPPY'] > level['HAPPY']]['UNHAPPY']\n",
    "    elif node == 5:\n",
    "        probabilities_for = 'MILDLY UNHAPPY'\n",
    "        y_pos_filter_list = ['MILDLY UNHAPPY']\n",
    "        y_neg_filter_list = ['MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])][['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']]\n",
    "        majority_vote     = level[ (level['MILDLY UNHAPPY'] > level['MEDIUM UNHAPPY']) & (level['MILDLY UNHAPPY'] > level['HEAVILY UNHAPPY']) ]['MILDLY UNHAPPY']\n",
    "    elif node == 6:\n",
    "        probabilities_for = 'MEDIUM UNHAPPY'\n",
    "        y_pos_filter_list = ['MEDIUM UNHAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'HEAVILY UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])][['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']]\n",
    "        majority_vote     = level[ (level['MEDIUM UNHAPPY'] > level['MILDLY UNHAPPY']) & (level['MEDIUM UNHAPPY'] > level['HEAVILY UNHAPPY']) ]['MEDIUM UNHAPPY']\n",
    "    elif node == 7:\n",
    "        probabilities_for = 'HEAVILY UNHAPPY'\n",
    "        y_pos_filter_list = ['HEAVILY UNHAPPY']\n",
    "        y_neg_filter_list = ['MILDLY UNHAPPY', 'MEDIUM UNHAPPY']\n",
    "        level             = probs[probs.detailedMatchClassification.isin(['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])][['MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY']]\n",
    "        majority_vote     = level[ (level['HEAVILY UNHAPPY'] > level['MEDIUM UNHAPPY']) & (level['HEAVILY UNHAPPY'] > level['MILDLY UNHAPPY']) ]['HEAVILY UNHAPPY']\n",
    "    else:\n",
    "        raise Exception('''Error: undefined node has been passed. Node options (integer input):\n",
    "                           1: Unknown\n",
    "                           2: Known\n",
    "                           3: Happy\n",
    "                           4: Unhappy\n",
    "                           5: Mildly Unhappy\n",
    "                           6: Medium Unhappy\n",
    "                           7: Heavily Unhappy''')\n",
    "    \n",
    "    y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)][probabilities_for] \n",
    "    y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)][probabilities_for]\n",
    "    \n",
    "    if option == 1:\n",
    "        y_pos = y_pos[y_pos > min(majority_vote)]\n",
    "        y_neg = y_neg[y_neg > min(majority_vote)]\n",
    "    elif option == 2:\n",
    "        y_pos = y_pos[y_pos.index.isin(majority_vote.index)]\n",
    "        y_neg = y_neg[y_neg.index.isin(majority_vote.index)]\n",
    "    else:\n",
    "        raise Exception('''Error: undefined threshold option has been passed. Threshold options (integer input):\n",
    "                           1: Consider all probabilities >= min(majority vote)\n",
    "                           2: Only consider probabilities that are the majority vote''')\n",
    "    \n",
    "#     y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)]#[probabilities_for]\n",
    "#     y_pos = y_pos[y_pos[probabilities_for] > boundary][probabilities_for]\n",
    "#     y_pos = y_pos.sort_values()\n",
    "#     y_pos = y_pos.reset_index(drop = True)  \n",
    "\n",
    "#     y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)]#[probabilities_for]\n",
    "#     y_neg = y_neg[y_neg[probabilities_for] > boundary][probabilities_for]\n",
    "#     y_neg = y_neg.sort_values()\n",
    "#     y_neg = y_neg.reset_index(drop = True)\n",
    "    \n",
    "    # Potential thresholds\n",
    "    V = np.concatenate((y_pos, y_neg))\n",
    "#    V = np.append(V, 0.5)\n",
    "    V = np.unique(V) # np.unique() also sorts\n",
    "    #print('V unique:',V)\n",
    "    \n",
    "    #V = V[0:(len(V)-1)] #discard the highest probability as option, putting that as threshold is nonsensical since criterion is 'probability > threshold'\n",
    "    #V = V[V >= max(lowerbound, 0.5)] #define allowed search space\n",
    "    #V_length = len(V) \n",
    "    \n",
    "    if len(y_neg) > 0:\n",
    "        lowerbound = np.percentile(y_neg, (certainty*100))\n",
    "    else:\n",
    "        lowerbound = V.min()\n",
    "    \n",
    "    V = V[V >= lowerbound] #define allowed search space\n",
    "    #print('V > lowerbound:',V)\n",
    "    \n",
    "    #steps = math.floor((V.max() - V.min()) / stepsize)  OLD -> ERROR\n",
    "    #S = np.linspace(V.min(), V.max(), steps)            OLD -> ERROR\n",
    "    \n",
    "    S = np.linspace(V.min(), V.max(), steps)\n",
    "    \n",
    "    #print('S:',S)\n",
    "    \n",
    "    thresholds = pd.DataFrame({'threshold'     : [0]*steps,\n",
    "                               'F_score'       : [0]*steps})\n",
    "#                                'perc_rejected' : [0]*steps,\n",
    "#                                'perc_accepted' : [0]*steps,\n",
    "#                                'count_rejected': [0]*steps,\n",
    "#                                'count_accepted': [0]*steps})\n",
    "    #print('thresholds pre:',thresholds)\n",
    "    \n",
    "#     thresholds = pd.DataFrame({'threshold'      : [0]*V_length,\n",
    "#                                'F_score'        : [0]*V_length})\n",
    "    \n",
    "    for i in range(steps):        \n",
    "        threshold = S[i]       \n",
    "#         threshold = V[i] \n",
    "        beta      = 1\n",
    "        positives = len(y_pos[y_pos >= threshold])  #CHANGED > into >=\n",
    "        negatives = len(y_neg[y_neg >= threshold])  #CHANGED > into >=\n",
    "        recall    = positives / len(y_pos)\n",
    "        precision = positives / (positives + negatives)\n",
    "\n",
    "        thresholds.loc[i, 'threshold']       = threshold\n",
    "        thresholds.loc[i, 'F_score']         = ((beta ** 2 + 1) * precision * recall) / ((beta ** 2 * precision) + recall) if ((beta ** 2 * precision) + recall) != 0 else 0\n",
    "        \n",
    "    #print('thresholds post:',thresholds)\n",
    "        \n",
    "    F_score         = thresholds['F_score'].max()\n",
    "    opt_index       = thresholds['F_score'].argmax()\n",
    "    threshold       = thresholds.loc[opt_index, 'threshold']\n",
    "    \n",
    "    return(probabilities_for, threshold)\n",
    "\n",
    "def flat_thresholds(probs, node, day, certainty, steps = 100):\n",
    "    \n",
    "    NODES = set(['UNKNOWN', 'HAPPY', 'MILDLY UNHAPPY', 'MEDIUM UNHAPPY', 'HEAVILY UNHAPPY'])\n",
    "    \n",
    "    if node == 1:   NODE = 'UNKNOWN'\n",
    "    elif node == 2: NODE = 'HAPPY'\n",
    "    elif node == 3: NODE = 'MILDLY UNHAPPY'\n",
    "    elif node == 4: NODE = 'MEDIUM UNHAPPY'\n",
    "    elif node == 5: NODE = 'HEAVILY UNHAPPY'\n",
    "    else:\n",
    "        raise Exception('''Error: undefined node has been passed. Node options (integer input):\n",
    "                           1: Unknown\n",
    "                           2: Happy\n",
    "                           3: Mildly Unhappy\n",
    "                           4: Medium Unhappy\n",
    "                           5: Heavily Unhappy''')\n",
    "        \n",
    "    probabilities_for = NODE\n",
    "    y_pos_filter_list = [NODE]\n",
    "    y_neg_filter_list = list(NODES - {NODE})\n",
    "    majority_vote     = probs[probs[NODE] > probs[list(NODES - {NODE})].max(axis=1)][NODE]\n",
    "        \n",
    "    y_pos = probs[probs.detailedMatchClassification.isin(y_pos_filter_list)][probabilities_for] \n",
    "    y_neg = probs[probs.detailedMatchClassification.isin(y_neg_filter_list)][probabilities_for]\n",
    "    \n",
    "    y_pos = y_pos[y_pos.index.isin(majority_vote.index)]\n",
    "    y_neg = y_neg[y_neg.index.isin(majority_vote.index)]\n",
    " \n",
    "    if len(y_neg) > 0:\n",
    "        lowerbound = np.percentile(y_neg, (certainty*100))\n",
    "    else:\n",
    "        lowerbound = V.min()\n",
    "    \n",
    "    # Potential thresholds\n",
    "    V = np.concatenate((y_pos, y_neg))\n",
    "    V = np.unique(V) # np.unique() also sorts    \n",
    "    V = V[V >= lowerbound] #define allowed search space\n",
    "    S = np.linspace(V.min(), V.max(), steps)\n",
    "    \n",
    "    thresholds = pd.DataFrame({'threshold'     : [0]*steps,\n",
    "                               'F_score'       : [0]*steps})\n",
    "    \n",
    "    for i in range(steps):        \n",
    "        threshold = S[i] \n",
    "        beta      = 1\n",
    "        positives = len(y_pos[y_pos >= threshold])\n",
    "        negatives = len(y_neg[y_neg >= threshold])\n",
    "        recall    = positives / len(y_pos)\n",
    "        precision = positives / (positives + negatives)\n",
    "\n",
    "        thresholds.loc[i, 'threshold']       = threshold\n",
    "        thresholds.loc[i, 'F_score']         = ( (1 + (beta**2)) * precision * recall ) / ( (beta**2) * precision + recall ) if ( (beta**2) * precision + recall ) != 0 else 0\n",
    "        \n",
    "    \n",
    "    F_score         = thresholds['F_score'].max()\n",
    "    opt_index       = thresholds['F_score'].argmax()\n",
    "    threshold       = thresholds.loc[opt_index, 'threshold']                           \n",
    "\n",
    "    return(probabilities_for, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
