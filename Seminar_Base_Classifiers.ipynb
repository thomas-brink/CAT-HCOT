{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "authorized-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "attempted-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "import warnings\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import keras\n",
    "\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "import functions\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "above-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "trying-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (    \n",
    "    r'Driver={SQL Server};'\n",
    "    r'Server=LAPTOP-LD74USH0\\SQLEXPRESS;'\n",
    "    r'Integrated Security=SSPI;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "finnish-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql2df(query, params=[], parse_dates=None, dsn='SQLEXPRESS'):\n",
    "        with py.connect(connection_string, readonly=True) as conn:\n",
    "            return pd.read_sql(query, conn, params=params, parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "trained-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First work with random top 100.000 (to reduce computation time) - 45secs\n",
    "\n",
    "df = sql2df('''\n",
    "SELECT TOP 100000 * FROM Seminar.dbo.cleaned_bol_data_full\n",
    "ORDER BY newid();\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "domestic-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.5 minutes \n",
    "\n",
    "df = sql2df('''\n",
    "SELECT * FROM Seminar.dbo.cleaned_bol_data_full;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "inappropriate-interest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orderDate             datetime64[ns]\n",
       "productId                     object\n",
       "sellerId                      object\n",
       "totalPrice                   float64\n",
       "quantityOrdered                int64\n",
       "                           ...      \n",
       "orderSeptember                  bool\n",
       "orderOctober                    bool\n",
       "orderNovember                   bool\n",
       "orderDecember                   bool\n",
       "productTitleLength             int64\n",
       "Length: 78, dtype: object"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change type of columns\n",
    "dtype = {'calculationDefinitive': bool,\n",
    "         'noCancellation': bool,\n",
    "         'noCase': bool,\n",
    "         'hasOneCase': bool,\n",
    "         'hasMoreCases': bool,\n",
    "         'noReturn': bool,\n",
    "         'orderWeekend': bool,\n",
    "         'orderCorona': bool,\n",
    "         'countryCodeNL': bool,\n",
    "         'fulfilmentByBol': bool,\n",
    "         'countryOriginNL': bool,\n",
    "         'countryOriginBE': bool,\n",
    "         'countryOriginDE': bool,\n",
    "         'orderMonday': bool,\n",
    "         'orderTuesday': bool,\n",
    "         'orderWednesday': bool,\n",
    "         'orderThursday': bool,\n",
    "         'orderFriday': bool,\n",
    "         'orderSaturday': bool,\n",
    "         'orderSunday': bool,\n",
    "         'orderJanuary': bool,\n",
    "         'orderFebruary': bool,\n",
    "         'orderMarch': bool,\n",
    "         'orderApril': bool,\n",
    "         'orderMay': bool,\n",
    "         'orderJune': bool,\n",
    "         'orderJuly': bool,\n",
    "         'orderAugust': bool,\n",
    "         'orderSeptember': bool,\n",
    "         'orderOctober': bool,\n",
    "         'orderNovember': bool,\n",
    "         'orderDecember': bool}\n",
    "\n",
    "df = df.astype(dtype)\n",
    "\n",
    "#Transform dates to date-type\n",
    "df['orderDate'] = pd.to_datetime(df['orderDate'], errors='coerce')\n",
    "df['cancellationDate'] = pd.to_datetime(df['cancellationDate'], errors='coerce')\n",
    "df['promisedDeliveryDate'] = pd.to_datetime(df['promisedDeliveryDate'], errors='coerce')\n",
    "df['shipmentDate'] = pd.to_datetime(df['shipmentDate'], errors='coerce')\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'], errors='coerce')\n",
    "df['startDateCase'] = pd.to_datetime(df['startDateCase'], errors='coerce')\n",
    "df['returnDateTime'] = pd.to_datetime(df['returnDateTime'], errors='coerce')\n",
    "df['registrationDateSeller'] = pd.to_datetime(df['registrationDateSeller'], errors='coerce')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-korea",
   "metadata": {},
   "source": [
    "#### Add variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "municipal-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification variable\n",
    "df['binaryMatchClassification'] = df['generalMatchClassification'].apply(lambda x: 'UNKNOWN' if x == 'UNKNOWN' else 'KNOWN')\n",
    "\n",
    "# Dummy for year = 2020\n",
    "df['orderYear2020'] = df['orderYear'].apply(lambda x: True if x == 2020 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-bumper",
   "metadata": {},
   "source": [
    "#### Transporter Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "outside-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transporterCluster(transporterCode):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered transporter variable: 28 -> 5 categories\n",
    "    \"\"\"\n",
    "    if transporterCode in ['AH-NL','TNT','TNT-EXPRESS','TNT-EXTRA']:\n",
    "        return 'POSTNL'\n",
    "    elif transporterCode in ['DHL','DHL_DE','DHLFORYOU']:\n",
    "        return 'DHL'\n",
    "    elif transporterCode in ['DPD-NL','DPD-BE']:\n",
    "        return 'DPD'\n",
    "    elif transporterCode in ['BRIEFPOST','BPOST_BE','BPOST_BRIEF','DHL-GLOBAL-MAIL','TNT_BRIEF']:\n",
    "        return 'BRIEF'\n",
    "    else:\n",
    "        return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "sitting-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSTNL    2110753\n",
       "BRIEF     1576462\n",
       "DHL        436975\n",
       "DPD        329746\n",
       "OTHER      319014\n",
       "Name: transporterCodeGeneral, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transporterCodeGeneral'] = df['transporterCode'].apply(transporterCluster)\n",
    "df['transporterCodeGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-watch",
   "metadata": {},
   "source": [
    "#### Product Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "fifth-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "def productGroupCluster(productGroup):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered product group variable based on categories bol.com\n",
    "    60 -> 14 groups.\n",
    "    \"\"\"\n",
    "    if productGroup in ['Dutch Books PG','Ebooks and Audiobooks','International Books PG']:\n",
    "        return 'Books'\n",
    "    elif productGroup in ['Games Accessories','Games Consoles','Games Software Physical',\n",
    "                          'Movies','Music']:\n",
    "        return 'Music, Film & Games'\n",
    "    elif productGroup in ['Camera','Desktop Monitor and Beamer','Ereaders and Accessories',\n",
    "                          'Laptop Computers','PC Accessories','Personal Audio',\n",
    "                          'Sound and Vision Accessories','Storage and Network',\n",
    "                          'Telephone and Tablet Accessories','Telephones and Tablets','Television']:\n",
    "        return 'Computer & Electronics'\n",
    "    elif productGroup in ['General Toys','Recreational and Outdoor Toys']:\n",
    "        return 'Toys & Hobby'\n",
    "    elif productGroup in ['Baby and Kids Fashion','Baby PG']:\n",
    "        return 'Baby & Kids'\n",
    "    elif productGroup in ['Daily Care PG','Health PG','Perfumery PG','Personal Care']:\n",
    "        return 'Health & Care'\n",
    "    elif productGroup in ['Footwear','Jewelry and Watches','Mens and Womens Fashion','Wearables']:\n",
    "        return 'Fashion, Shoes & Accessories'\n",
    "    elif productGroup in ['Bodyfashion and Beachwear','Camping and Outdoor','Cycling',\n",
    "                          'Sporting Equipment','Sportswear','Travel Bags and Accessories']:\n",
    "        return 'Sports, Outdoor & Travel'\n",
    "    elif productGroup in ['Educational Dutch','Educational International','Printing and Ink']:\n",
    "        return 'Office & School'\n",
    "    elif productGroup in ['Supermarket PG'] :\n",
    "        return 'Food & Beverage'\n",
    "    elif productGroup in ['Furniture','Heating and Air','Home Decoration','Home Entertainment',\n",
    "                          'Household','Household Appliances','Kitchen','Kitchen Machines',\n",
    "                          'Lighting','Major Domestic Appliances PG','Plumbing and Safety']:\n",
    "        return 'Home, Cooking & Household'\n",
    "    elif productGroup in ['Garden','Pet PG','Textiles','Tools and Paint']:\n",
    "        return 'Pets, Garden & Jobs'\n",
    "    elif productGroup in ['Car and Motorcycle'] :\n",
    "        return 'Car & Motor'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "original-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer & Electronics          1387679\n",
       "Home, Cooking & Household        797874\n",
       "Sports, Outdoor & Travel         522098\n",
       "Toys & Hobby                     500977\n",
       "Pets, Garden & Jobs              339813\n",
       "Health & Care                    299049\n",
       "Food & Beverage                  258769\n",
       "Books                            184581\n",
       "Music, Film & Games              163842\n",
       "Baby & Kids                      113707\n",
       "Fashion, Shoes & Accessories     110067\n",
       "Office & School                   52270\n",
       "Car & Motor                       29753\n",
       "Other                             12471\n",
       "Name: productGroupGeneral, dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['productGroupGeneral'] = df['productGroup'].apply(productGroupCluster)\n",
    "df['productGroupGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "frank-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummies of new product grouping\n",
    "for group in df['productGroupGeneral'].unique():\n",
    "    \n",
    "    columnName = 'group' + group.split(' ')[0].replace(',','')\n",
    "    df[columnName] = df['productGroupGeneral'].apply(lambda x: True if x == group else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "german-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orderDate', 'productId', 'sellerId', 'totalPrice', 'quantityOrdered',\n",
      "       'countryCode', 'cancellationDate', 'cancellationReasonCode',\n",
      "       'promisedDeliveryDate', 'shipmentDate', 'transporterCode',\n",
      "       'transporterName', 'transporterNameOther',\n",
      "       'dateTimeFirstDeliveryMoment', 'fulfilmentType', 'startDateCase',\n",
      "       'cntDistinctCaseIds', 'returnDateTime', 'quantityReturned',\n",
      "       'returnCode', 'productTitle', 'brickName', 'chunkName', 'productGroup',\n",
      "       'productSubGroup', 'productSubSubGroup', 'registrationDateSeller',\n",
      "       'countryOriginSeller', 'currentCountryAvailabilitySeller',\n",
      "       'calculationDefinitive', 'noCancellation', 'onTimeDelivery', 'noCase',\n",
      "       'hasOneCase', 'hasMoreCases', 'noReturn', 'detailedMatchClassification',\n",
      "       'generalMatchClassification', 'determinantClassification', 'orderYear',\n",
      "       'orderMonth', 'orderYearMonth', 'orderWeekday', 'orderWeekend',\n",
      "       'orderCorona', 'transporterFeature', 'partnerSellingMonths',\n",
      "       'cancellationDays', 'shipmentDays', 'promisedDeliveryDays',\n",
      "       'actualDeliveryDays', 'caseDays', 'returnDays', 'countryCodeNL',\n",
      "       'fulfilmentByBol', 'countryOriginNL', 'countryOriginBE',\n",
      "       'countryOriginDE', 'orderMonday', 'orderTuesday', 'orderWednesday',\n",
      "       'orderThursday', 'orderFriday', 'orderSaturday', 'orderSunday',\n",
      "       'orderJanuary', 'orderFebruary', 'orderMarch', 'orderApril', 'orderMay',\n",
      "       'orderJune', 'orderJuly', 'orderAugust', 'orderSeptember',\n",
      "       'orderOctober', 'orderNovember', 'orderDecember', 'productTitleLength',\n",
      "       'binaryMatchClassification', 'orderYear2020', 'transporterCodeGeneral',\n",
      "       'productGroupGeneral', 'groupComputer', 'groupToys', 'groupMusic',\n",
      "       'groupPets', 'groupOther', 'groupHome', 'groupSports', 'groupFood',\n",
      "       'groupHealth', 'groupBooks', 'groupBaby', 'groupCar', 'groupFashion',\n",
      "       'groupOffice'],\n",
      "      dtype='object')\n",
      "Total:  96  columns\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print('Total: ',len(df.columns),' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "coated-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "\n",
    "#Classifications\n",
    "CLASS = ['generalMatchClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-conversion",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "outdoor-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addKnownColumns(df,X):\n",
    "    \"\"\"\n",
    "    Function to create columns which indicate whether determinants are known after X days.\n",
    "    Input: X = number of days after order date at which the prediction is made\n",
    "           df = dataFrame\n",
    "    \"\"\"\n",
    "#     df_ = df[['actualDeliveryDays','onTimeDelivery','shipmentDays','transporterCodeGeneral']]\n",
    "    \n",
    "    df['caseKnownX']           = df['caseDays'].apply(lambda x: True if x <= X else False)\n",
    "    df['returnKnownX']         = df['returnDays'].apply(lambda x: True if x <= X else False)\n",
    "    df['cancellationKnownX']   = df['cancellationDays'].apply(lambda x: True if x <= X else False)\n",
    "    \n",
    "#     df_['actualDeliveryKnown'] = df['actualDeliveryDays'].apply(lambda x: True if x <= X else False)\n",
    "#     df_['shipmentDaysKnown']   = df['shipmentDays'].apply(lambda x: True if x <= X else False)\n",
    "    \n",
    "    df['onTimeDeliveryKnownX'] = df.apply(lambda row: True if ((row.actualDeliveryDays <= X) and (row.onTimeDelivery == True)) else False, axis = 1)\n",
    "    df['lateDeliveryKnownX']   = df.apply(lambda row: True if ((row.actualDeliveryDays <= X) and (row.onTimeDelivery == False)) else False, axis = 1)\n",
    "    \n",
    "    for transporter in df['transporterCodeGeneral'].unique():\n",
    "        dummyColumn = 'transporter' + transporter +'/X'\n",
    "        df[dummyColumn] = df.apply(lambda row: True if ((row.shipmentDays <= X) and (row.transporterCodeGeneral == transporter)) else False, axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "imported-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addProductColumns(df,X):\n",
    "    \n",
    "    if ['productOrderCount0','productTotalCount0','productTotalReturned0','productReturnFraction0'] not in list(df.columns):\n",
    "    \n",
    "        df = addProductColumns0(df)\n",
    "    \n",
    "    if X > 0:\n",
    "        \n",
    "        df = addProductColumnsX(df,X)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df['productOrderCountX'] = df['productOrderCount0']\n",
    "        df['productTotalCountX'] = df['productTotalCount0']\n",
    "        df['productTotalReturnedX'] = df['productTotalReturned0']\n",
    "        df['productReturnFractionX'] = df['productReturnFraction0']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "interior-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSellerColumns(df,X):\n",
    "    \n",
    "    if 'sellerDailyOrders0' not in list(df.columns):\n",
    "    \n",
    "        df = addSellerColumns0(df)\n",
    "    \n",
    "    if X > 0:\n",
    "        \n",
    "        df = addSellerColumnsX(df,X)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        df['sellerDailyOrdersX'] = df['sellerDailyOrders0']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "corresponding-battle",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addProductColumns0(df): \n",
    "    \"\"\"\n",
    "    Function to add 4 columns: productOrderCount, productTotalCount, productTotalReturned and productReturnFraction.\n",
    "    Input: dataFrame with columns: 'productId','orderDate','quantityOrdered','quantityReturned','returnDateTime'.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by = ['productId','orderDate'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df_ = df[['productId','orderDate','quantityOrdered','quantityReturned','returnDateTime']]\n",
    "    \n",
    "    #ProductTotalCount\n",
    "    pivot = df_.groupby(['productId','orderDate']).quantityOrdered.sum().groupby('productId').cumsum()\n",
    "    productTotalCount = df_.merge(pivot, \n",
    "                                left_on=['productId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').quantityOrdered_y\n",
    "    \n",
    "    #ProductOrderCount\n",
    "    pivot = df_.groupby(['productId','orderDate']).quantityOrdered.count().groupby('productId').cumsum()\n",
    "    productOrderCount = df_.merge(pivot, \n",
    "                                left_on=['productId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').quantityOrdered_y\n",
    "    \n",
    "    #ProductTotalReturned\n",
    "    productTotalReturned = np.zeros(df_.shape[0])\n",
    "    \n",
    "    previousID = None\n",
    "    \n",
    "    returnDic = {}\n",
    "    \n",
    "    for row in df_.itertuples(): #iterate through dataFrame: row[0] = index, row[1] = productId, row[2] = orderDate\n",
    "                                                           # row[3] = quantityOrdered, row[4] = quantityReturned\n",
    "        if row[0] == 0:                                    # row[5] = returnDateTime\n",
    "            \n",
    "            #update return dictionary if this product is returned\n",
    "            if row[4] != None:\n",
    "                if row[5] in returnDic:\n",
    "                    returnDic[row[5]] += row[4]\n",
    "                else:\n",
    "                    returnDic[row[5]] = row[4]\n",
    "\n",
    "            previousID = row[1]\n",
    "            \n",
    "        elif (previousID == row[1]):\n",
    "            \n",
    "            #update return dictionary if this product is returned\n",
    "            if row[4] != None:\n",
    "                if row[5] in returnDic:\n",
    "                    returnDic[row[5]] += row[4]\n",
    "                else:\n",
    "                    returnDic[row[5]] = row[4]\n",
    "            \n",
    "            #add returned products to new dictionary if known\n",
    "            known = {k: v for k, v in returnDic.items() if k <= row[2]}\n",
    "            productTotalReturned[row[0]] = sum(known.values())\n",
    "            \n",
    "            #update the dictionary by removing the returns which are now known\n",
    "            returnDic = {k: v for k, v in returnDic.items() if k > row[2]}\n",
    "                        \n",
    "            previousID = row[1]\n",
    "            \n",
    "        else:\n",
    "            returnDic = {} #new productId, hence empty the return dictionary\n",
    "            \n",
    "            #update return dictionary if this product is returned\n",
    "            if row[4] != None:\n",
    "                if row[5] in returnDic:\n",
    "                    returnDic[row[5]] += row[4]\n",
    "                else:\n",
    "                    returnDic[row[5]] = row[4]\n",
    "                    \n",
    "            previousID = row[1]\n",
    "    \n",
    "    df_['productTotalReturned'] = productTotalReturned\n",
    "    pivot = df_.groupby(by = ['productId','orderDate']).productTotalReturned.sum().groupby('productId').cumsum()\n",
    "    productTotalReturned = df_.merge(pivot, \n",
    "                                left_on=['productId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').productTotalReturned_y\n",
    "     \n",
    "    #Add new columns to dataFrame    \n",
    "    df['productOrderCount0'] = productOrderCount\n",
    "    df['productTotalCount0'] = productTotalCount\n",
    "    df['productTotalReturned0'] = productTotalReturned\n",
    "    df['productReturnFraction0'] = productTotalReturned / productTotalCount\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "cutting-probe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addProductColumnsX(df,X):\n",
    "    \"\"\"\n",
    "    Function to add 4 columns: productOrderCountX, productTotalCountX, productTotalReturnedX and productReturnFractionX.\n",
    "    Input: dataFrame with columns: 'productId','orderDate','productOrderCount','productTotalCount','productTotalReturned'\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by = ['productId','orderDate'], ascending = [True, False]) #reverse ordering on Orderdate!\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df_ = df[['productId','orderDate','productOrderCount0','productTotalCount0','productTotalReturned0']]\n",
    "    #            row[1]       row[2]        row[3]               row[4]                 row[5]    \n",
    "    \n",
    "    df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
    "    #      row[6]\n",
    "\n",
    "    knownProductInfo = np.zeros((df_.shape[0],3))\n",
    "    \n",
    "    previousID = None\n",
    "    previousMaxDate = None\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    for row in df_.itertuples(): #iterate  \n",
    "                                                                  \n",
    "        if row[0] == 0:                                          \n",
    "            \n",
    "            knownProductInfo[[row[0]]] = (row[3],row[4],row[5]) \n",
    "            \n",
    "            dic[row[2]] = (row[3],row[4],row[5])\n",
    "\n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "            \n",
    "        elif (previousID == row[1]):\n",
    "            \n",
    "            if row[6] >= previousMaxDate:\n",
    "                dic[row[2]] = (row[3],row[4],row[5])\n",
    "                knownProductInfo[[row[0]]] = dic[max(dic)]\n",
    "            else:\n",
    "                dic[row[2]] = (row[3],row[4],row[5])\n",
    "                dic = {k: v for k, v in dic.items() if k <= row[6]}\n",
    "                \n",
    "                knownProductInfo[[row[0]]] = dic[max(dic)]\n",
    "                previousMaxDate = max(dic)\n",
    "                 \n",
    "            previousID = row[1]\n",
    "            \n",
    "        else:\n",
    "            dic = {} #new productId -> empty the dictionary\n",
    "            \n",
    "            knownProductInfo[[row[0]]] = (row[3],row[4],row[5])\n",
    "            dic[row[2]] = (row[3],row[4],row[5])\n",
    "                    \n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "\n",
    "    df['productOrderCountX'] = knownProductInfo[:,0]\n",
    "    df['productTotalCountX'] = knownProductInfo[:,1]\n",
    "    df['productTotalReturnedX'] = knownProductInfo[:,2]\n",
    "    df['productReturnFractionX'] = knownProductInfo[:,2] / knownProductInfo[:,1]\n",
    "    \n",
    "    #Reverse to natural order\n",
    "    df = df.sort_values(by = ['productId','orderDate'], ascending = [True, True])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "valued-version",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addSellerColumns0(df):\n",
    "    \"\"\"\n",
    "    Function to add 4 columns: \n",
    "    Input: dataFrame with columns: 'sellerId','orderDate','quantityOrdered','partnerSellingMonths'\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by = ['sellerId','orderDate'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df_ = df[['sellerId','orderDate','quantityOrdered','partnerSellingMonths']]\n",
    "    \n",
    "    firstOrder = df_.groupby('sellerId').orderDate.min()\n",
    "    df_['firstOrder'] = df_.merge(firstOrder,\n",
    "                                  left_on = 'sellerId',\n",
    "                                  right_index = True,\n",
    "                                  how = 'left').orderDate_y\n",
    "    df_['daysFirstOrder'] = (df_['orderDate'] - df_['firstOrder']).dt.days + 1\n",
    "    \n",
    "    pivot = df_.groupby(['sellerId','orderDate']).quantityOrdered.count().groupby('sellerId').cumsum()\n",
    "    sellerTotalCount = df_.merge(pivot, \n",
    "                                left_on=['sellerId','orderDate'], \n",
    "                                right_index=True, \n",
    "                                how = 'left').quantityOrdered_y\n",
    "    \n",
    "    df['sellerDailyOrders0'] = np.log(sellerTotalCount / df_['daysFirstOrder'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "closed-technique",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def addSellerColumnsX(df,X):\n",
    "    \"\"\"\n",
    "    Function to add 4 columns: \n",
    "    Input: dataFrame with columns: 'sellerId','orderDate','quantityOrdered','partnerSellingMonths'\n",
    "    \"\"\"\n",
    "        \n",
    "    df = df.sort_values(by = ['sellerId','orderDate'], ascending = [True, False]) #reverse ordering orderdate!\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    df_ = df[['sellerId','orderDate','sellerDailyOrders0']]\n",
    "    #            row[1]       row[2]        row[3]        \n",
    "\n",
    "    df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
    "    #      row[4]\n",
    "\n",
    "    knownSellerInfo = np.zeros(df_.shape[0])\n",
    "\n",
    "    previousID = None\n",
    "    previousMaxDate = None\n",
    "\n",
    "    dic = {}\n",
    "\n",
    "    for row in df_.itertuples(): #iterate  \n",
    "\n",
    "        if row[0] == 0:                                          \n",
    "\n",
    "            knownSellerInfo[[row[0]]] = row[3]\n",
    "\n",
    "            dic[row[2]] = row[3]\n",
    "\n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "\n",
    "        elif (previousID == row[1]):\n",
    "\n",
    "            if row[4] >= previousMaxDate:\n",
    "                dic[row[2]] = row[3]\n",
    "                knownSellerInfo[[row[0]]] = dic[max(dic)]\n",
    "            else:\n",
    "                dic[row[2]] = row[3]\n",
    "                dic = {k: v for k, v in dic.items() if k <= row[4]}\n",
    "\n",
    "                knownSellerInfo[[row[0]]] = dic[max(dic)]\n",
    "                previousMaxDate = max(dic)\n",
    "\n",
    "            previousID = row[1]\n",
    "\n",
    "        else:\n",
    "            dic = {} #new productId -> empty the dictionary\n",
    "\n",
    "            knownSellerInfo[[row[0]]] = row[3]\n",
    "            dic[row[2]] = row[3]\n",
    "\n",
    "            previousMaxDate = row[2]\n",
    "            previousID = row[1]\n",
    "\n",
    "    df['sellerDailyOrdersX'] = knownSellerInfo\n",
    "\n",
    "    #Reverse to natural order\n",
    "    df = df.sort_values(by = ['sellerId','orderDate'], ascending = [True, True])\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "conceptual-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLabels(classifier, X, y, n, split = 'TimeSeries', smote = False, scale = None, days = 0):\n",
    "    \"\"\"\n",
    "    Function to classify match labels using a pre-specified classifier with X and y variables. \n",
    "    \n",
    "    Input:\n",
    "    - classifier: can be any supported classifier. E.g. DecisionTreeClassifier(random_state=0, class_weight='balanced', max_depth=10). Necessary!\n",
    "    - X: dataframe input on explanatory features. Necessary!\n",
    "    - y: dataframe input on labels. Necessary!\n",
    "    - n: number of folds to be evaluated.\n",
    "    - split: object that can take value 'Random' to make K-fold random train/test split. Default is to apply time series split.\n",
    "    - smote: boolean, if true Synthetic Minority Oversampling will be applied. Default = False.\n",
    "    - scale: object that can take values 'MinMax' or 'Standard' to scale X correspondingly. Any other input will not scale X. Default = None.\n",
    "    - days: integer number of days after orderDate that should be considered. Default = 0.\n",
    "    \n",
    "    Output: \n",
    "    - accuracy: list of accuracies for the n evaluated classifiers.\n",
    "    - class_report: report of performance measures for the n evaluated classifiers.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = {}\n",
    "    class_report = {}\n",
    "    count = 1\n",
    "    \n",
    "    if split == 'Random':\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits = n, random_state = 0, shuffle = True)\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            if scale == 'MinMax':\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            elif scale == 'Standard':\n",
    "                scaler = preprocessing.StandardScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            else:\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            if smote == True:\n",
    "                smote = SMOTE('not majority')\n",
    "                X_train, y_train = smote.fit_sample(X_train,y_train)\n",
    "            else:\n",
    "                X_train, y_train = X_train, y_train\n",
    "            \n",
    "            clf = classifier\n",
    "            clf = clf.fit(X_train,y_train)\n",
    "            prediction = clf.predict(X_test)\n",
    "            accuracy[count] = metrics.accuracy_score(y_test, prediction)\n",
    "            class_report[count] = metrics.classification_report(y_test, prediction)\n",
    "    \n",
    "            print(count)\n",
    "            count +=1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits = n)\n",
    "        \n",
    "        for train_index, test_index in tscv.split(X):\n",
    "        \n",
    "            if scale == 'MinMax':\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            elif scale == 'Standard':\n",
    "                scaler = preprocessing.StandardScaler()\n",
    "                X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "                X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            else:\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            if smote == True:\n",
    "                smote = SMOTE('not majority')\n",
    "                X_train, y_train = smote.fit_sample(X_train,y_train)\n",
    "            else:\n",
    "                X_train, y_train = X_train, y_train\n",
    "            \n",
    "            clf = classifier\n",
    "            clf = clf.fit(X_train,y_train)\n",
    "            prediction = clf.predict(X_test)\n",
    "            accuracy[count] = metrics.accuracy_score(y_test, prediction)\n",
    "            class_report[count] = metrics.classification_report(y_test, prediction)\n",
    "    \n",
    "            print(count)\n",
    "            count +=1\n",
    "\n",
    "    return(accuracy, class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "casual-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['productId', 'sellerId', 'countryCode', 'cancellationReasonCode', 'transporterCode', 'transporterName', 'transporterNameOther', 'fulfilmentType', 'returnCode', 'productTitle', 'brickName', 'chunkName', 'productGroup', 'productSubGroup', 'productSubSubGroup', 'countryOriginSeller', 'currentCountryAvailabilitySeller', 'onTimeDelivery', 'detailedMatchClassification', 'generalMatchClassification', 'determinantClassification', 'orderMonth', 'orderYearMonth', 'transporterFeature', 'binaryMatchClassification', 'transporterCodeGeneral', 'productGroupGeneral']\n"
     ]
    }
   ],
   "source": [
    "#Categorical variables\n",
    "s = (df.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-character",
   "metadata": {},
   "source": [
    "# Function-based Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-anxiety",
   "metadata": {},
   "source": [
    "## Define X and y variables for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "noticed-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['orderDate']\n",
    "X_col_base = ['totalPrice','quantityOrdered','promisedDeliveryDays','orderCorona','partnerSellingMonths',\n",
    "        'countryCodeNL', 'fulfilmentByBol', 'countryOriginNL', 'countryOriginBE', 'countryOriginDE', 'orderWeekend',\n",
    "        'orderMonday','orderTuesday', 'orderWednesday', 'orderThursday', 'orderFriday', 'orderSaturday', 'orderSunday',\n",
    "        'orderJanuary', 'orderFebruary', 'orderMarch', 'orderApril', 'orderMay', 'orderJune', 'orderJuly',\n",
    "        'orderAugust', 'orderSeptember', 'orderOctober', 'orderNovember', 'orderDecember', 'productTitleLength',\n",
    "        'orderYear2020', 'groupComputer', 'groupFood', 'groupBooks', 'groupHealth', 'groupToys', 'groupSports', \n",
    "        'groupHome', 'groupOffice', 'groupPets', 'groupMusic', 'groupFashion', 'groupBaby', 'groupOther', 'groupCar']\n",
    "#y_col = ['binaryMatchClassification']\n",
    "y_col = ['generalMatchClassification']\n",
    "#'productOrderCount', 'productReturnFraction', "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-nowhere",
   "metadata": {},
   "source": [
    "## Function to return X and y for a pre-specified number of days after orderDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "reasonable-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataX(df,days):\n",
    "    \"\"\"\n",
    "    Function to return features and output labels for a pre-specified number of days after orderDate. \n",
    "    \n",
    "    Input:\n",
    "    - df: dataframe containing all features available at the time of ordering.\n",
    "    - days: integer number of days after orderDate that should be considered.\n",
    "    \n",
    "    Output: \n",
    "    - X: dataframe output of features that can be used the number of days after orderDate. E.g. information on cases and deliveries are added.\n",
    "    - y: dataframe output of output labels that can be used the number of days after orderDate.\n",
    "    \"\"\"    \n",
    "    \n",
    "    df = addKnownColumns(df,days)\n",
    "    df = addProductColumns(df,days)\n",
    "    df = addSellerColumns(df,days)\n",
    "    \n",
    "    if days == 0:\n",
    "        X_col = X_col_base + ['productOrderCountX', 'productTotalCountX',\n",
    "                 'productTotalReturnedX', 'productReturnFractionX', 'sellerDailyOrdersX']\n",
    "    else:\n",
    "        X_col = X_col_base + ['caseKnownX', 'returnKnownX', 'cancellationKnownX', 'onTimeDeliveryKnownX',\n",
    "                 'lateDeliveryKnownX', 'transporterPOSTNL/X', 'transporterDHL/X', 'transporterDPD/X', \n",
    "                 'transporterBRIEF/X', 'transporterOTHER/X', 'productOrderCountX', 'productTotalCountX',\n",
    "                 'productTotalReturnedX', 'productReturnFractionX', 'sellerDailyOrdersX']\n",
    "\n",
    "    df_test = df[index+X_col+y_col].dropna()\n",
    "    df_test = df_test.sort_values(by = 'orderDate')\n",
    "    df_test = df_test.reset_index(drop = True)\n",
    "\n",
    "    X = df_test[X_col]\n",
    "    y = df_test[y_col]\n",
    "    \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-trigger",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-calendar",
   "metadata": {},
   "source": [
    "### Function: classifyLabels(classifier, X, y, n, split = 'TimeSeries', smote = False, scale = None, days = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "Lets Go\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "A = 5\n",
    "\n",
    "resultsAcc = {}\n",
    "resultsClass = {}\n",
    "\n",
    "for DAYS in range(A):\n",
    "    \n",
    "    X, y = dataX(df,DAYS)\n",
    "    print('Lets Go')\n",
    "    \n",
    "    accuracy, class_report = classifyLabels(DecisionTreeClassifier(random_state=0,\n",
    "                                                                   class_weight='balanced'), X, y, n = 3)\n",
    "        \n",
    "    resultsAcc[DAYS] = accuracy\n",
    "    resultsClass[DAYS] = class_report\n",
    "    \n",
    "    print(DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "designing-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1: 0.82324, 2: 0.84432, 3: 0.82716},\n",
       " 1: {1: 0.90316, 2: 0.91356, 3: 0.91212},\n",
       " 2: {1: 0.91408, 2: 0.93048, 3: 0.93216},\n",
       " 3: {1: 0.9212, 2: 0.94012, 3: 0.94224},\n",
       " 4: {1: 0.93256, 2: 0.94392, 3: 0.94504},\n",
       " 5: {1: 0.93532, 2: 0.9452, 3: 0.95116},\n",
       " 6: {1: 0.93988, 2: 0.95092, 3: 0.95264},\n",
       " 7: {1: 0.9432, 2: 0.9524, 3: 0.95688},\n",
       " 8: {1: 0.944, 2: 0.95528, 3: 0.95772},\n",
       " 9: {1: 0.94812, 2: 0.95604, 3: 0.95768}}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "public-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_accuracies_binary = resultsAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "vocal-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_report_binary = resultsClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "useful-operation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.84      0.91      0.87     16759\n",
      "     UNKNOWN       0.77      0.65      0.71      8241\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.81      0.78      0.79     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.86      0.94      0.90     18233\n",
      "     UNKNOWN       0.78      0.59      0.67      6767\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.82      0.76      0.78     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.82      0.95      0.88     16847\n",
      "     UNKNOWN       0.85      0.57      0.68      8153\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.76      0.78     25000\n",
      "weighted avg       0.83      0.83      0.82     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.92      0.94      0.93     16759\n",
      "     UNKNOWN       0.87      0.83      0.85      8241\n",
      "\n",
      "    accuracy                           0.90     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.90      0.90      0.90     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.93      0.95      0.94     18233\n",
      "     UNKNOWN       0.86      0.81      0.84      6767\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.90      0.88      0.89     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.91      0.96      0.94     16847\n",
      "     UNKNOWN       0.91      0.81      0.86      8153\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.91      0.89      0.90     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.93      0.94      0.94     16759\n",
      "     UNKNOWN       0.87      0.86      0.87      8241\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.90      0.90      0.90     25000\n",
      "weighted avg       0.91      0.91      0.91     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.96      0.95     18233\n",
      "     UNKNOWN       0.89      0.84      0.87      6767\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.92      0.90      0.91     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.97      0.95     16847\n",
      "     UNKNOWN       0.92      0.86      0.89      8153\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.91      0.92     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.93      0.95      0.94     16759\n",
      "     UNKNOWN       0.90      0.86      0.88      8241\n",
      "\n",
      "    accuracy                           0.92     25000\n",
      "   macro avg       0.91      0.91      0.91     25000\n",
      "weighted avg       0.92      0.92      0.92     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     18233\n",
      "     UNKNOWN       0.90      0.87      0.89      6767\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.93      0.92      0.92     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16847\n",
      "     UNKNOWN       0.93      0.89      0.91      8153\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.93     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.96      0.95     16759\n",
      "     UNKNOWN       0.91      0.88      0.90      8241\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.92      0.92     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     18233\n",
      "     UNKNOWN       0.92      0.87      0.89      6767\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.93      0.92      0.93     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16847\n",
      "     UNKNOWN       0.94      0.89      0.91      8153\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.94      0.93      0.94     25000\n",
      "weighted avg       0.94      0.95      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.94      0.96      0.95     16759\n",
      "     UNKNOWN       0.92      0.88      0.90      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.93      0.92      0.93     25000\n",
      "weighted avg       0.94      0.94      0.93     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     18233\n",
      "     UNKNOWN       0.93      0.87      0.90      6767\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.94      0.92      0.93     25000\n",
      "weighted avg       0.94      0.95      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.98      0.96     16847\n",
      "     UNKNOWN       0.95      0.90      0.92      8153\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.94      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.96      0.96     16759\n",
      "     UNKNOWN       0.92      0.89      0.91      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.93     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.94      0.88      0.91      6767\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.93      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.98      0.97     16847\n",
      "     UNKNOWN       0.95      0.90      0.93      8153\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.94      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16759\n",
      "     UNKNOWN       0.93      0.90      0.91      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.94     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.94      0.88      0.91      6767\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.93      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     16847\n",
      "     UNKNOWN       0.96      0.91      0.93      8153\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.96      0.94      0.95     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16759\n",
      "     UNKNOWN       0.94      0.89      0.91      8241\n",
      "\n",
      "    accuracy                           0.94     25000\n",
      "   macro avg       0.94      0.93      0.94     25000\n",
      "weighted avg       0.94      0.94      0.94     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.95      0.89      0.91      6767\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.95      0.93      0.94     25000\n",
      "weighted avg       0.96      0.96      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     16847\n",
      "     UNKNOWN       0.96      0.91      0.93      8153\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.96      0.94      0.95     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.95      0.97      0.96     16759\n",
      "     UNKNOWN       0.94      0.90      0.92      8241\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.94      0.94     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     18233\n",
      "     UNKNOWN       0.95      0.89      0.92      6767\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.95      0.94      0.94     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.96      0.98      0.97     16847\n",
      "     UNKNOWN       0.96      0.91      0.93      8153\n",
      "\n",
      "    accuracy                           0.96     25000\n",
      "   macro avg       0.96      0.94      0.95     25000\n",
      "weighted avg       0.96      0.96      0.96     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(A):\n",
    "    for item in resultsClass[i].values():\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "elementary-liver",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-222-87b2216d9be3>:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['productTotalReturned'] = productTotalReturned\n",
      "<ipython-input-223-2e46c60816db>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
      "<ipython-input-224-c875244aaa5a>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['daysFirstOrder'] = (df_['orderDate'] - df_['firstOrder']).dt.days + 1\n",
      "<ipython-input-225-754f78ba8450>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['orderDateX'] = df_['orderDate'] + timedelta(X)\n",
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.8126, 2: 0.83996, 3: 0.8458}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.88      0.87      0.88     13647\n",
      "     UNHAPPY       0.49      0.56      0.53      3112\n",
      "     UNKNOWN       0.83      0.81      0.82      8241\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.74      0.75      0.74     25000\n",
      "weighted avg       0.82      0.81      0.82     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.86      0.92      0.89     15320\n",
      "     UNHAPPY       0.87      0.43      0.57      2913\n",
      "     UNKNOWN       0.78      0.84      0.81      6767\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.73      0.76     25000\n",
      "weighted avg       0.84      0.84      0.83     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.87      0.90      0.89     14006\n",
      "     UNHAPPY       0.85      0.41      0.55      2841\n",
      "     UNKNOWN       0.80      0.90      0.85      8153\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.84      0.74      0.76     25000\n",
      "weighted avg       0.85      0.85      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Bernoulli 1 day\n",
    "(X, y) = dataX(df,5)\n",
    "(accuracy,class_report) = classifyLabels(BernoulliNB(), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "nonprofit-landing",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.588248, 2: 0.689048, 3: 0.675984}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.61      0.68     68195\n",
      "     UNHAPPY       0.15      0.29      0.20     15437\n",
      "     UNKNOWN       0.66      0.66      0.66     41368\n",
      "\n",
      "    accuracy                           0.59    125000\n",
      "   macro avg       0.53      0.52      0.51    125000\n",
      "weighted avg       0.66      0.59      0.62    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.69      0.94      0.80     75861\n",
      "     UNHAPPY       0.00      0.00      0.00     14564\n",
      "     UNKNOWN       0.67      0.44      0.53     34575\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.45      0.46      0.44    125000\n",
      "weighted avg       0.61      0.69      0.63    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.66      0.94      0.78     70405\n",
      "     UNHAPPY       0.00      0.00      0.00     14378\n",
      "     UNKNOWN       0.72      0.46      0.56     40217\n",
      "\n",
      "    accuracy                           0.68    125000\n",
      "   macro avg       0.46      0.47      0.45    125000\n",
      "weighted avg       0.61      0.68      0.62    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Bernoulli\n",
    "(accuracy,class_report) = classifyLabels(BernoulliNB(), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "looking-firewall",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.648288, 2: 0.646056, 3: 0.644936}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.68      0.84      0.75     68195\n",
      "     UNHAPPY       0.18      0.08      0.11     15437\n",
      "     UNKNOWN       0.67      0.55      0.61     41368\n",
      "\n",
      "    accuracy                           0.65    125000\n",
      "   macro avg       0.51      0.49      0.49    125000\n",
      "weighted avg       0.62      0.65      0.62    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.71      0.83      0.76     75861\n",
      "     UNHAPPY       0.18      0.10      0.13     14564\n",
      "     UNKNOWN       0.59      0.48      0.53     34575\n",
      "\n",
      "    accuracy                           0.65    125000\n",
      "   macro avg       0.49      0.47      0.47    125000\n",
      "weighted avg       0.61      0.65      0.62    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.72      0.78      0.75     70405\n",
      "     UNHAPPY       0.16      0.10      0.12     14378\n",
      "     UNKNOWN       0.62      0.60      0.61     40217\n",
      "\n",
      "    accuracy                           0.64    125000\n",
      "   macro avg       0.50      0.49      0.49    125000\n",
      "weighted avg       0.62      0.64      0.63    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussian\n",
    "(accuracy,class_report) = classifyLabels(GaussianNB(), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "charged-conservative",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.776368, 2: 0.757728, 3: 0.762664}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.84      0.83      0.83     83632\n",
      "     UNKNOWN       0.66      0.68      0.67     41368\n",
      "\n",
      "    accuracy                           0.78    125000\n",
      "   macro avg       0.75      0.75      0.75    125000\n",
      "weighted avg       0.78      0.78      0.78    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.83      0.83      0.83     90425\n",
      "     UNKNOWN       0.56      0.56      0.56     34575\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.70      0.70      0.70    125000\n",
      "weighted avg       0.76      0.76      0.76    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       KNOWN       0.81      0.84      0.83     84783\n",
      "     UNKNOWN       0.64      0.59      0.62     40217\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.73      0.72      0.72    125000\n",
      "weighted avg       0.76      0.76      0.76    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-NN\n",
    "(accuracy,class_report) = classifyLabels(neighbors.KNeighborsClassifier(n_neighbors = 3), X, y, n = 3, scale = 'MinMax')\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "important-jacksonville",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.678176, 2: 0.685968, 3: 0.7108}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.75      0.76     68195\n",
      "     UNHAPPY       0.20      0.03      0.05     15437\n",
      "     UNKNOWN       0.59      0.80      0.68     41368\n",
      "\n",
      "    accuracy                           0.68    125000\n",
      "   macro avg       0.52      0.53      0.50    125000\n",
      "weighted avg       0.64      0.68      0.65    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.83      0.79     75861\n",
      "     UNHAPPY       0.21      0.05      0.08     14564\n",
      "     UNKNOWN       0.58      0.64      0.61     34575\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.52      0.51      0.49    125000\n",
      "weighted avg       0.64      0.69      0.66    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.81      0.79     70405\n",
      "     UNHAPPY       0.21      0.03      0.05     14378\n",
      "     UNKNOWN       0.64      0.79      0.71     40217\n",
      "\n",
      "    accuracy                           0.71    125000\n",
      "   macro avg       0.54      0.54      0.52    125000\n",
      "weighted avg       0.66      0.71      0.68    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "(accuracy,class_report) = classifyLabels(LogisticRegression(random_state=0,\n",
    "                                                            class_weight='balanced',\n",
    "                                                            fit_intercept=False,\n",
    "                                                            solver='liblinear'), X, y, n = 3, scale = 'MinMax')\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (very slow!)\n",
    "(accuracy,class_report) = classifyLabels(svm.SVC(random_state=0,\n",
    "                                                 class_weight='balanced'), X, y, n = 3, scale = 'MinMax')\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "guided-smell",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:635: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.9 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "{1: 0.603464, 2: 0.587064, 3: 0.603976}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.67      0.70     68195\n",
      "     UNHAPPY       0.14      0.18      0.16     15437\n",
      "     UNKNOWN       0.63      0.64      0.64     41368\n",
      "\n",
      "    accuracy                           0.60    125000\n",
      "   macro avg       0.50      0.50      0.50    125000\n",
      "weighted avg       0.63      0.60      0.61    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.66      0.70     75861\n",
      "     UNHAPPY       0.13      0.16      0.14     14564\n",
      "     UNKNOWN       0.52      0.61      0.56     34575\n",
      "\n",
      "    accuracy                           0.59    125000\n",
      "   macro avg       0.47      0.48      0.47    125000\n",
      "weighted avg       0.62      0.59      0.60    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.72      0.69      0.71     70405\n",
      "     UNHAPPY       0.13      0.18      0.15     14378\n",
      "     UNKNOWN       0.64      0.60      0.62     40217\n",
      "\n",
      "    accuracy                           0.60    125000\n",
      "   macro avg       0.50      0.49      0.49    125000\n",
      "weighted avg       0.63      0.60      0.62    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "(accuracy,class_report) = classifyLabels(DecisionTreeClassifier(random_state=0,\n",
    "                                                                class_weight='balanced'), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "nearby-faculty",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.73088, 2: 0.740224, 3: 0.751032}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.87      0.81     68195\n",
      "     UNHAPPY       0.15      0.02      0.03     15437\n",
      "     UNKNOWN       0.71      0.77      0.74     41368\n",
      "\n",
      "    accuracy                           0.73    125000\n",
      "   macro avg       0.54      0.55      0.52    125000\n",
      "weighted avg       0.66      0.73      0.69    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.76      0.90      0.83     75861\n",
      "     UNHAPPY       0.25      0.01      0.01     14564\n",
      "     UNKNOWN       0.69      0.70      0.69     34575\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.57      0.54      0.51    125000\n",
      "weighted avg       0.68      0.74      0.69    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.93      0.83     70405\n",
      "     UNHAPPY       0.30      0.01      0.02     14378\n",
      "     UNKNOWN       0.77      0.71      0.74     40217\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.61      0.55      0.53    125000\n",
      "weighted avg       0.70      0.75      0.70    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "(accuracy,class_report) = classifyLabels(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
    "                                                            n_estimators=50,\n",
    "                                                            random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "different-august",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.747288, 2: 0.75016, 3: 0.74272}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.92      0.82     68195\n",
      "     UNHAPPY       0.23      0.00      0.00     15437\n",
      "     UNKNOWN       0.75      0.75      0.75     41368\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.58      0.55      0.52    125000\n",
      "weighted avg       0.68      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.76      0.93      0.83     75861\n",
      "     UNHAPPY       0.45      0.00      0.00     14564\n",
      "     UNKNOWN       0.72      0.68      0.70     34575\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.65      0.54      0.51    125000\n",
      "weighted avg       0.71      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.73      0.94      0.82     70405\n",
      "     UNHAPPY       0.32      0.00      0.00     14378\n",
      "     UNKNOWN       0.78      0.66      0.72     40217\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.61      0.54      0.51    125000\n",
      "weighted avg       0.70      0.74      0.69    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "(accuracy,class_report) = classifyLabels(GradientBoostingClassifier(random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "immediate-entry",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.75276, 2: 0.751056, 3: 0.757056}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.92      0.83     68195\n",
      "     UNHAPPY       0.25      0.00      0.01     15437\n",
      "     UNKNOWN       0.75      0.76      0.76     41368\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.59      0.56      0.53    125000\n",
      "weighted avg       0.69      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.92      0.83     75861\n",
      "     UNHAPPY       0.22      0.00      0.00     14564\n",
      "     UNKNOWN       0.71      0.71      0.71     34575\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.56      0.54      0.52    125000\n",
      "weighted avg       0.69      0.75      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.94      0.83     70405\n",
      "     UNHAPPY       0.26      0.00      0.00     14378\n",
      "     UNKNOWN       0.79      0.71      0.75     40217\n",
      "\n",
      "    accuracy                           0.76    125000\n",
      "   macro avg       0.60      0.55      0.53    125000\n",
      "weighted avg       0.70      0.76      0.71    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hist Gradient Boosting\n",
    "(accuracy,class_report) = classifyLabels(HistGradientBoostingClassifier(random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "familiar-strategy",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.704248, 2: 0.691872, 3: 0.691832}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.84      0.79     68195\n",
      "     UNHAPPY       0.15      0.05      0.07     15437\n",
      "     UNKNOWN       0.70      0.72      0.71     41368\n",
      "\n",
      "    accuracy                           0.70    125000\n",
      "   macro avg       0.53      0.54      0.52    125000\n",
      "weighted avg       0.66      0.70      0.67    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.76      0.82      0.79     75861\n",
      "     UNHAPPY       0.16      0.06      0.09     14564\n",
      "     UNKNOWN       0.62      0.68      0.65     34575\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.51      0.52      0.51    125000\n",
      "weighted avg       0.65      0.69      0.67    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.74      0.82      0.78     70405\n",
      "     UNHAPPY       0.14      0.07      0.10     14378\n",
      "     UNKNOWN       0.70      0.68      0.69     40217\n",
      "\n",
      "    accuracy                           0.69    125000\n",
      "   macro avg       0.53      0.53      0.52    125000\n",
      "weighted avg       0.66      0.69      0.67    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "(accuracy,class_report) = classifyLabels(BaggingClassifier(n_estimators=10,\n",
    "                                                           random_state=0), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "liberal-aquarium",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-8a91e4f11b03>:85: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = clf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{1: 0.741472, 2: 0.743208, 3: 0.752912}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.90      0.82     68195\n",
      "     UNHAPPY       0.18      0.03      0.05     15437\n",
      "     UNKNOWN       0.75      0.74      0.75     41368\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.56      0.56      0.54    125000\n",
      "weighted avg       0.68      0.74      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.77      0.91      0.83     75861\n",
      "     UNHAPPY       0.17      0.03      0.05     14564\n",
      "     UNKNOWN       0.72      0.69      0.70     34575\n",
      "\n",
      "    accuracy                           0.74    125000\n",
      "   macro avg       0.55      0.54      0.53    125000\n",
      "weighted avg       0.68      0.74      0.70    125000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " KNOWN HAPPY       0.75      0.93      0.83     70405\n",
      "     UNHAPPY       0.18      0.03      0.05     14378\n",
      "     UNKNOWN       0.79      0.71      0.75     40217\n",
      "\n",
      "    accuracy                           0.75    125000\n",
      "   macro avg       0.57      0.55      0.54    125000\n",
      "weighted avg       0.70      0.75      0.71    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "(accuracy,class_report) = classifyLabels(RandomForestClassifier(n_estimators=10,\n",
    "                                                                random_state=0,\n",
    "                                                                class_weight='balanced'), X, y, n = 3)\n",
    "print(accuracy)\n",
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
