{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "continental-formation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T14:35:25.130165Z",
     "iopub.status.busy": "2021-02-01T14:35:25.129636Z",
     "iopub.status.idle": "2021-02-01T14:35:26.696380Z",
     "shell.execute_reply": "2021-02-01T14:35:26.696380Z",
     "shell.execute_reply.started": "2021-02-01T14:35:25.130165Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-processor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:19:00.260338Z",
     "iopub.status.busy": "2021-02-01T23:19:00.260338Z",
     "iopub.status.idle": "2021-02-01T23:19:03.545734Z",
     "shell.execute_reply": "2021-02-01T23:19:03.544737Z",
     "shell.execute_reply.started": "2021-02-01T23:19:00.260338Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc as py\n",
    "\n",
    "import warnings\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import importlib\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-empire",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:19:07.288121Z",
     "iopub.status.busy": "2021-02-01T23:19:07.288121Z",
     "iopub.status.idle": "2021-02-01T23:19:07.303071Z",
     "shell.execute_reply": "2021-02-01T23:19:07.302070Z",
     "shell.execute_reply.started": "2021-02-01T23:19:07.288121Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-pledge",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-amateur",
   "metadata": {},
   "source": [
    "## Option 1: via Data_Cleaning_Preparation code (preferred) -> load in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appointed-attendance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:19:12.211688Z",
     "iopub.status.busy": "2021-02-01T23:19:12.210689Z",
     "iopub.status.idle": "2021-02-01T23:20:08.907391Z",
     "shell.execute_reply": "2021-02-01T23:20:08.907391Z",
     "shell.execute_reply.started": "2021-02-01T23:19:12.211688Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/thoma/Documents/seminar_data/cleaned_prepared_data.csv', low_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "copyrighted-public",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:20:08.909392Z",
     "iopub.status.busy": "2021-02-01T23:20:08.908392Z",
     "iopub.status.idle": "2021-02-01T23:20:25.339025Z",
     "shell.execute_reply": "2021-02-01T23:20:25.337972Z",
     "shell.execute_reply.started": "2021-02-01T23:20:08.909392Z"
    }
   },
   "outputs": [],
   "source": [
    "df['orderDate'] = pd.to_datetime(df['orderDate'])\n",
    "df['cancellationDate'] = pd.to_datetime(df['cancellationDate'])\n",
    "df['promisedDeliveryDate'] = pd.to_datetime(df['promisedDeliveryDate'])\n",
    "df['shipmentDate'] = pd.to_datetime(df['shipmentDate'])\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'])\n",
    "df['startDateCase'] = pd.to_datetime(df['startDateCase'])\n",
    "df['returnDateTime'] = pd.to_datetime(df['returnDateTime'])\n",
    "df['registrationDateSeller'] = pd.to_datetime(df['registrationDateSeller'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aging-matthew",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:20:25.341016Z",
     "iopub.status.busy": "2021-02-01T23:20:25.340033Z",
     "iopub.status.idle": "2021-02-01T23:20:25.354240Z",
     "shell.execute_reply": "2021-02-01T23:20:25.353223Z",
     "shell.execute_reply.started": "2021-02-01T23:20:25.341016Z"
    }
   },
   "outputs": [],
   "source": [
    "historic_variable = ['transporterCode','sellerId','productGroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "anticipated-track",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:20:25.355181Z",
     "iopub.status.busy": "2021-02-01T23:20:25.355181Z",
     "iopub.status.idle": "2021-02-01T23:20:25.369564Z",
     "shell.execute_reply": "2021-02-01T23:20:25.368564Z",
     "shell.execute_reply.started": "2021-02-01T23:20:25.355181Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "DATE = ['orderDate']\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength','promisedDeliveryDays','partnerSellingDays', 'orderCorona']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "YEAR = ['orderYear2020']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "HISTORICX = []\n",
    "for x in range(len(historic_variable)):\n",
    "    HISTORICX = HISTORICX + [historic_variable[x]+'HistoricHappyX',historic_variable[x]+'HistoricUnhappyX',historic_variable[x]+'HistoricUnknownX']\n",
    "\n",
    "#Determinants\n",
    "DETERMINANT = ['noReturn', 'noCase', 'noCancellation', 'onTimeDelivery']\n",
    "\n",
    "#Classifications\n",
    "CLASSIFICATION = ['generalMatchClassification','detailedMatchClassification','binaryMatchClassification','determinantClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-environment",
   "metadata": {},
   "source": [
    "## Option 2: via direct sql connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressed-essay",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "connection_string = (    \n",
    "    r'Driver={SQL Server};'\n",
    "    r'Server=LAPTOP-LD74USH0\\SQLEXPRESS;'\n",
    "    r'Integrated Security=SSPI;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-extreme",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sql2df(query, params=[], parse_dates=None, dsn='SQLEXPRESS'):\n",
    "        with py.connect(connection_string, readonly=True) as conn:\n",
    "            return pd.read_sql(query, conn, params=params, parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "later-murray",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# First work with random top 100.000 (to reduce computation time) - 45secs\n",
    "\n",
    "df = sql2df('''\n",
    "SELECT TOP 500000 * FROM Seminar.dbo.cleaned_bol_data_full\n",
    "ORDER BY newid();\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "operating-relations",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 9.5 minutes \n",
    "\n",
    "df = sql2df('''\n",
    "SELECT * FROM Seminar.dbo.cleaned_bol_data_full;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "union-graphics",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orderDate             datetime64[ns]\n",
       "productId                     object\n",
       "sellerId                      object\n",
       "totalPrice                   float64\n",
       "quantityOrdered                int64\n",
       "                           ...      \n",
       "orderSeptember                  bool\n",
       "orderOctober                    bool\n",
       "orderNovember                   bool\n",
       "orderDecember                   bool\n",
       "productTitleLength             int64\n",
       "Length: 78, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change type of columns\n",
    "dtype = {'calculationDefinitive': bool,\n",
    "         'noCancellation': bool,\n",
    "         'noCase': bool,\n",
    "         'hasOneCase': bool,\n",
    "         'hasMoreCases': bool,\n",
    "         'noReturn': bool,\n",
    "         'orderWeekend': bool,\n",
    "         'orderCorona': bool,\n",
    "         'countryCodeNL': bool,\n",
    "         'fulfilmentByBol': bool,\n",
    "         'countryOriginNL': bool,\n",
    "         'countryOriginBE': bool,\n",
    "         'countryOriginDE': bool,\n",
    "         'orderMonday': bool,\n",
    "         'orderTuesday': bool,\n",
    "         'orderWednesday': bool,\n",
    "         'orderThursday': bool,\n",
    "         'orderFriday': bool,\n",
    "         'orderSaturday': bool,\n",
    "         'orderSunday': bool,\n",
    "         'orderJanuary': bool,\n",
    "         'orderFebruary': bool,\n",
    "         'orderMarch': bool,\n",
    "         'orderApril': bool,\n",
    "         'orderMay': bool,\n",
    "         'orderJune': bool,\n",
    "         'orderJuly': bool,\n",
    "         'orderAugust': bool,\n",
    "         'orderSeptember': bool,\n",
    "         'orderOctober': bool,\n",
    "         'orderNovember': bool,\n",
    "         'orderDecember': bool}\n",
    "\n",
    "df = df.astype(dtype)\n",
    "\n",
    "#Transform dates to date-type\n",
    "df['orderDate'] = pd.to_datetime(df['orderDate'], errors='coerce')\n",
    "df['cancellationDate'] = pd.to_datetime(df['cancellationDate'], errors='coerce')\n",
    "df['promisedDeliveryDate'] = pd.to_datetime(df['promisedDeliveryDate'], errors='coerce')\n",
    "df['shipmentDate'] = pd.to_datetime(df['shipmentDate'], errors='coerce')\n",
    "df['dateTimeFirstDeliveryMoment'] = pd.to_datetime(df['dateTimeFirstDeliveryMoment'], errors='coerce')\n",
    "df['startDateCase'] = pd.to_datetime(df['startDateCase'], errors='coerce')\n",
    "df['returnDateTime'] = pd.to_datetime(df['returnDateTime'], errors='coerce')\n",
    "df['registrationDateSeller'] = pd.to_datetime(df['registrationDateSeller'], errors='coerce')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-substance",
   "metadata": {},
   "source": [
    "#### Add variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "inside-paper",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Binary classification variable\n",
    "df['binaryMatchClassification'] = df['generalMatchClassification'].apply(lambda x: 'UNKNOWN' if x == 'UNKNOWN' else 'KNOWN')\n",
    "\n",
    "# Dummy for year = 2020\n",
    "df['orderYear2020'] = df['orderYear'].apply(lambda x: True if x == 2020 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-bathroom",
   "metadata": {},
   "source": [
    "#### Transporter Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "burning-fight",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def transporterCluster(transporterCode):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered transporter variable: 28 -> 5 categories\n",
    "    \"\"\"\n",
    "    if transporterCode in ['AH-NL','TNT','TNT-EXPRESS','TNT-EXTRA']:\n",
    "        return 'POSTNL'\n",
    "    elif transporterCode in ['DHL','DHL_DE','DHLFORYOU']:\n",
    "        return 'DHL'\n",
    "    elif transporterCode in ['DPD-NL','DPD-BE']:\n",
    "        return 'DPD'\n",
    "    elif transporterCode in ['BRIEFPOST','BPOST_BE','BPOST_BRIEF','DHL-GLOBAL-MAIL','TNT_BRIEF']:\n",
    "        return 'BRIEF'\n",
    "    else:\n",
    "        return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "original-batch",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSTNL    221508\n",
       "BRIEF     165035\n",
       "DHL        45527\n",
       "DPD        34475\n",
       "OTHER      33455\n",
       "Name: transporterCodeGeneral, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transporterCodeGeneral'] = df['transporterCode'].apply(transporterCluster)\n",
    "df['transporterCodeGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-nevada",
   "metadata": {},
   "source": [
    "#### Product Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compound-bleeding",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def productGroupCluster(productGroup):\n",
    "    \"\"\"\n",
    "    Function to create a new manually clustered product group variable based on categories bol.com\n",
    "    60 -> 14 groups.\n",
    "    \"\"\"\n",
    "    if productGroup in ['Dutch Books PG','Ebooks and Audiobooks','International Books PG']:\n",
    "        return 'Books'\n",
    "    elif productGroup in ['Games Accessories','Games Consoles','Games Software Physical',\n",
    "                          'Movies','Music']:\n",
    "        return 'Music, Film & Games'\n",
    "    elif productGroup in ['Camera','Desktop Monitor and Beamer','Ereaders and Accessories',\n",
    "                          'Laptop Computers','PC Accessories','Personal Audio',\n",
    "                          'Sound and Vision Accessories','Storage and Network',\n",
    "                          'Telephone and Tablet Accessories','Telephones and Tablets','Television']:\n",
    "        return 'Computer & Electronics'\n",
    "    elif productGroup in ['General Toys','Recreational and Outdoor Toys']:\n",
    "        return 'Toys & Hobby'\n",
    "    elif productGroup in ['Baby and Kids Fashion','Baby PG']:\n",
    "        return 'Baby & Kids'\n",
    "    elif productGroup in ['Daily Care PG','Health PG','Perfumery PG','Personal Care']:\n",
    "        return 'Health & Care'\n",
    "    elif productGroup in ['Footwear','Jewelry and Watches','Mens and Womens Fashion','Wearables']:\n",
    "        return 'Fashion, Shoes & Accessories'\n",
    "    elif productGroup in ['Bodyfashion and Beachwear','Camping and Outdoor','Cycling',\n",
    "                          'Sporting Equipment','Sportswear','Travel Bags and Accessories']:\n",
    "        return 'Sports, Outdoor & Travel'\n",
    "    elif productGroup in ['Educational Dutch','Educational International','Printing and Ink']:\n",
    "        return 'Office & School'\n",
    "    elif productGroup in ['Supermarket PG'] :\n",
    "        return 'Food & Beverage'\n",
    "    elif productGroup in ['Furniture','Heating and Air','Home Decoration','Home Entertainment',\n",
    "                          'Household','Household Appliances','Kitchen','Kitchen Machines',\n",
    "                          'Lighting','Major Domestic Appliances PG','Plumbing and Safety']:\n",
    "        return 'Home, Cooking & Household'\n",
    "    elif productGroup in ['Garden','Pet PG','Textiles','Tools and Paint']:\n",
    "        return 'Pets, Garden & Jobs'\n",
    "    elif productGroup in ['Car and Motorcycle'] :\n",
    "        return 'Car & Motor'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eleven-machinery",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computer & Electronics          145687\n",
       "Home, Cooking & Household        83348\n",
       "Sports, Outdoor & Travel         54598\n",
       "Toys & Hobby                     52834\n",
       "Pets, Garden & Jobs              35484\n",
       "Health & Care                    31315\n",
       "Food & Beverage                  26802\n",
       "Books                            19435\n",
       "Music, Film & Games              17343\n",
       "Baby & Kids                      11784\n",
       "Fashion, Shoes & Accessories     11453\n",
       "Office & School                   5450\n",
       "Car & Motor                       3149\n",
       "Other                             1318\n",
       "Name: productGroupGeneral, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['productGroupGeneral'] = df['productGroup'].apply(productGroupCluster)\n",
    "df['productGroupGeneral'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "random-probe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Create dummies of new product grouping\n",
    "for group in df['productGroupGeneral'].unique():\n",
    "    \n",
    "    columnName = 'group' + group.split(' ')[0].replace(',','')\n",
    "    df[columnName] = df['productGroupGeneral'].apply(lambda x: True if x == group else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "loose-torture",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orderDate', 'productId', 'sellerId', 'totalPrice', 'quantityOrdered',\n",
      "       'countryCode', 'cancellationDate', 'cancellationReasonCode',\n",
      "       'promisedDeliveryDate', 'shipmentDate', 'transporterCode',\n",
      "       'transporterName', 'transporterNameOther',\n",
      "       'dateTimeFirstDeliveryMoment', 'fulfilmentType', 'startDateCase',\n",
      "       'cntDistinctCaseIds', 'returnDateTime', 'quantityReturned',\n",
      "       'returnCode', 'productTitle', 'brickName', 'chunkName', 'productGroup',\n",
      "       'productSubGroup', 'productSubSubGroup', 'registrationDateSeller',\n",
      "       'countryOriginSeller', 'currentCountryAvailabilitySeller',\n",
      "       'calculationDefinitive', 'noCancellation', 'onTimeDelivery', 'noCase',\n",
      "       'hasOneCase', 'hasMoreCases', 'noReturn', 'detailedMatchClassification',\n",
      "       'generalMatchClassification', 'determinantClassification', 'orderYear',\n",
      "       'orderMonth', 'orderYearMonth', 'orderWeekday', 'orderWeekend',\n",
      "       'orderCorona', 'transporterFeature', 'partnerSellingMonths',\n",
      "       'cancellationDays', 'shipmentDays', 'promisedDeliveryDays',\n",
      "       'actualDeliveryDays', 'caseDays', 'returnDays', 'countryCodeNL',\n",
      "       'fulfilmentByBol', 'countryOriginNL', 'countryOriginBE',\n",
      "       'countryOriginDE', 'orderMonday', 'orderTuesday', 'orderWednesday',\n",
      "       'orderThursday', 'orderFriday', 'orderSaturday', 'orderSunday',\n",
      "       'orderJanuary', 'orderFebruary', 'orderMarch', 'orderApril', 'orderMay',\n",
      "       'orderJune', 'orderJuly', 'orderAugust', 'orderSeptember',\n",
      "       'orderOctober', 'orderNovember', 'orderDecember', 'productTitleLength',\n",
      "       'binaryMatchClassification', 'orderYear2020', 'transporterCodeGeneral',\n",
      "       'productGroupGeneral', 'groupHome', 'groupHealth', 'groupSports',\n",
      "       'groupFood', 'groupToys', 'groupComputer', 'groupMusic', 'groupFashion',\n",
      "       'groupBooks', 'groupPets', 'groupBaby', 'groupCar', 'groupOffice',\n",
      "       'groupOther'],\n",
      "      dtype='object')\n",
      "Total:  96  columns\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print('Total: ',len(df.columns),' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eight-executive",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Fixed Columns:\n",
    "BASIC = ['totalPrice','quantityOrdered','fulfilmentByBol','countryCodeNL','countryOriginNL','countryOriginBE',\n",
    "        'countryOriginDE','productTitleLength']\n",
    "WEEK = ['orderMonday','orderTuesday','orderWednesday','orderThursday','orderFriday','orderSaturday','orderSunday']\n",
    "MONTH = ['orderJanuary','orderFebruary','orderMarch','orderApril','orderMay','orderJune',\n",
    "         'orderJuly','orderAugust','orderSeptember','orderOctober','orderNovember','orderDecember']\n",
    "GROUP = ['groupHealth','groupHome','groupSports','groupComputer','groupPets','groupToys','groupBooks', \n",
    "         'groupBaby', 'groupMusic', 'groupFood','groupOffice','groupFashion','groupOther','groupCar']\n",
    "\n",
    "#Dynamic Columns:\n",
    "TRANSPORTERX = ['transporterPOSTNL/X','transporterDHL/X','transporterDPD/X','transporterBRIEF/X','transporterOTHER/X']\n",
    "KNOWNX = ['caseKnownX','returnKnownX','cancellationKnownX','onTimeDeliveryKnownX','lateDeliveryKnownX']\n",
    "PRODUCTX = ['productOrderCountX','productTotalCountX','productTotalReturnedX','productReturnFractionX']\n",
    "SELLERX = ['sellerDailyOrdersX']\n",
    "\n",
    "#Classifications\n",
    "CLASS = ['generalMatchClassification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-casting",
   "metadata": {},
   "source": [
    "# Create Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "owned-scholar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T00:12:36.976094Z",
     "iopub.status.busy": "2021-02-02T00:12:36.976094Z",
     "iopub.status.idle": "2021-02-02T00:12:37.670663Z",
     "shell.execute_reply": "2021-02-02T00:12:37.669702Z",
     "shell.execute_reply.started": "2021-02-02T00:12:36.976094Z"
    }
   },
   "outputs": [],
   "source": [
    "X_col = BASIC + WEEK + MONTH + YEAR + GROUP + TRANSPORTERX + KNOWNX + PRODUCTX + SELLERX + HISTORICX\n",
    "y_col = [CLASSIFICATION[0]]  # Match label prediction\n",
    "#Y_col = [CLASSIFICATION[2]]  # Binary classification\n",
    "\n",
    "#df_sample = df\n",
    "df_sample = df.sample(n = 100000, replace = False, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-sudan",
   "metadata": {},
   "source": [
    "# Function-based Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-cabin",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "racial-vehicle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:27:01.765893Z",
     "iopub.status.busy": "2021-02-01T23:27:01.764892Z",
     "iopub.status.idle": "2021-02-01T23:27:01.773891Z",
     "shell.execute_reply": "2021-02-01T23:27:01.773646Z",
     "shell.execute_reply.started": "2021-02-01T23:27:01.765893Z"
    }
   },
   "outputs": [],
   "source": [
    "def classificationPerformanceOverTime(df, DATE, X_col, y_col, DAYS, estimator, REP, splitType = 'TimeSeries', smoteActive = False, scaler = None, NN_estimator = False):\n",
    "    resultDic = {}\n",
    "    \n",
    "    for days in range(DAYS):\n",
    "        X, y = functions.dataX(df, DATE, X_col, y_col, historic_variable, days)\n",
    "        result = functions.classifyLabelsNew(estimator, X, y, REP, splitType, smoteActive, scaler, NN_estimator)\n",
    "        resultDic[days] = result\n",
    "        print('DAYS: ', days)\n",
    "    \n",
    "    RESULT = pd.DataFrame.from_dict(resultDic, orient = 'index')\n",
    "    return(RESULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "accuracy = {}\n",
    "class_report = {}\n",
    "count = 1\n",
    "\n",
    "X, y = functions.dataX(df_sample, DATE, X_col, y_col, historic_variable, 0)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=0,\n",
    "                                 class_weight='balanced')\n",
    "    #clf = RandomForestClassifier(n_estimators=10,random_state=0,class_weight='balanced')\n",
    "    #clf = LogisticRegression(random_state=0,class_weight='balanced',fit_intercept=False,solver='liblinear')\n",
    "    #clf = GradientBoostingClassifier(random_state=0)\n",
    "    # clf = HistGradientBoostingClassifier(random_state=0)\n",
    "    #clf = BaggingClassifier(n_estimators=10,random_state=0) \n",
    "    #clf = BernoulliNB()\n",
    "    #clf = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "    #clf = svm.SVC(random_state=0, kernel='linear', decision_function_shape = 'ovo')\n",
    "    \n",
    "    clf = clf.fit(X_train,y_train)\n",
    "\n",
    "    prediction = clf.predict(X_test)\n",
    "    \n",
    "    accuracy[count] = metrics.accuracy_score(y_test, prediction)\n",
    "    class_report[count] = metrics.classification_report(y_test, prediction)\n",
    "    \n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in class_report.values():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "editorial-thomson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T08:32:32.639201Z",
     "iopub.status.busy": "2021-02-02T08:32:32.638191Z",
     "iopub.status.idle": "2021-02-02T08:32:32.673006Z",
     "shell.execute_reply": "2021-02-02T08:32:32.672033Z",
     "shell.execute_reply.started": "2021-02-02T08:32:32.638191Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-8fbb50ad8989>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'font.size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportanceDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimportanceDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 8})\n",
    "importanceDF = pd.DataFrame(clf.feature_importances_,index=X_col,columns=['importance']).sort_values('importance',ascending=False)\n",
    "importanceDF.plot.bar(figsize=(16,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "separated-circulation",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T16:35:08.632060Z",
     "iopub.status.busy": "2021-02-01T16:35:08.632060Z",
     "iopub.status.idle": "2021-02-01T16:50:47.636833Z",
     "shell.execute_reply": "2021-02-01T16:50:47.635836Z",
     "shell.execute_reply.started": "2021-02-01T16:35:08.632060Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "PREDICT_DAYS = 11\n",
    "REP = 3\n",
    "\n",
    "resultDic = {}\n",
    "\n",
    "#estimator = svm.SVC(random_state=0,class_weight='balanced')\n",
    "# estimator = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),n_estimators=50,random_state=0)\n",
    "estimator = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "#estimator = LogisticRegression(random_state=0,class_weight='balanced',fit_intercept=False,solver='liblinear')\n",
    "# estimator = RandomForestClassifier(n_estimators=10,random_state=0,class_weight='balanced')\n",
    "# estimator = KerasClassifier(build_fn = neuralNetwork,epochs = 10,verbose = 0)\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for DAYS in range(PREDICT_DAYS):\n",
    "    \n",
    "    X, y = functions.dataX(df_sample, DATE, X_col, y_col, historic_variable, DAYS)\n",
    "\n",
    "    result = functions.classifyLabelsNew(estimator, X, y, n = REP, scale = 'MinMax')\n",
    "\n",
    "    resultDic[DAYS] = result\n",
    "    \n",
    "    print('DAYS: ',DAYS)\n",
    "\n",
    "RESULT = pd.DataFrame.from_dict(resultDic, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sensitive-holly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T08:14:14.255252Z",
     "iopub.status.busy": "2021-02-02T08:14:14.254258Z",
     "iopub.status.idle": "2021-02-02T08:14:14.287304Z",
     "shell.execute_reply": "2021-02-02T08:14:14.287304Z",
     "shell.execute_reply.started": "2021-02-02T08:14:14.255252Z"
    }
   },
   "outputs": [],
   "source": [
    "RESULT_ADA.to_excel('/Users/thoma/Documents/seminar_data/base_classifier_results.xlsx', sheet_name = 'ADA, 500K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "conscious-church",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T16:51:36.970120Z",
     "iopub.status.busy": "2021-02-01T16:51:36.970120Z",
     "iopub.status.idle": "2021-02-01T17:00:39.462979Z",
     "shell.execute_reply": "2021-02-01T17:00:39.461938Z",
     "shell.execute_reply.started": "2021-02-01T16:51:36.970120Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "RESULT_BNB = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, BernoulliNB(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_estimator = LogisticRegression(random_state=0,class_weight='balanced',fit_intercept=False,solver='liblinear')\n",
    "RESULT_LOG = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, log_estimator, 3, scaler = 'MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wicked-sustainability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:27:10.961684Z",
     "iopub.status.busy": "2021-02-01T23:27:10.960680Z",
     "iopub.status.idle": "2021-02-02T00:12:36.974090Z",
     "shell.execute_reply": "2021-02-02T00:12:36.973139Z",
     "shell.execute_reply.started": "2021-02-01T23:27:10.961684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# ADA Boost (using Decision trees with max_depth = 1)\n",
    "ada_estimator = AdaBoostClassifier(random_state=0)\n",
    "RESULT_ADA = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, ada_estimator, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "adopted-fancy",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T15:11:57.280018Z",
     "iopub.status.busy": "2021-02-01T15:11:57.280018Z",
     "iopub.status.idle": "2021-02-01T15:28:19.964506Z",
     "shell.execute_reply": "2021-02-01T15:28:19.960914Z",
     "shell.execute_reply.started": "2021-02-01T15:11:57.280018Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_estimator = DecisionTreeClassifier(random_state=0,class_weight='balanced')\n",
    "RESULT_DT = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, dt_estimator, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fluid-namibia",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T17:21:20.917734Z",
     "iopub.status.busy": "2021-02-01T17:21:20.917734Z",
     "iopub.status.idle": "2021-02-01T20:28:49.657809Z",
     "shell.execute_reply": "2021-02-01T20:28:49.656868Z",
     "shell.execute_reply.started": "2021-02-01T17:21:20.917734Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gradient_estimator = GradientBoostingClassifier(random_state=0)\n",
    "RESULT_GRADIENT = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, gradient_estimator, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "chief-tourism",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T17:01:31.210424Z",
     "iopub.status.busy": "2021-02-01T17:01:31.210424Z",
     "iopub.status.idle": "2021-02-01T17:19:27.705540Z",
     "shell.execute_reply": "2021-02-01T17:19:27.703256Z",
     "shell.execute_reply.started": "2021-02-01T17:01:31.210424Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Hist Gradient Boosting\n",
    "histgradient_estimator = HistGradientBoostingClassifier(random_state=0)\n",
    "RESULT_HISTGRADIENT = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, histgradient_estimator, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "hungry-estonia",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T21:30:59.704704Z",
     "iopub.status.busy": "2021-02-01T21:30:59.704704Z",
     "iopub.status.idle": "2021-02-01T22:01:14.188560Z",
     "shell.execute_reply": "2021-02-01T22:01:14.187627Z",
     "shell.execute_reply.started": "2021-02-01T21:30:59.704704Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  0\n",
      "WARNING:tensorflow:Layer dense_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  1\n",
      "WARNING:tensorflow:Layer dense_20 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_24 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  2\n",
      "WARNING:tensorflow:Layer dense_26 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_30 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  3\n",
      "WARNING:tensorflow:Layer dense_32 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  4\n",
      "WARNING:tensorflow:Layer dense_38 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_40 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_42 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  5\n",
      "WARNING:tensorflow:Layer dense_44 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_46 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  6\n",
      "WARNING:tensorflow:Layer dense_50 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_52 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_54 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  7\n",
      "WARNING:tensorflow:Layer dense_56 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_58 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_60 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  8\n",
      "WARNING:tensorflow:Layer dense_62 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_64 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_66 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  9\n",
      "WARNING:tensorflow:Layer dense_68 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_70 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_72 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "nn_estimator = KerasClassifier(build_fn = functions.neuralNetwork,epochs = 10,verbose = 0)\n",
    "RESULT_NN = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, nn_estimator, 3, scaler = 'MinMax', NN_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "choice-mineral",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T15:47:24.971486Z",
     "iopub.status.busy": "2021-02-01T15:47:24.971486Z",
     "iopub.status.idle": "2021-02-01T16:30:32.030579Z",
     "shell.execute_reply": "2021-02-01T16:30:32.030579Z",
     "shell.execute_reply.started": "2021-02-01T15:47:24.971486Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Bagging (using Decision trees)\n",
    "bagging_estimator = BaggingClassifier(n_estimators=10,random_state=0) \n",
    "RESULT_BAG = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, bagging_estimator, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fitting-substitute",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-01T15:29:27.720852Z",
     "iopub.status.busy": "2021-02-01T15:29:27.719891Z",
     "iopub.status.idle": "2021-02-01T15:45:48.307126Z",
     "shell.execute_reply": "2021-02-01T15:45:48.306126Z",
     "shell.execute_reply.started": "2021-02-01T15:29:27.720852Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (using Decision trees)\n",
    "rf_estimator = RandomForestClassifier(n_estimators=10,random_state=0,class_weight='balanced')\n",
    "RESULT_RF = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, rf_estimator, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "found-standing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T00:12:37.672667Z",
     "iopub.status.busy": "2021-02-02T00:12:37.672667Z",
     "iopub.status.idle": "2021-02-02T01:11:17.774245Z",
     "shell.execute_reply": "2021-02-02T01:11:17.773233Z",
     "shell.execute_reply.started": "2021-02-02T00:12:37.672667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n",
      "DAYS:  1\n",
      "DAYS:  2\n",
      "DAYS:  3\n",
      "DAYS:  4\n",
      "DAYS:  5\n",
      "DAYS:  6\n",
      "DAYS:  7\n",
      "DAYS:  8\n",
      "DAYS:  9\n",
      "DAYS:  10\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbours\n",
    "knn_estimator = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "RESULT_KNN = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 11, knn_estimator, 3, scaler = 'MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "similar-toddler",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:25:54.905060Z",
     "iopub.status.busy": "2021-02-01T23:25:54.905060Z",
     "iopub.status.idle": "2021-02-01T23:26:15.136377Z",
     "shell.execute_reply": "2021-02-01T23:26:15.135195Z",
     "shell.execute_reply.started": "2021-02-01T23:25:54.905060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYS:  0\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine - too slow to run\n",
    "svm_estimator = svm.SVC(random_state=0, kernel='linear', decision_function_shape = 'ovo')\n",
    "RESULT_SVM = classificationPerformanceOverTime(df_sample, DATE, X_col, y_col, 1, svm_estimator, 3, scaler = 'MinMax') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "informational-montreal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-01T23:26:28.118892Z",
     "iopub.status.busy": "2021-02-01T23:26:28.118892Z",
     "iopub.status.idle": "2021-02-01T23:26:28.146057Z",
     "shell.execute_reply": "2021-02-01T23:26:28.145089Z",
     "shell.execute_reply.started": "2021-02-01T23:26:28.118892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_HAPPY</th>\n",
       "      <th>recall_HAPPY</th>\n",
       "      <th>f1_HAPPY</th>\n",
       "      <th>precision_UNHAPPY</th>\n",
       "      <th>recall_UNHAPPY</th>\n",
       "      <th>f1_UNHAPPY</th>\n",
       "      <th>precision_UNKNOWN</th>\n",
       "      <th>recall_UNKNOWN</th>\n",
       "      <th>f1_UNKNOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840267</td>\n",
       "      <td>0.834287</td>\n",
       "      <td>0.977994</td>\n",
       "      <td>0.900415</td>\n",
       "      <td>0.705556</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>0.047467</td>\n",
       "      <td>0.858079</td>\n",
       "      <td>0.894121</td>\n",
       "      <td>0.875646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_HAPPY  recall_HAPPY  f1_HAPPY  precision_UNHAPPY  \\\n",
       "0  0.840267         0.834287      0.977994  0.900415           0.705556   \n",
       "\n",
       "   recall_UNHAPPY  f1_UNHAPPY  precision_UNKNOWN  recall_UNKNOWN  f1_UNKNOWN  \n",
       "0        0.024837    0.047467           0.858079        0.894121    0.875646  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
